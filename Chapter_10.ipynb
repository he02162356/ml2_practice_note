{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "載入資料集(fashion_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 56s 2us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 11s 3us/step\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "製作驗證組以及將像素尺度降為0-1之間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "建立分類模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=[28, 28]))\n",
    "model.add(Dense(300, activation=\"relu\"))\n",
    "model.add(Dense(100, activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "''' or\n",
    "model = Sequential([\n",
    "    model.add(Flatten(input_shape=[28, 28]))\n",
    "    model.add(Dense(300, activation=\"relu\"))\n",
    "    model.add(Dense(100, activation=\"relu\"))\n",
    "    model.add(Dense(10, activation=\"softmax\"))\n",
    "])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#取得階層清單\n",
    "model.layers\n",
    "\n",
    "hidden1 = model.layers[1]\n",
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('dense') is hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07052931, -0.01767065, -0.03468414, ...,  0.00886471,\n",
       "        -0.06968559, -0.01493316],\n",
       "       [-0.00537051,  0.01387029,  0.02448081, ...,  0.02502297,\n",
       "        -0.03937232, -0.00298154],\n",
       "       [-0.00526917,  0.03227858, -0.00444372, ..., -0.04865788,\n",
       "         0.06963743, -0.05006591],\n",
       "       ...,\n",
       "       [-0.00768428,  0.0019048 , -0.00216477, ...,  0.05416037,\n",
       "         0.03434458, -0.05309908],\n",
       "       [ 0.05878463, -0.05900495,  0.06294499, ..., -0.04191666,\n",
       "         0.01598443,  0.06163958],\n",
       "       [-0.02181765, -0.07391696,  0.02772903, ..., -0.00244069,\n",
       "        -0.04114655, -0.04391563]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#取得參數\n",
    "\n",
    "weights, biases = hidden1.get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "編譯模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "採用\"sparse_categorical_crossentropy\"是因為標籤為稀疏,意指每個實例僅有一個目標索引\n",
    "\n",
    "y_train\n",
    "->>>>> array([4, 0, 7, ..., 3, 0, 5], dtype=uint8)\n",
    "\n",
    "倘若每個實例皆有每個類別的目標機率\n",
    "ex. one-hot ->>>>> [0., 0., 1.] 代表類別二\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練集評估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.7338 - accuracy: 0.7594 - val_loss: 0.5785 - val_accuracy: 0.7862\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 2s 984us/step - loss: 0.4915 - accuracy: 0.8269 - val_loss: 0.4510 - val_accuracy: 0.8454\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 2s 996us/step - loss: 0.4452 - accuracy: 0.8432 - val_loss: 0.4357 - val_accuracy: 0.8524\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 2s 989us/step - loss: 0.4146 - accuracy: 0.8539 - val_loss: 0.3880 - val_accuracy: 0.8666\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 2s 991us/step - loss: 0.3954 - accuracy: 0.8611 - val_loss: 0.3766 - val_accuracy: 0.8730\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 2s 982us/step - loss: 0.3807 - accuracy: 0.8655 - val_loss: 0.3817 - val_accuracy: 0.8694\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 2s 996us/step - loss: 0.3669 - accuracy: 0.8700 - val_loss: 0.3742 - val_accuracy: 0.8706\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 2s 998us/step - loss: 0.3544 - accuracy: 0.8750 - val_loss: 0.3594 - val_accuracy: 0.8740\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 2s 986us/step - loss: 0.3451 - accuracy: 0.8761 - val_loss: 0.3601 - val_accuracy: 0.8750\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 2s 986us/step - loss: 0.3347 - accuracy: 0.8811 - val_loss: 0.3539 - val_accuracy: 0.8770\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3268 - accuracy: 0.8829 - val_loss: 0.3383 - val_accuracy: 0.8816\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 2s 995us/step - loss: 0.3186 - accuracy: 0.8859 - val_loss: 0.3355 - val_accuracy: 0.8820\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3121 - accuracy: 0.8897 - val_loss: 0.3256 - val_accuracy: 0.8870\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 2s 985us/step - loss: 0.3062 - accuracy: 0.8904 - val_loss: 0.3369 - val_accuracy: 0.8798\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 2s 995us/step - loss: 0.2991 - accuracy: 0.8915 - val_loss: 0.3259 - val_accuracy: 0.8848\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 2s 993us/step - loss: 0.2924 - accuracy: 0.8956 - val_loss: 0.3185 - val_accuracy: 0.8878\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2866 - accuracy: 0.8965 - val_loss: 0.3276 - val_accuracy: 0.8798\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2814 - accuracy: 0.8988 - val_loss: 0.3084 - val_accuracy: 0.8902\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 2s 983us/step - loss: 0.2753 - accuracy: 0.9007 - val_loss: 0.3164 - val_accuracy: 0.8868\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 2s 988us/step - loss: 0.2706 - accuracy: 0.9024 - val_loss: 0.3040 - val_accuracy: 0.8888\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 2s 992us/step - loss: 0.2655 - accuracy: 0.9044 - val_loss: 0.3160 - val_accuracy: 0.8868\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 2s 979us/step - loss: 0.2613 - accuracy: 0.9053 - val_loss: 0.3049 - val_accuracy: 0.8884\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 2s 985us/step - loss: 0.2567 - accuracy: 0.9081 - val_loss: 0.2971 - val_accuracy: 0.8920\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 2s 990us/step - loss: 0.2524 - accuracy: 0.9089 - val_loss: 0.3023 - val_accuracy: 0.8928\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2485 - accuracy: 0.9103 - val_loss: 0.3158 - val_accuracy: 0.8880\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 2s 998us/step - loss: 0.2438 - accuracy: 0.9126 - val_loss: 0.3032 - val_accuracy: 0.8876\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 2s 982us/step - loss: 0.2406 - accuracy: 0.9133 - val_loss: 0.3060 - val_accuracy: 0.8854\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 2s 990us/step - loss: 0.2360 - accuracy: 0.9148 - val_loss: 0.2918 - val_accuracy: 0.8912\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2324 - accuracy: 0.9160 - val_loss: 0.2969 - val_accuracy: 0.8912\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 2s 976us/step - loss: 0.2277 - accuracy: 0.9177 - val_loss: 0.2988 - val_accuracy: 0.8902\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 1, 'epochs': 30, 'steps': 1719}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.733770</td>\n",
       "      <td>0.759382</td>\n",
       "      <td>0.578457</td>\n",
       "      <td>0.7862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.491530</td>\n",
       "      <td>0.826891</td>\n",
       "      <td>0.451032</td>\n",
       "      <td>0.8454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.445179</td>\n",
       "      <td>0.843236</td>\n",
       "      <td>0.435666</td>\n",
       "      <td>0.8524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.414586</td>\n",
       "      <td>0.853873</td>\n",
       "      <td>0.388026</td>\n",
       "      <td>0.8666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.395383</td>\n",
       "      <td>0.861109</td>\n",
       "      <td>0.376620</td>\n",
       "      <td>0.8730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.380688</td>\n",
       "      <td>0.865491</td>\n",
       "      <td>0.381679</td>\n",
       "      <td>0.8694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.366901</td>\n",
       "      <td>0.869964</td>\n",
       "      <td>0.374152</td>\n",
       "      <td>0.8706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.354378</td>\n",
       "      <td>0.874982</td>\n",
       "      <td>0.359371</td>\n",
       "      <td>0.8740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.345064</td>\n",
       "      <td>0.876109</td>\n",
       "      <td>0.360098</td>\n",
       "      <td>0.8750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.334697</td>\n",
       "      <td>0.881127</td>\n",
       "      <td>0.353895</td>\n",
       "      <td>0.8770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.326844</td>\n",
       "      <td>0.882945</td>\n",
       "      <td>0.338290</td>\n",
       "      <td>0.8816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.318645</td>\n",
       "      <td>0.885855</td>\n",
       "      <td>0.335452</td>\n",
       "      <td>0.8820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.312095</td>\n",
       "      <td>0.889745</td>\n",
       "      <td>0.325569</td>\n",
       "      <td>0.8870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.306159</td>\n",
       "      <td>0.890382</td>\n",
       "      <td>0.336914</td>\n",
       "      <td>0.8798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.299145</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.325869</td>\n",
       "      <td>0.8848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.292383</td>\n",
       "      <td>0.895564</td>\n",
       "      <td>0.318497</td>\n",
       "      <td>0.8878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.286645</td>\n",
       "      <td>0.896545</td>\n",
       "      <td>0.327570</td>\n",
       "      <td>0.8798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.281410</td>\n",
       "      <td>0.898836</td>\n",
       "      <td>0.308409</td>\n",
       "      <td>0.8902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.275342</td>\n",
       "      <td>0.900709</td>\n",
       "      <td>0.316366</td>\n",
       "      <td>0.8868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.270552</td>\n",
       "      <td>0.902436</td>\n",
       "      <td>0.303959</td>\n",
       "      <td>0.8888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.265531</td>\n",
       "      <td>0.904364</td>\n",
       "      <td>0.315994</td>\n",
       "      <td>0.8868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.261283</td>\n",
       "      <td>0.905273</td>\n",
       "      <td>0.304903</td>\n",
       "      <td>0.8884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.256722</td>\n",
       "      <td>0.908055</td>\n",
       "      <td>0.297139</td>\n",
       "      <td>0.8920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.252405</td>\n",
       "      <td>0.908945</td>\n",
       "      <td>0.302259</td>\n",
       "      <td>0.8928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.248474</td>\n",
       "      <td>0.910291</td>\n",
       "      <td>0.315846</td>\n",
       "      <td>0.8880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.243836</td>\n",
       "      <td>0.912618</td>\n",
       "      <td>0.303155</td>\n",
       "      <td>0.8876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.240596</td>\n",
       "      <td>0.913309</td>\n",
       "      <td>0.305982</td>\n",
       "      <td>0.8854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.236037</td>\n",
       "      <td>0.914782</td>\n",
       "      <td>0.291792</td>\n",
       "      <td>0.8912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.232371</td>\n",
       "      <td>0.916018</td>\n",
       "      <td>0.296897</td>\n",
       "      <td>0.8912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.227738</td>\n",
       "      <td>0.917673</td>\n",
       "      <td>0.298827</td>\n",
       "      <td>0.8902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  val_loss  val_accuracy\n",
       "0   0.733770  0.759382  0.578457        0.7862\n",
       "1   0.491530  0.826891  0.451032        0.8454\n",
       "2   0.445179  0.843236  0.435666        0.8524\n",
       "3   0.414586  0.853873  0.388026        0.8666\n",
       "4   0.395383  0.861109  0.376620        0.8730\n",
       "5   0.380688  0.865491  0.381679        0.8694\n",
       "6   0.366901  0.869964  0.374152        0.8706\n",
       "7   0.354378  0.874982  0.359371        0.8740\n",
       "8   0.345064  0.876109  0.360098        0.8750\n",
       "9   0.334697  0.881127  0.353895        0.8770\n",
       "10  0.326844  0.882945  0.338290        0.8816\n",
       "11  0.318645  0.885855  0.335452        0.8820\n",
       "12  0.312095  0.889745  0.325569        0.8870\n",
       "13  0.306159  0.890382  0.336914        0.8798\n",
       "14  0.299145  0.891473  0.325869        0.8848\n",
       "15  0.292383  0.895564  0.318497        0.8878\n",
       "16  0.286645  0.896545  0.327570        0.8798\n",
       "17  0.281410  0.898836  0.308409        0.8902\n",
       "18  0.275342  0.900709  0.316366        0.8868\n",
       "19  0.270552  0.902436  0.303959        0.8888\n",
       "20  0.265531  0.904364  0.315994        0.8868\n",
       "21  0.261283  0.905273  0.304903        0.8884\n",
       "22  0.256722  0.908055  0.297139        0.8920\n",
       "23  0.252405  0.908945  0.302259        0.8928\n",
       "24  0.248474  0.910291  0.315846        0.8880\n",
       "25  0.243836  0.912618  0.303155        0.8876\n",
       "26  0.240596  0.913309  0.305982        0.8854\n",
       "27  0.236037  0.914782  0.291792        0.8912\n",
       "28  0.232371  0.916018  0.296897        0.8912\n",
       "29  0.227738  0.917673  0.298827        0.8902"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) #將縱座標設為[0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型驗證及測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 984us/step - loss: 64.3692 - accuracy: 0.8468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[64.3691635131836, 0.8468000292778015]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-32-81ace37e545f>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "建立回歸模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 30)                270       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 674us/step - loss: 0.7594 - val_loss: 10.7906\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 545us/step - loss: 0.4910 - val_loss: 23.5368\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 537us/step - loss: 0.5533 - val_loss: 13.9391\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 503us/step - loss: 0.4731 - val_loss: 18.4506\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 549us/step - loss: 0.4616 - val_loss: 0.3753\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 559us/step - loss: 0.3982 - val_loss: 0.3677\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 540us/step - loss: 0.3900 - val_loss: 0.3653\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 549us/step - loss: 0.3852 - val_loss: 0.3738\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 617us/step - loss: 0.3837 - val_loss: 0.4027\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 533us/step - loss: 0.3773 - val_loss: 0.3933\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 560us/step - loss: 0.3756 - val_loss: 0.3956\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 577us/step - loss: 0.3724 - val_loss: 0.3749\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 514us/step - loss: 0.3727 - val_loss: 0.3672\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 561us/step - loss: 0.3690 - val_loss: 0.4086\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 575us/step - loss: 0.3767 - val_loss: 0.3739\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 515us/step - loss: 0.3680 - val_loss: 0.3489\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 537us/step - loss: 0.3634 - val_loss: 0.3741\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 565us/step - loss: 0.3630 - val_loss: 0.3481\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 577us/step - loss: 0.3657 - val_loss: 0.3494\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 528us/step - loss: 0.3606 - val_loss: 0.3370\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAmOUlEQVR4nO3deXRb9Z338fdXkmV5X2LHWckeSKAsSQiEQEiG5QmUrS1taTsQGGjaaZnl6bTz0Okc2ofO1ulp5zzT0lJa0rK1oVCgKUNJKU1I2ZOQEJIAiZMA2e0stuN4k6Xf88eVE8eRbMWWLUv+vM65R7q6P119cyN/9NPvLjLnHCIikvl86S5ARERSQ4EuIpIlFOgiIllCgS4ikiUU6CIiWUKBLiKSJXoMdDNbYmY1ZrYxwXIzs/82s2oz22BmM1JfpoiI9CSZHvovgIXdLL8KmBKbFgM/7ntZIiJyqnoMdOfcKuBQN02uBx5ynteAUjMbmaoCRUQkOYEUrGM0sLPT/K7YY3u7NjSzxXi9ePLy8maOHTu2Vy8YjUbx+Qbv8H9/1lfYuINwThGtuRW9XsdQ3n6pMNjrg8Ffo+rrvS1bthxwzlXGXeic63ECxgMbEyx7Bri40/wLwKye1jlz5kzXWytWrOj1cwdCv9b376c59z9f7dMqhvT2S4HBXp9zg79G1dd7wBqXIFdT8RG0G+jc1R4Te0z6gxno+jsiEkcqAn0ZcEvsaJcLgXrn3EnDLZIqBijQReRkPY6hm9mvgPlAhZntAr4J5AA45+4DngWuBqqBJuC2/ipWUA9dRBLqMdCdc5/pYbkDvpyyiqQH6qGLSHyDczeuJKYeuogkoEDPOOqhi0h8CvRMox66iCSgQM846qGLSHwK9EyjHrqIJKBAzzjqoYtIfAr0TGOmPBeRuBToGUc9dBGJT4GeaTSGLiIJKNAzjnroIhKfAj3TGOqhi0hcCvSMox66iMSnQM80GkMXkQQU6BlHPXQRiU+BnmnUQxeRBBToGUc9dBGJT4GeadRDF5EEFOiZxnyohy4i8SjQM4566CISnwI905iBi6a7ChEZhBToGUc7RUUkPgV6ptFOURFJQIGecSzdBYjIIKVAzzTqoYtIAgr0jKMxdBGJT4GeaXT5XBFJQIGecdRDF5H4FOiZRmPoIpKAAj3jqIcuIvEp0DONeugikoACPeOohy4i8SnQM4166CKSgAI946iHLiLxKdAzjXroIpKAAj3jqIcuIvElFehmttDM3jOzajO7K87y08xshZmtM7MNZnZ16ksVQD10EUmox0A3Mz9wL3AVMB34jJlN79Lsn4FfO+fOA24CfpTqQqWDeugiEl8yPfTZQLVzbrtzrg1YClzfpY0DimP3S4A9qStRTqAeuogkYK6HcDCzG4GFzrk7YvM3Axc45+7s1GYk8AegDCgALnfOrY2zrsXAYoCqqqqZS5cu7VXRjY2NFBYW9uq5A6E/6zt33ddx5uOtc/+11+sYytsvFQZ7fTD4a1R9vbdgwYK1zrlZcRc657qdgBuBn3Wavxn4YZc2XwH+IXZ/DrAZ8HW33pkzZ7reWrFiRa+fOxD6tb4lVzm35Oo+rWJIb78UGOz1OTf4a1R9vQescQlyNZkhl93A2E7zY2KPdXY78OvYB8SrQAioSGLdcqrMh8bQRSSeZAJ9NTDFzCaYWRBvp+eyLm0+BC4DMLNpeIFem8pCpRONoYtIHD0GunOuHbgTWA68g3c0yyYzu8fMros1+wfg82b2FvAr4NbYVwNJNdNRLiISXyCZRs65Z4Fnuzx2d6f7m4G5qS1N4tNRLiISn84UzTRm4KLprkJEBqGMC3TnHAebh3KgachFROLLuED/wZ+q+cdVzRxtbU93KemhE4tEJIGMC/SZ48qIOHh9x8F0l5Im6qGLSHwZGehBH6zaciDdpaSHeugikkDGBXoox8/p5X5WbR2qh7mrhy4i8WVcoAOcVeFne+1Rdh1uSncpA089dBFJIGMDHeClrUNx2EU9dBGJLyMDfVSBMaI4xJ+HYqCrhy4iCWRkoJsZl0yp4KXqA0SiQy3c1EMXkfgyMtAB5k2tpL45zIZddekuZWCZKc9FJK6MDfS5kyswYwgOu6iHLiLxZWyglxcE+cjoElZtGWKHL2oMXUQSyNhAB7hkSgXrdtbR0BJOdykDTIEuIifL6ECfN6WSSNTx6rYhdBkA9dBFJIGMDvTzTiujIOjnz0PqrFGNoYtIfBkd6MGAjzmThg2t67qohy4iCWR0oIN3+OKHh5r44ODRdJcyQNRDF5H4Mj7QL5lSCcCqoXL4onroIpJAxgf6+GH5jCnLG0KHL6qHLiLxZXyge5cBqOTVbQcJR4bAT9OZTz10EYkr4wMd4NKpFTS2trN+Z126S+l/ph66iMSXFYE+Z1IFPoM/D4lhF42hi0h8WRHoJXk5nDu2lBeHwo5R9dBFJIGsCHTwjnbZsKuOuqa2dJfSz9RDF5H4sibQ502txDl4uTrLLwOgwxZFJIGsCfRzxpRQFAoMgcMXNeQiIvFlTaAH/D7mTqrgz1trcdncg1UPXUQSyJpAB2/YZU99C9tqs/kyAOqhi0h8WRXol0ypAMjuqy8a6qGLSFxZFehjy/OZUFGQ5ePo6qGLSHxZFejg9dJf236I1vZIukvpHxpDF5EEsi7Q502ppDkcYe0Hh9NdSj9RD11E4su6QL9w0jACPsveH71QD11EEkgq0M1soZm9Z2bVZnZXgjafMrPNZrbJzH6Z2jKTV5gbYMa4sizeMaoeuojE12Ogm5kfuBe4CpgOfMbMpndpMwX4OjDXOXcm8PepLzV586ZUsGlPAwcaW9NZRv9QD11EEkimhz4bqHbObXfOtQFLgeu7tPk8cK9z7jCAc64mtWWemnlTvV8xerk6G4dd1EMXkfisp7MqzexGYKFz7o7Y/M3ABc65Ozu1eRrYAswF/MC3nHPPxVnXYmAxQFVV1cylS5f2qujGxkYKCwsTLo86x9/+qYlzKgN8/uzcXr1GX/RUX19M2XIfw2te4uWLH+n1OvqzvlRQfX032GtUfb23YMGCtc65WXEXOue6nYAbgZ91mr8Z+GGXNs8ATwE5wARgJ1Da3XpnzpzpemvFihU9tvnyo2vdrH953kWj0V6/Tm8lU1+vPfMPzv3HuD6tol/rSwHV13eDvUbV13vAGpcgV5MZctkNjO00Pyb2WGe7gGXOubBzbgdeb31KUh83/WTe1Epqj7Ty3v4j6Swj9TSGLiIJJBPoq4EpZjbBzILATcCyLm2eBuYDmFkFMBXYnroyT92xywBk3eGLGkMXkfh6DHTnXDtwJ7AceAf4tXNuk5ndY2bXxZotBw6a2WZgBfA151xaL0w+siSPKcMLWZVthy+aKc9FJK5AMo2cc88Cz3Z57O5O9x3wldg0aFwypZJHXv+AlnCEUI4/3eWkiHroIhJf1p0p2tm8qRW0tUd5Y8ehdJeSOubTGLqIxJXVgX7BhGEE/b7suvqifiRaRBLI6kDPC/o5f0IZf96aZTtG1UMXkTiyOtDBG0d/b/8R9je0pGR94UiUDw6m8ReR1EMXkQSyPtDnTfEuA5CKXvqho2189qevcel3V/L0uq6H4g8UHYcuIvFlfaCfMaKIisLcPo+jV9cc4YZ7X+atXfVMH1nMVx9/ixXvpuGSNeqhi0gCWR/oPp9xyZQKXqo+QDTauyB8aesBPvajV2hqa2fp4gt57AsXcsbIIv760bWseX+gj6AxcNEBfk0RyQRZH+jgHb546Ggbm/c2nPJzH339Axb9/A1Gl+bx9JfnMuO0MopCOfzittmMKsnjr36xmnf3nfp6e02n/otIAkMi0OdO9i4D8OIpDLtEoo57freZbzy1kXlTKnj8i3MYU5Z/bHlFYS4P3T6b/GCAWx54g52HmlJed3wachGR+IZEoA8vCjFtZHHSv2LU2NrO5x9aw5KXd3Db3PH8bNH5FIVyTmo3piyfh26fTWt7lL984HVqjwzAD2qohy4iCQyJQAfvV4zWfnCYo63t3bbbXdfMjT9+hRe31PLtG87im9eeid9nCdtPrSri57edT01DK4uWvEFDSzjVpXehHrqIxDd0An1qJeGI4/Udia8Ztn5nHdf/8GV2H27m57eez80Xjktq3TNOK+O+m2eyteYIdzy4hrZIPwaueugiksCQCfSZ48oI5fhYleByus9s2MOnf/IqeUEfT37pomM/Y5esS6dW8r1Pncvq9w/x47daaY/015Eo6qGLSHxDJtBDOX4umDDspMvpOuf4wQtbufOX6zh7TAlPf2kuU6qKevUa150ziv973Zmsq4lw15Nvd/yaU2pZ4uEfERnahkygg/ejF9trj7LrsHdESmt7hK/8+i2+9/wWPnbeaB654wKGFfbtN0hvmTOe6yfl8MTaXfz7799NRdldxAJdwy4i0sWQCvRLpx6/DMDBxlY+99PXeWrdbr565VS+/6lzyA2k5prpN0zO4ZY547h/1Xbue3FbStZ5jCnQRSS+pH7gIltMHl7IiOIQT6zdxY9WVlPT0Mq9n53BR88emdLXMTO+de2ZHG4K8x+/f5ey/Bw+ff5pqVp77FaBLiInGlKBbuZdBuDxtbuoKMzlsS/M4dyxpf3yWj6f8b1PnkN9c5ivP/k2JXlBFp41ou8rVg9dRBIYUkMuAIsuGs81Z4/kt3fO7bcw7xAM+LjvL2dwzthS/nbpOl7dloqfWVUPXUTiG3KBftboEn742RmMLs0bkNfLDwb4+a3nM648n88/tIaNu+v7tsJjea5AF5ETDblAT4fS/CAP3T6bkrwcFi15g+21jX1Ym3roIhLfkBpDT6eRJXk8fPtsbrzvVT71k1e5cOIwJg8vZFKlN02sLCCUk8RRNhpDF5EEFOgDaGJlIQ/fPpvv/2ELG3bV8z9v7z2Wy2YwujTvWMBPGl7A5MpCJg0vZFhBEDt2QpF66CISnwJ9gJ05qoQHbj0fgJZwhB0HjrKttpFtNbHb2kbe2HGI5nDk2HNK8nKYVFnApMpCPtF8mAsB56LonFER6UyBnkahHD/TRhYzbWTxCY9Ho469DS1sq/ECvjp2u3JLLWVNtVyYA9/+3Wb+6YaZBPzaDSIiHgX6IOTzGaNL8xhdmnfSRcKaV74NK2Hp6g/Z0eD4wWdnUJir/0YR0VEuGScv6IX3N6+dxqqtB/jkfa+yt745zVWJyGCgQM843sj5p2eOYcmt57PzUBM33Pty349vF5GMp0DPNHb8KJdLp1by+Bfn4DPjUz95lT+9uz+tpYlIeinQM86Jx6FPG1nM01+ey8TKAu54cA0Pvfp++koTkbRSoGcaO/k49KriEL/+whz+4ozh3P3bTdzzu81EojpOXWSoUaBnnPhniuYHA/zk5lncNnc8S17ewRcfWUtTW/c/iC0i2UWBnmm6OfXf7zO+ee2ZfOva6bzwzn4+/ZPXqGloGeACRSRdFOgZp+dT/2+dO4Gf3jKLbbWNfOxHr/DeviMDU5qIpJUCPdMkeXGuy6ZV8esvzCEciXLjj19h1ZbabtuLSOZLKtDNbKGZvWdm1WZ2VzftPmFmzsxmpa5Eia/nnZ5njS7h6S/PZXRZHrf9YjW/euPDAahLBi3nYPMy+OVN8Pr90NaU7ookxXo8Z9zM/MC9wBXALmC1mS1zzm3u0q4I+Dvg9f4oVGJO8fK5o0rzeOKvL+LLj77J1598mw8ONjE7lMFHwOzdANv+BAWVUHoalI2DolHg1+UPurX7TVj+DfjwFcgrgy2/hxe/Axd+Ec6/w3tMMl4yfwWzgWrn3HYAM1sKXA9s7tLu28B3gK+ltELp4tQvn1uYG+CBRbP45rJN3PfiNl6t9LM77wNGFocYURJiVGkeZfk5nS7RO8i01MPbT8CbD8He9Scv9wWgeLQX7qWnQen442FfehoUjgDfEB1drN8FL9wDGx7zPgSv+S847xbYtRpe+j786V/gpf8Hs26DC78Exan9wXQZWOZ66OmZ2Y3AQufcHbH5m4ELnHN3dmozA/iGc+4TZrYS+Kpzbk2cdS0GFgNUVVXNXLp0aa+KbmxspLCwsFfPHQj9Wd/IPc9x+pYf88qcJbTlDjul5zrnWP5+O09saaXdnRjeAR+Uh4yyXKM8ZJSHfJSFOu5784VB8A1A6Dc2NlJYUEBJ/TuM3Ps8lbUv4Y+20Vgwnr0jr6Rm+Fz8kWbymvcTaqkh1HLibW7b4RPWF7UcWkKVtISG0xKqojV3GODwRdtiU/iUbp1zHCmZzqHyGRwqn0Fz/uALweb6WqYfXM6YXb/FnGPn2Ov58LRPEAnkn9CuoHEHp334JMNrXsKZj30j/oKdYz/e7/+mofw33FcLFixY65yLO6zd5++pZuYDvg/c2lNb59z9wP0As2bNcvPnz+/Va65cuZLePncg9Gt9a3bAFrhozhwoHnXKT18AXLliBWfNnMOe+hb21Tezt76FffUtx+Z31rewpqaFcOTED/ug30dVSS5VRSFK83MozsuhpJupY3lSv8TUobGW6qf+lcnvvwwHtkCwCM77HMy4hcJR5zHFjCk9rSPcDHU7oe5DqHsf3+EPyK/7kPy6D6BuDTTFfqzbH4RACAK5J97m5kKg5OTHY+337HyfUa3VDKu+31tP2QSYfDlMvgzGXwK5aQyCaATWPUzby98kGK6Dj3wSLrubcaWnMS7uE+YDt8GhHdgrP2DUukcYte+PMP16uPh/w8hz+qXMIf033I+SCfTdwNhO82Nij3UoAs4CVsa+so8AlpnZdfF66dJHKfgJOp8Zw4tDDC8OwdjSuG2iUceBo63sq2/pFPjN7KtvYX9DC7vrWnhn7xHqm8M0tnZ/AlMw4Dsh6ItCAXL8PoJ+HwG/kWOOac1rueDwM0xreInJrp1dRWezcfLd7Bh+BQQLyNlu5HzwAQG/kRvwU16Qw7CCXIYVBqkozD3xQyMnDyqnelM87W3eME0vh2G2rFzJqPnz4dB2qH7Bm9b/Elb/FHw5MG5OLOAvh+HTO53d28+2/QmW/zPUbKK5+AyCi34DY5I8PqF8Alzzfbj0/8DrP4bVD8Cmp2DSZV6wj7944P4d0mvJBPpqYIqZTcAL8puAz3YsdM7VAxUd890NuUgqDMxP0Pl8xvCiEMOLQpw9pvu27ZEoDS3t1DeHT5gautx2TAcb2whHopSG93Nl2x+5OvwCI6jlMEU84hayNDyPrQfH0l7rgJ1J1VuYG2BYYZBhBUGGFeZSURhkWEHstvB48A8rCFKaH8TvS0E4lU+E2RNh9uehvRU+fA2q/+gF/PN3e1PRSK/nPvlymDi/f3Y+1rwLf/hnqH4eSsfBJx9kXU0J85MN886KquDyb3khvvoBeO1H8OA1MHqW99jpVw/d/REZoMdAd861m9mdwHLADyxxzm0ys3uANc65Zf1dpHTS0Ut68yGoPN0LjKKRUDTC65mmQcDvo7wgSHlBsPuG7a3QsNs7UmXdI174AUxaADNuoez0q1kUyGVc7Ouuc472qCMciRKOONojUdqjjpZwhENH2zjY2MbBo60caPTuH2hs5eDRVnYeamLdh3UcOtpKokvaBP0+cvxGTsB37NtCjt/I8XvzOQEfwc7zfh/BgBHw+Th0oJUX6jaSH/STF/THbgPk50wif+RU8sb9DSXhA1TWvETpnlXkb/4dvnWP4MyHjZ7l/XvLJ3r/Z0WjvNtQcfxCu9NYCyv/DdY+CMFCuOLbcMEXvCGi2pWnvr6YlnCE/UcD7Bu9iNrLbqD0vcc5c8cvKHvsc+zyj+XRnI+xoWQBFWVljC7NY1Tsx1hGleYxuiyvf39wpb0V9qyH4dN6t82yXFJb3jn3LPBsl8fuTtB2ft/LkoQqTvfGlV/8zsnL8sqOh3tHUBSP7BT6I6FweP/UFY3C0Rqo3w31O73grt/l3a+P3T9ac7x98Wi49B/h3M95R6PEYWbHQrarccMKkijJUdcc5kBjqxf2jW0cbGzlUFOYtvZo7IPCm9ravQ+O9ujx+x3T0bYI4U7tG45G2HR4D0fbIrS1R7upYDTwGfx8inNsG5f6NzD/w7f4yK7/xNflG9ZRF6KGMvZTTo0rYz9l7Hdl7Hfl1FDGPldGjSujjQC5tPH5nOUstqcI0crvQ1ezrOQWotXlFOzcTH4wwOGaVtaFt1CYG6AgN0BBrp+CYID8XD+hHD8HG9vY19BCTYM3nLb/SCv761vY19BCfXO4y7/jLApyvsun89eyKPIU/6flv2lpvZ8/Hzif37TM5meRs2kj5/h/bShwLORHl3lB782HGF2aT2VRbo//dyeIhGHHi7DxSXjnGWit9/ZpTF3o7SOYcoX3ISb6CbqMc9oF8PWd0FIHR/ZBwx7v9kjstmEvHNkLNe9A435wXQLHfFwUKIb1Jd4fRU4ozo7BvBPnczrPh7z1HNkbC+yOAN8D0S5BkFMAJWO8acRZUDLWC/LyCTD2AvCdws7SXvD57Ng3h6lVRSlbb+cdZpGoo6mtnea2CE2xqTncfvz+scfPorntGp4LR3imuZGi8AGK22spDh+gOFxLYZt3Ozp8gDPatlEYPkDAdQ1WaAqUApDfXsfmoot4ovwLbGcUR1vbaaxroamtnaOt7TQ0t/Pc+1t73kYGlUW5VBWHOG1YPrMnlFNV7M2PKAlRVexNxaEAZteAuxt2rCK08Tdc8c4yroj8mWhBEYfHXkH18CvZEDyPnQ3t7KlrZnddC2s+OHzSB4TfZ+T7HcNWrzi287w4lENxXiB2m0NJyMeExvWM3/ccVbv+QKD1MNFgEe6Ma/BPuRx2vgGbnoTNT0NuCUy/zgv38Ref0vvKOUdbJEpLW5SW9ggt4QjN4Qjb6yLkbjtIS3uE1thjLeEoLeEIre1RCoJ+ivNyKM0PUpqXQ2l+x/6hnNQM5/WSAj0TmXm98bwy76tnItEINNZ44dsxNezlQPVbjKosh/YWCLd4t+2t0NIQux+b77gNN3PSmL35vXAuGQ1jZ8fuj/FCuyR2P1Sa9TvS/D6jKOT9IaeUc9B0qNMHtXebf2QPtB6BGbcwfeJ84n5NxvvQuWTepRxta6epNUJjqxf0R9vaaQ1HKS8IUlUcoqIweGo/NG4GEy/1po9+D3a8iG/jUwx793cM2/YkF4RKYdq1cPHHYfw88AdobO0I+Gb21DWzt66FzdXvU1heSkOLt49lT10zR5rbmNSymSt5hSv9rzPc6jjqcvmf6EyeiVzIqpazaX0jSHCtD7/vLwjYpcyxjXy05SUuX/c4BesepoYynmMuy32X8C4TMZ8Bhpn34WWxfVBtkSjNbRFa2iOJjy947bVT+A87vnmKQ164d4R8aX6QkrwApXnBY0eHzRpXxsTK1B8NpUDPZj6/N+TS5WSRLf7YURrJcs772tsR8C7inaTSzz3sIc0MCoZ504iP9GoVfp95Pd5Uf9gce4Gc40fztP+Xd5TNpidh09Ow7mHIr4Dp11F45seZOu6iE74lrczdy/z553nvrT1vwsZnvee178IFQrROuIy9E65l34hLKQkHuKY5zLyWdhqawzS0hIlGHc6BYwLr3TVsjLQwpf4VPnJoOZ9teI5bos9QmzuWt0qvYH3pFRzMHYNzEI2ldzDgIy/HG346Ph1/bMs7m5g981xCOf5O7bzlwYCPo60R6pvbqGvydvTXNYWpaw5T39TmzXd6bOehpmMHBHTs0/m3j31EgS5pYgaBoDeJxBMIwukLvSnc4h1xs/FJeGsprFkChVUw/QY46+MwZjYFjTvgjy96HwCH3/cO95x8GVz+Tez0qwjlFjESOLXTm2YCfwPNh2HzMirffpzL3/85l+9fAqPO84ZkzvqEt2+pB/kH3+OiSRWJlwcDp7wvIBp1HGltp74pTEle/3zIKtBFJLVyQt6wy7Rroe0obFnuHdP+5oPwxk8gWMT5bUe8YbuJl8K8r8EZH03dIZ15ZTBzkTfV7/Y+NN5+HJb/k3c9m3FzoaACou3Hp0jYG6KMtkM0zMz6OtgcOjbv3Ua8di7qXVJi+DSoPMO7HT7NG3bsZojR57Nj52L0FwW6iPSfYIHXKz/r497Y/3vPwY6VbGksZOoNX/OCtT+VjIaL/sabarfAxifgvWfhaK13cpk/EDvJLOB9Swjkgq+A1hYfReVV3rCiL+d4G3/AGyY6vAO2Pg/rHz3+WrnF3qHEHSHfcVs0csD2JSnQRWRg5BbB2Z+Esz/JnpUrmdrfYd5V5VRY8E/e1IONyZ7633TIO6Ks9h3vBK/ad70PjHUPH28TKoHKaTD8jOO3I86G/PLe/1sSUKCLiPRWfjmMn+tNnTXWdgr52O3m30LzL7zlV30XLlic8nIU6CIiqVZY6U0T5h1/zDnv3JCad2DY5H55WQW6iMhAMIudxd3zUTa9pavsiIhkCQW6iEiWUKCLiGQJBbqISJZQoIuIZAkFuohIllCgi4hkCQW6iEiWUKCLiGQJBbqISJZQoIuIZAkFuohIllCgi4hkCQW6iEiWUKCLiGQJBbqISJZQoIuIZAkFuohIllCgi4hkCQW6iEiWUKCLiGQJBbqISJZQoIuIZAkFuohIlkgq0M1soZm9Z2bVZnZXnOVfMbPNZrbBzF4ws3GpL1VERLrTY6CbmR+4F7gKmA58xsymd2m2DpjlnDsbeAL4z1QXKiIi3Uumhz4bqHbObXfOtQFLges7N3DOrXDONcVmXwPGpLZMERHpiTnnum9gdiOw0Dl3R2z+ZuAC59ydCdr/ENjnnPuXOMsWA4sBqqqqZi5durRXRTc2NlJYWNir5w4E1dc3qq/vBnuNqq/3FixYsNY5NyvuQudctxNwI/CzTvM3Az9M0PYv8XrouT2td+bMma63VqxY0evnDgTV1zeqr+8Ge42qr/eANS5BrgaS+EDYDYztND8m9tgJzOxy4BvApc651mQ/bUREJDWSGUNfDUwxswlmFgRuApZ1bmBm5wE/Aa5zztWkvkwREelJj4HunGsH7gSWA+8Av3bObTKze8zsuliz7wKFwONmtt7MliVYnYiI9JNkhlxwzj0LPNvlsbs73b88xXWJiMgp0pmiIiJZQoEuIpIlFOgiIllCgS4ikiUU6CIiWUKBLiKSJRToIiJZQoEuIpIlFOgiIllCgS4ikiUU6CIiWUKBLiKSJRToIiJZQoEuIpIlFOgiIllCgS4ikiUU6CIiWUKBLiKSJRToIiJZQoEuIpIlFOgiIllCgS4ikiUU6CIiWUKBLiKSJRToIiJZQoEuIpIlFOgiIllCgS4ikiUU6CIiWUKBLiKSJRToIiJZQoEuIpIlFOgiIllCgS4ikiUU6CIiWSKpQDezhWb2nplVm9ldcZbnmtljseWvm9n4lFcqIiLd6jHQzcwP3AtcBUwHPmNm07s0ux047JybDPwX8J1UFyoiIt1Lpoc+G6h2zm13zrUBS4Hru7S5Hngwdv8J4DIzs9SVKSIiPQkk0WY0sLPT/C7ggkRtnHPtZlYPDAMOdG5kZouBxbHZRjN7rzdFAxVd1z3IqL6+UX19N9hrVH29Ny7RgmQCPWWcc/cD9/d1PWa2xjk3KwUl9QvV1zeqr+8Ge42qr38kM+SyGxjbaX5M7LG4bcwsAJQAB1NRoIiIJCeZQF8NTDGzCWYWBG4ClnVpswxYFLt/I/An55xLXZkiItKTHodcYmPidwLLAT+wxDm3yczuAdY455YBDwAPm1k1cAgv9PtTn4dt+pnq6xvV13eDvUbV1w9MHWkRkeygM0VFRLKEAl1EJEsM6kAfzJccMLOxZrbCzDab2SYz+7s4beabWb2ZrY9Ndw9UfbHXf9/M3o699po4y83M/ju2/TaY2YwBrO30TttlvZk1mNnfd2kz4NvPzJaYWY2Zbez0WLmZPW9mW2O3ZQmeuyjWZquZLYrXph9q+66ZvRv7/3vKzEoTPLfb90I/1/gtM9vd6f/x6gTP7fbvvR/re6xTbe+b2foEzx2QbdgnzrlBOeHtgN0GTASCwFvA9C5tvgTcF7t/E/DYANY3EpgRu18EbIlT33zgmTRuw/eBim6WXw38HjDgQuD1NP5f7wPGpXv7AfOAGcDGTo/9J3BX7P5dwHfiPK8c2B67LYvdLxuA2q4EArH734lXWzLvhX6u8VvAV5N4D3T7995f9XVZ/j3g7nRuw75Mg7mHPqgvOeCc2+ucezN2/wjwDt4Zs5nkeuAh53kNKDWzkWmo4zJgm3PugzS89gmcc6vwjtTqrPP77EHghjhP/V/A8865Q865w8DzwML+rs059wfnXHts9jW880TSJsH2S0Yyf+991l19sez4FPCrVL/uQBnMgR7vkgNdA/OESw4AHZccGFCxoZ7zgNfjLJ5jZm+Z2e/N7MyBrQwH/MHM1sYuu9BVMtt4INxE4j+idG6/DlXOub2x+/uAqjhtBsO2/Cu8b1zx9PRe6G93xoaFliQYshoM2+8SYL9zbmuC5enehj0azIGeEcysEPgN8PfOuYYui9/EG0Y4B/gB8PQAl3exc24G3pUyv2xm8wb49XsUO1ntOuDxOIvTvf1O4rzv3oPuWF8z+wbQDjyaoEk63ws/BiYB5wJ78YY1BqPP0H3vfND/PQ3mQB/0lxwwsxy8MH/UOfdk1+XOuQbnXGPs/rNAjplVDFR9zrndsdsa4Cm8r7WdJbON+9tVwJvOuf1dF6R7+3Wyv2MoKnZbE6dN2ralmd0KXAN8LvaBc5Ik3gv9xjm33zkXcc5FgZ8meO20vhdj+fFx4LFEbdK5DZM1mAN9UF9yIDbe9gDwjnPu+wnajOgY0zez2Xjbe0A+cMyswMyKOu7j7Tzb2KXZMuCW2NEuFwL1nYYWBkrCXlE6t18Xnd9ni4DfxmmzHLjSzMpiQwpXxh7rV2a2EPhH4DrnXFOCNsm8F/qzxs77ZT6W4LWT+XvvT5cD7zrndsVbmO5tmLR075XtbsI7CmML3t7vb8QeuwfvzQsQwvuqXg28AUwcwNouxvvqvQFYH5uuBr4IfDHW5k5gE94e+9eAiwawvomx130rVkPH9utcn+H9eMk24G1g1gD//xbgBXRJp8fSuv3wPlz2AmG8cdzb8fbLvABsBf4IlMfazgJ+1um5fxV7L1YDtw1QbdV4Y88d78GOo75GAc92914YwO33cOz9tQEvpEd2rTE2f9Lf+0DUF3v8Fx3vu05t07IN+zLp1H8RkSwxmIdcRETkFCjQRUSyhAJdRCRLKNBFRLKEAl1EJEso0EVEsoQCXUQkS/x/9K3cOQam7fYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.DataFrame(history.history))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 302us/step - loss: 0.3543\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.64504963],\n",
       "       [1.6663288 ],\n",
       "       [4.1411757 ]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 Functional API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Concatenate\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "#residual模塊\n",
    "input_ = Input(shape=X_train.shape[1:])\n",
    "hidden1 = Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = Concatenate()([input_, hidden2])\n",
    "output = Dense(1)(concat)\n",
    "model = Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 30)           270         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 30)           930         dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 38)           0           input_3[0][0]                    \n",
      "                                                                 dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 1)            39          concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"functional_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#多輸入\n",
    "\n",
    "input_A = Input(shape=[5], name=\"wide_input\")\n",
    "input_B = Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = Concatenate()([input_A, hidden2])\n",
    "output = Dense(1, name=\"output\")(concat)\n",
    "model = Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11610, 8)\n",
      "(11610, 5)\n",
      "(11610, 6)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_train_A.shape)\n",
    "print(X_train_B.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 779us/step - loss: 2.2613 - val_loss: 3.8818\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 647us/step - loss: 0.7906 - val_loss: 2.1988\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 676us/step - loss: 0.6745 - val_loss: 1.3711\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 680us/step - loss: 0.6153 - val_loss: 0.9699\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 668us/step - loss: 0.5731 - val_loss: 0.7527\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 644us/step - loss: 0.5417 - val_loss: 0.6339\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 697us/step - loss: 0.5184 - val_loss: 0.5632\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 637us/step - loss: 0.5008 - val_loss: 0.5133\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 666us/step - loss: 0.4874 - val_loss: 0.4913\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 638us/step - loss: 0.4767 - val_loss: 0.4691\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 664us/step - loss: 0.4678 - val_loss: 0.4563\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 606us/step - loss: 0.4609 - val_loss: 0.4504\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 669us/step - loss: 0.4553 - val_loss: 0.4429\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 620us/step - loss: 0.4502 - val_loss: 0.4353\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 658us/step - loss: 0.4458 - val_loss: 0.4325\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 642us/step - loss: 0.4420 - val_loss: 0.4296\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 661us/step - loss: 0.4384 - val_loss: 0.4266\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 635us/step - loss: 0.4354 - val_loss: 0.4245\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 698us/step - loss: 0.4327 - val_loss: 0.4222\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 674us/step - loss: 0.4302 - val_loss: 0.4228\n"
     ]
    }
   ],
   "source": [
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 397us/step - loss: 0.4194\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4194067120552063"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#多輸入多輸出\n",
    "\n",
    "input_A = Input(shape=[5], name=\"wide_input\")\n",
    "input_B = Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = Concatenate()([input_A, hidden2])\n",
    "output = Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = Dense(1, name=\"aux_output\")(hidden2)\n",
    "model = keras.models.Model(inputs=[input_A, input_B],\n",
    "                           outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#可設置loss權重 \n",
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.8361 - main_output_loss: 2.4672 - aux_output_loss: 6.1565 - val_loss: 1.4777 - val_main_output_loss: 1.0081 - val_aux_output_loss: 5.7040\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 798us/step - loss: 1.1600 - main_output_loss: 0.8443 - aux_output_loss: 4.0007 - val_loss: 1.2099 - val_main_output_loss: 0.7179 - val_aux_output_loss: 5.6381\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 821us/step - loss: 0.8851 - main_output_loss: 0.6901 - aux_output_loss: 2.6404 - val_loss: 1.2294 - val_main_output_loss: 0.6687 - val_aux_output_loss: 6.2754\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 745us/step - loss: 0.7693 - main_output_loss: 0.6291 - aux_output_loss: 2.0306 - val_loss: 1.2148 - val_main_output_loss: 0.6180 - val_aux_output_loss: 6.5862\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 804us/step - loss: 0.7095 - main_output_loss: 0.5926 - aux_output_loss: 1.7624 - val_loss: 1.1378 - val_main_output_loss: 0.5405 - val_aux_output_loss: 6.5131\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 770us/step - loss: 0.6699 - main_output_loss: 0.5628 - aux_output_loss: 1.6334 - val_loss: 1.0507 - val_main_output_loss: 0.5186 - val_aux_output_loss: 5.8391\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 771us/step - loss: 0.6408 - main_output_loss: 0.5396 - aux_output_loss: 1.5515 - val_loss: 0.9624 - val_main_output_loss: 0.5047 - val_aux_output_loss: 5.0818\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 800us/step - loss: 0.6177 - main_output_loss: 0.5207 - aux_output_loss: 1.4905 - val_loss: 0.8746 - val_main_output_loss: 0.4854 - val_aux_output_loss: 4.3773\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 757us/step - loss: 0.5983 - main_output_loss: 0.5048 - aux_output_loss: 1.4406 - val_loss: 0.7978 - val_main_output_loss: 0.4676 - val_aux_output_loss: 3.7694\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 782us/step - loss: 0.5818 - main_output_loss: 0.4912 - aux_output_loss: 1.3973 - val_loss: 0.7320 - val_main_output_loss: 0.4546 - val_aux_output_loss: 3.2285\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 762us/step - loss: 0.5679 - main_output_loss: 0.4801 - aux_output_loss: 1.3581 - val_loss: 0.6995 - val_main_output_loss: 0.4576 - val_aux_output_loss: 2.8767\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 792us/step - loss: 0.5556 - main_output_loss: 0.4702 - aux_output_loss: 1.3241 - val_loss: 0.6433 - val_main_output_loss: 0.4416 - val_aux_output_loss: 2.4585\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 751us/step - loss: 0.5453 - main_output_loss: 0.4624 - aux_output_loss: 1.2911 - val_loss: 0.6005 - val_main_output_loss: 0.4308 - val_aux_output_loss: 2.1276\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 773us/step - loss: 0.5361 - main_output_loss: 0.4556 - aux_output_loss: 1.2605 - val_loss: 0.5793 - val_main_output_loss: 0.4340 - val_aux_output_loss: 1.8866\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 801us/step - loss: 0.5283 - main_output_loss: 0.4502 - aux_output_loss: 1.2319 - val_loss: 0.5599 - val_main_output_loss: 0.4362 - val_aux_output_loss: 1.6736\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 777us/step - loss: 0.5216 - main_output_loss: 0.4456 - aux_output_loss: 1.2062 - val_loss: 0.5332 - val_main_output_loss: 0.4265 - val_aux_output_loss: 1.4936\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 784us/step - loss: 0.5158 - main_output_loss: 0.4419 - aux_output_loss: 1.1811 - val_loss: 0.5204 - val_main_output_loss: 0.4273 - val_aux_output_loss: 1.3582\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 794us/step - loss: 0.5105 - main_output_loss: 0.4386 - aux_output_loss: 1.1574 - val_loss: 0.5172 - val_main_output_loss: 0.4344 - val_aux_output_loss: 1.2627\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 775us/step - loss: 0.5056 - main_output_loss: 0.4356 - aux_output_loss: 1.1359 - val_loss: 0.5020 - val_main_output_loss: 0.4267 - val_aux_output_loss: 1.1797\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 822us/step - loss: 0.5015 - main_output_loss: 0.4334 - aux_output_loss: 1.1145 - val_loss: 0.4970 - val_main_output_loss: 0.4274 - val_aux_output_loss: 1.1235\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
    "                    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 518us/step - loss: 0.4903 - main_output_loss: 0.4249 - aux_output_loss: 1.0787\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate(\n",
    "    [X_test_A, X_test_B], [y_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 Subclassing API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.models.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs) #處理標準引數\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "\n",
    "model = WideAndDeepModel(30, activation=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 0s 974us/step - loss: 2.2290 - output_1_loss: 2.0371 - output_2_loss: 3.9567 - val_loss: 2.1687 - val_output_1_loss: 1.7081 - val_output_2_loss: 6.3140\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 768us/step - loss: 0.9827 - output_1_loss: 0.8065 - output_2_loss: 2.5685 - val_loss: 1.2188 - val_output_1_loss: 0.6999 - val_output_2_loss: 5.8887\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 774us/step - loss: 0.8243 - output_1_loss: 0.6932 - output_2_loss: 2.0047 - val_loss: 1.1507 - val_output_1_loss: 0.6351 - val_output_2_loss: 5.7918\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 827us/step - loss: 0.7574 - output_1_loss: 0.6458 - output_2_loss: 1.7616 - val_loss: 1.0530 - val_output_1_loss: 0.5935 - val_output_2_loss: 5.1885\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 770us/step - loss: 0.7142 - output_1_loss: 0.6128 - output_2_loss: 1.6270 - val_loss: 0.9705 - val_output_1_loss: 0.5775 - val_output_2_loss: 4.5081\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 792us/step - loss: 0.6813 - output_1_loss: 0.5865 - output_2_loss: 1.5341 - val_loss: 0.8892 - val_output_1_loss: 0.5355 - val_output_2_loss: 4.0719\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 836us/step - loss: 0.6530 - output_1_loss: 0.5631 - output_2_loss: 1.4621 - val_loss: 0.8241 - val_output_1_loss: 0.5151 - val_output_2_loss: 3.6051\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 790us/step - loss: 0.6288 - output_1_loss: 0.5432 - output_2_loss: 1.3997 - val_loss: 0.7655 - val_output_1_loss: 0.4976 - val_output_2_loss: 3.1764\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 798us/step - loss: 0.6075 - output_1_loss: 0.5257 - output_2_loss: 1.3432 - val_loss: 0.7130 - val_output_1_loss: 0.4776 - val_output_2_loss: 2.8321\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 760us/step - loss: 0.5892 - output_1_loss: 0.5107 - output_2_loss: 1.2964 - val_loss: 0.6682 - val_output_1_loss: 0.4634 - val_output_2_loss: 2.5106\n",
      "162/162 [==============================] - 0s 510us/step - loss: 0.5707 - output_1_loss: 0.4944 - output_2_loss: 1.2569\n",
      "WARNING:tensorflow:5 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f5505d38598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit((X_train_A, X_train_B), (y_train, y_train), epochs=10,\n",
    "                    validation_data=((X_valid_A, X_valid_B), (y_valid, y_valid)))\n",
    "total_loss, main_loss, aux_loss = model.evaluate((X_test_A, X_test_B), (y_test, y_test))\n",
    "y_pred_main, y_pred_aux = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "儲存模型與調用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 0s 736us/step - loss: 1.9915 - val_loss: 0.9594\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 582us/step - loss: 0.7963 - val_loss: 0.7183\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 607us/step - loss: 0.6839 - val_loss: 0.6595\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 616us/step - loss: 0.6287 - val_loss: 0.6033\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 594us/step - loss: 0.5882 - val_loss: 0.5756\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 620us/step - loss: 0.5562 - val_loss: 0.5818\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 652us/step - loss: 0.5303 - val_loss: 0.5012\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 615us/step - loss: 0.5101 - val_loss: 0.5648\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 622us/step - loss: 0.4925 - val_loss: 0.4788\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 595us/step - loss: 0.4779 - val_loss: 0.5190\n",
      "162/162 [==============================] - 0s 298us/step - loss: 0.4632\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f56481247b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.5601214],\n",
       "       [1.5411216],\n",
       "       [3.015672 ]], dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"my_keras_weights.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f56480ce278>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"my_keras_weights.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 0s 740us/step - loss: 2.2434 - val_loss: 1.3414\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 620us/step - loss: 0.8465 - val_loss: 0.7230\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 613us/step - loss: 0.6993 - val_loss: 0.6616\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 598us/step - loss: 0.6442 - val_loss: 0.6751\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 619us/step - loss: 0.6076 - val_loss: 0.5685\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 629us/step - loss: 0.5764 - val_loss: 0.5439\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 564us/step - loss: 0.5500 - val_loss: 0.5251\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 614us/step - loss: 0.5268 - val_loss: 0.4934\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 609us/step - loss: 0.5069 - val_loss: 0.4705\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 612us/step - loss: 0.4894 - val_loss: 0.4530\n"
     ]
    }
   ],
   "source": [
    "#儲存驗證後最好的模型\n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 365us/step - loss: 0.4758\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.h5\") \n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#提前停止訓練\n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                  restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 0s 749us/step - loss: 0.4745 - val_loss: 0.4491\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 644us/step - loss: 0.4613 - val_loss: 0.4374\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 592us/step - loss: 0.4507 - val_loss: 0.4214\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 657us/step - loss: 0.4417 - val_loss: 0.4138\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 584us/step - loss: 0.4338 - val_loss: 0.4177\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 596us/step - loss: 0.4274 - val_loss: 0.4190\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 600us/step - loss: 0.4217 - val_loss: 0.4181\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 605us/step - loss: 0.4170 - val_loss: 0.4079\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 595us/step - loss: 0.4125 - val_loss: 0.4239\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 562us/step - loss: 0.4086 - val_loss: 0.4230\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 558us/step - loss: 0.4058 - val_loss: 0.4189\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 602us/step - loss: 0.4026 - val_loss: 0.4048\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 591us/step - loss: 0.3997 - val_loss: 0.4357\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 585us/step - loss: 0.3975 - val_loss: 0.4152\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 584us/step - loss: 0.3952 - val_loss: 0.4423\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 577us/step - loss: 0.3934 - val_loss: 0.4216\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 604us/step - loss: 0.3915 - val_loss: 0.4002\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 581us/step - loss: 0.3897 - val_loss: 0.4247\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 626us/step - loss: 0.3882 - val_loss: 0.3817\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 632us/step - loss: 0.3867 - val_loss: 0.3817\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 597us/step - loss: 0.3851 - val_loss: 0.3785\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 624us/step - loss: 0.3835 - val_loss: 0.4176\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 603us/step - loss: 0.3823 - val_loss: 0.3751\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 600us/step - loss: 0.3809 - val_loss: 0.4058\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 600us/step - loss: 0.3800 - val_loss: 0.3846\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 628us/step - loss: 0.3785 - val_loss: 0.3685\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 590us/step - loss: 0.3777 - val_loss: 0.3877\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 573us/step - loss: 0.3762 - val_loss: 0.3736\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 583us/step - loss: 0.3756 - val_loss: 0.3913\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 607us/step - loss: 0.3744 - val_loss: 0.4033\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 589us/step - loss: 0.3736 - val_loss: 0.3785\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 590us/step - loss: 0.3727 - val_loss: 0.3819\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 621us/step - loss: 0.3717 - val_loss: 0.3651\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 615us/step - loss: 0.3710 - val_loss: 0.3634\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 608us/step - loss: 0.3701 - val_loss: 0.3998\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 618us/step - loss: 0.3692 - val_loss: 0.3886\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 599us/step - loss: 0.3685 - val_loss: 0.3643\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 573us/step - loss: 0.3683 - val_loss: 0.3768\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 562us/step - loss: 0.3675 - val_loss: 0.3696\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 569us/step - loss: 0.3668 - val_loss: 0.3898\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 612us/step - loss: 0.3660 - val_loss: 0.3707\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 578us/step - loss: 0.3655 - val_loss: 0.3993\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 593us/step - loss: 0.3650 - val_loss: 0.3983\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 585us/step - loss: 0.3647 - val_loss: 0.4011\n",
      "162/162 [==============================] - 0s 270us/step - loss: 0.3697\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#自己定義\n",
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "328/363 [==========================>...] - ETA: 0s - loss: 0.3690\n",
      "val/train: 1.04\n",
      "363/363 [==============================] - 0s 622us/step - loss: 0.3700 - val_loss: 0.3849\n",
      "Epoch 2/5\n",
      "321/363 [=========================>....] - ETA: 0s - loss: 0.3678\n",
      "val/train: 1.04\n",
      "363/363 [==============================] - 0s 606us/step - loss: 0.3694 - val_loss: 0.3826\n",
      "Epoch 3/5\n",
      "333/363 [==========================>...] - ETA: 0s - loss: 0.3665\n",
      "val/train: 0.98\n",
      "363/363 [==============================] - 0s 583us/step - loss: 0.3689 - val_loss: 0.3607\n",
      "Epoch 4/5\n",
      "337/363 [==========================>...] - ETA: 0s - loss: 0.3673\n",
      "val/train: 1.09\n",
      "363/363 [==============================] - 0s 610us/step - loss: 0.3682 - val_loss: 0.4008\n",
      "Epoch 5/5\n",
      "322/363 [=========================>....] - ETA: 0s - loss: 0.3705\n",
      "val/train: 1.03\n",
      "363/363 [==============================] - 0s 587us/step - loss: 0.3675 - val_loss: 0.3788\n"
     ]
    }
   ],
   "source": [
    "val_train_ratio_cb = PrintValTrainRatioCallback()\n",
    "history = model.fit(X_train, y_train, epochs=5,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[val_train_ratio_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#根據時間產生目錄\n",
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\") #os.curdir -> 取得當前路徑\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  1/363 [..............................] - ETA: 0s - loss: 6.4649 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_train_batch_end` time: 0.0219s). Check your callbacks.\n",
      "363/363 [==============================] - 0s 876us/step - loss: 1.8601 - accuracy: 0.0025 - val_loss: 2.2697 - val_accuracy: 0.0044\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 672us/step - loss: 0.7190 - accuracy: 0.0029 - val_loss: 0.6453 - val_accuracy: 0.0044\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 656us/step - loss: 0.6270 - accuracy: 0.0029 - val_loss: 0.6093 - val_accuracy: 0.0044\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 651us/step - loss: 0.5811 - accuracy: 0.0029 - val_loss: 0.5574 - val_accuracy: 0.0044\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 659us/step - loss: 0.5474 - accuracy: 0.0029 - val_loss: 0.5198 - val_accuracy: 0.0044\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 622us/step - loss: 0.5214 - accuracy: 0.0029 - val_loss: 0.5006 - val_accuracy: 0.0044\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 641us/step - loss: 0.5005 - accuracy: 0.0029 - val_loss: 0.4717 - val_accuracy: 0.0044\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 628us/step - loss: 0.4832 - accuracy: 0.0029 - val_loss: 0.4588 - val_accuracy: 0.0044\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 599us/step - loss: 0.4692 - accuracy: 0.0029 - val_loss: 0.4451 - val_accuracy: 0.0044\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 651us/step - loss: 0.4571 - accuracy: 0.0029 - val_loss: 0.4263 - val_accuracy: 0.0044\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 628us/step - loss: 0.4468 - accuracy: 0.0029 - val_loss: 0.4162 - val_accuracy: 0.0044\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 636us/step - loss: 0.4380 - accuracy: 0.0029 - val_loss: 0.4081 - val_accuracy: 0.0044\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 642us/step - loss: 0.4307 - accuracy: 0.0029 - val_loss: 0.4000 - val_accuracy: 0.0044\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 603us/step - loss: 0.4246 - accuracy: 0.0029 - val_loss: 0.3935 - val_accuracy: 0.0044\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 643us/step - loss: 0.4193 - accuracy: 0.0029 - val_loss: 0.3878 - val_accuracy: 0.0044\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 665us/step - loss: 0.4141 - accuracy: 0.0029 - val_loss: 0.3845 - val_accuracy: 0.0044\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 669us/step - loss: 0.4093 - accuracy: 0.0029 - val_loss: 0.3807 - val_accuracy: 0.0044\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 644us/step - loss: 0.4057 - accuracy: 0.0029 - val_loss: 0.3786 - val_accuracy: 0.0044\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 647us/step - loss: 0.4024 - accuracy: 0.0029 - val_loss: 0.3794 - val_accuracy: 0.0044\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 637us/step - loss: 0.3991 - accuracy: 0.0029 - val_loss: 0.3760 - val_accuracy: 0.0044\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 638us/step - loss: 0.3966 - accuracy: 0.0029 - val_loss: 0.3758 - val_accuracy: 0.0044\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 660us/step - loss: 0.3935 - accuracy: 0.0029 - val_loss: 0.3723 - val_accuracy: 0.0044\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 671us/step - loss: 0.3909 - accuracy: 0.0029 - val_loss: 0.3713 - val_accuracy: 0.0044\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 615us/step - loss: 0.3886 - accuracy: 0.0029 - val_loss: 0.3727 - val_accuracy: 0.0044\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 624us/step - loss: 0.3863 - accuracy: 0.0029 - val_loss: 0.3725 - val_accuracy: 0.0044\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 670us/step - loss: 0.3844 - accuracy: 0.0029 - val_loss: 0.3665 - val_accuracy: 0.0044\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 662us/step - loss: 0.3820 - accuracy: 0.0029 - val_loss: 0.3689 - val_accuracy: 0.0044\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 643us/step - loss: 0.3804 - accuracy: 0.0029 - val_loss: 0.3657 - val_accuracy: 0.0044\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 657us/step - loss: 0.3785 - accuracy: 0.0029 - val_loss: 0.3699 - val_accuracy: 0.0044\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 655us/step - loss: 0.3771 - accuracy: 0.0029 - val_loss: 0.3636 - val_accuracy: 0.0044\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cd = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[tensorboard_cd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 7347), started 0:04:17 ago. (Use '!kill 7347' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9124e66809551e26\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9124e66809551e26\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_logdir = get_run_logdir()\n",
    "writer = tf.summary.create_file_writer(test_logdir)\n",
    "with writer.as_default():\n",
    "    for step in range(1,1000 + 1):\n",
    "        tf.summary.scalar(\"my_scalar\", np.sin(step / 10), step=step)\n",
    "        data = (np.random.randn(100) + 2) * step / 100\n",
    "        tf.summary.histogram(\"my_hist\", data, buckets=50, step=step)\n",
    "        images = np.random.randn(2, 32, 32, 3)\n",
    "        tf.summary.image(\"my_image\", images * step / 1000, step=step)\n",
    "        texts = [\"The step is \" + str(step), \"Its square is \" + str(step**2)]\n",
    "        tf.summary.text(\"my_text\", texts, step=step)\n",
    "        sine_wave = tf.math.sin(tf.range(12000) / 48000 * 2 * np.pi * step)\n",
    "        audio = tf.reshape(tf.cast(sine_wave, tf.float32), [1, -1, 1])\n",
    "        tf.summary.audio(\"my_audio\", audio, sample_rate=48000, step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 7347), started 1:16:20 ago. (Use '!kill 7347' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-fc13283794039988\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-fc13283794039988\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "微調神經網路超參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用於實踐sklearn回歸接口\n",
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 0s 663us/step - loss: 1.3293 - val_loss: 33.4581\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 564us/step - loss: 0.9855 - val_loss: 23.5270\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 579us/step - loss: 0.8313 - val_loss: 0.5811\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 565us/step - loss: 0.5868 - val_loss: 0.5302\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 536us/step - loss: 0.5348 - val_loss: 0.4950\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 556us/step - loss: 0.4942 - val_loss: 0.4687\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 534us/step - loss: 0.4672 - val_loss: 0.4331\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 559us/step - loss: 0.4498 - val_loss: 0.4154\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 526us/step - loss: 0.4382 - val_loss: 0.4095\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 575us/step - loss: 0.4296 - val_loss: 0.4034\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 560us/step - loss: 0.4230 - val_loss: 0.3971\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 571us/step - loss: 0.4180 - val_loss: 0.3914\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 547us/step - loss: 0.4137 - val_loss: 0.3951\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 559us/step - loss: 0.4102 - val_loss: 0.3856\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 534us/step - loss: 0.4077 - val_loss: 0.3803\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 590us/step - loss: 0.4046 - val_loss: 0.3949\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 567us/step - loss: 0.4021 - val_loss: 0.3850\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 576us/step - loss: 0.4001 - val_loss: 0.3821\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 561us/step - loss: 0.3974 - val_loss: 0.3748\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 570us/step - loss: 0.3959 - val_loss: 0.3756\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 532us/step - loss: 0.3946 - val_loss: 0.3732\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 551us/step - loss: 0.3929 - val_loss: 0.3760\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 556us/step - loss: 0.3913 - val_loss: 0.3699\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 569us/step - loss: 0.3901 - val_loss: 0.3677\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 583us/step - loss: 0.3888 - val_loss: 0.3755\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 524us/step - loss: 0.3878 - val_loss: 0.3644\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 520us/step - loss: 0.3863 - val_loss: 0.3625\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 565us/step - loss: 0.3851 - val_loss: 0.3739\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 528us/step - loss: 0.3844 - val_loss: 0.3657\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 547us/step - loss: 0.3831 - val_loss: 0.3701\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 606us/step - loss: 0.3823 - val_loss: 0.3618\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 602us/step - loss: 0.3811 - val_loss: 0.3680\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 594us/step - loss: 0.3802 - val_loss: 0.3585\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 588us/step - loss: 0.3787 - val_loss: 0.3717\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 557us/step - loss: 0.3780 - val_loss: 0.3585\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 579us/step - loss: 0.3772 - val_loss: 0.3556\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 603us/step - loss: 0.3760 - val_loss: 0.3539\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 591us/step - loss: 0.3753 - val_loss: 0.3532\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 580us/step - loss: 0.3744 - val_loss: 0.3711\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 588us/step - loss: 0.3736 - val_loss: 0.3525\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 584us/step - loss: 0.3725 - val_loss: 0.3633\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 569us/step - loss: 0.3718 - val_loss: 0.3522\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 559us/step - loss: 0.3708 - val_loss: 0.3707\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 541us/step - loss: 0.3708 - val_loss: 0.3972\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 571us/step - loss: 0.3695 - val_loss: 0.3553\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 562us/step - loss: 0.3686 - val_loss: 0.3611\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 548us/step - loss: 0.3681 - val_loss: 0.3673\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 564us/step - loss: 0.3673 - val_loss: 0.4045\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 598us/step - loss: 0.3681 - val_loss: 0.3572\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 631us/step - loss: 0.3662 - val_loss: 0.3813\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 568us/step - loss: 0.3654 - val_loss: 0.4076\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 569us/step - loss: 0.3662 - val_loss: 0.5985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f56c480c588>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100,\n",
    "              validation_data=(X_valid, y_valid),\n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 363us/step - loss: 0.3669\n"
     ]
    }
   ],
   "source": [
    "mse_test = keras_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] learning_rate=0.0055152207481209145, n_hidden=3, n_neurons=64 ...\n",
      "Epoch 1/50\n",
      "\r",
      "  1/242 [..............................] - ETA: 0s - loss: 4.8687"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 947us/step - loss: 1.2131 - val_loss: 0.5133\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 719us/step - loss: 0.4964 - val_loss: 0.7087\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 751us/step - loss: 0.4375 - val_loss: 1.7544\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.4221 - val_loss: 5.2576\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.4605 - val_loss: 1.3208\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 694us/step - loss: 0.3904 - val_loss: 0.4635\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 0s 737us/step - loss: 0.3645 - val_loss: 0.3785\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - 0s 751us/step - loss: 0.3562 - val_loss: 0.3390\n",
      "Epoch 9/50\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.3499 - val_loss: 0.3431\n",
      "Epoch 10/50\n",
      "242/242 [==============================] - 0s 723us/step - loss: 0.3468 - val_loss: 0.3520\n",
      "Epoch 11/50\n",
      "242/242 [==============================] - 0s 763us/step - loss: 0.3411 - val_loss: 0.3552\n",
      "Epoch 12/50\n",
      "242/242 [==============================] - 0s 777us/step - loss: 0.3377 - val_loss: 0.3336\n",
      "Epoch 13/50\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.3354 - val_loss: 0.3486\n",
      "Epoch 14/50\n",
      "242/242 [==============================] - 0s 736us/step - loss: 0.3337 - val_loss: 0.3576\n",
      "Epoch 15/50\n",
      "242/242 [==============================] - 0s 741us/step - loss: 0.3301 - val_loss: 0.3583\n",
      "Epoch 16/50\n",
      "242/242 [==============================] - 0s 715us/step - loss: 0.3269 - val_loss: 0.3608\n",
      "Epoch 17/50\n",
      "242/242 [==============================] - 0s 731us/step - loss: 0.3255 - val_loss: 0.3290\n",
      "Epoch 18/50\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.3241 - val_loss: 0.3576\n",
      "Epoch 19/50\n",
      "242/242 [==============================] - 0s 748us/step - loss: 0.3205 - val_loss: 0.3582\n",
      "Epoch 20/50\n",
      "242/242 [==============================] - 0s 737us/step - loss: 0.3197 - val_loss: 0.3329\n",
      "Epoch 21/50\n",
      "242/242 [==============================] - 0s 728us/step - loss: 0.3161 - val_loss: 0.3395\n",
      "Epoch 22/50\n",
      "242/242 [==============================] - 0s 727us/step - loss: 0.3158 - val_loss: 0.3647\n",
      "Epoch 23/50\n",
      "242/242 [==============================] - 0s 715us/step - loss: 0.3135 - val_loss: 0.3071\n",
      "Epoch 24/50\n",
      "242/242 [==============================] - 0s 747us/step - loss: 0.3121 - val_loss: 0.3157\n",
      "Epoch 25/50\n",
      "242/242 [==============================] - 0s 728us/step - loss: 0.3095 - val_loss: 0.3467\n",
      "Epoch 26/50\n",
      "242/242 [==============================] - 0s 730us/step - loss: 0.3089 - val_loss: 0.3308\n",
      "Epoch 27/50\n",
      "242/242 [==============================] - 0s 727us/step - loss: 0.3066 - val_loss: 0.3197\n",
      "Epoch 28/50\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.3044 - val_loss: 0.3553\n",
      "Epoch 29/50\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.3024 - val_loss: 0.3019\n",
      "Epoch 30/50\n",
      "242/242 [==============================] - 0s 770us/step - loss: 0.3010 - val_loss: 0.3379\n",
      "Epoch 31/50\n",
      "242/242 [==============================] - 0s 733us/step - loss: 0.3006 - val_loss: 0.3006\n",
      "Epoch 32/50\n",
      "242/242 [==============================] - 0s 769us/step - loss: 0.3001 - val_loss: 0.3286\n",
      "Epoch 33/50\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.2983 - val_loss: 0.2954\n",
      "Epoch 34/50\n",
      "242/242 [==============================] - 0s 706us/step - loss: 0.2979 - val_loss: 0.3226\n",
      "Epoch 35/50\n",
      "242/242 [==============================] - 0s 756us/step - loss: 0.2951 - val_loss: 0.3042\n",
      "Epoch 36/50\n",
      "242/242 [==============================] - 0s 686us/step - loss: 0.2937 - val_loss: 0.3146\n",
      "Epoch 37/50\n",
      "242/242 [==============================] - 0s 737us/step - loss: 0.2931 - val_loss: 0.3026\n",
      "Epoch 38/50\n",
      "242/242 [==============================] - 0s 722us/step - loss: 0.2910 - val_loss: 0.3100\n",
      "Epoch 39/50\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.2899 - val_loss: 0.3093\n",
      "Epoch 40/50\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.2887 - val_loss: 0.3001\n",
      "Epoch 41/50\n",
      "242/242 [==============================] - 0s 763us/step - loss: 0.2893 - val_loss: 0.3065\n",
      "Epoch 42/50\n",
      "242/242 [==============================] - 0s 708us/step - loss: 0.2874 - val_loss: 0.3438\n",
      "Epoch 43/50\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.2863 - val_loss: 0.2906\n",
      "Epoch 44/50\n",
      "242/242 [==============================] - 0s 732us/step - loss: 0.2841 - val_loss: 0.2854\n",
      "Epoch 45/50\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.2829 - val_loss: 0.2937\n",
      "Epoch 46/50\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.2822 - val_loss: 0.2965\n",
      "Epoch 47/50\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.2833 - val_loss: 0.3345\n",
      "Epoch 48/50\n",
      "242/242 [==============================] - 0s 680us/step - loss: 0.2787 - val_loss: 0.2919\n",
      "Epoch 49/50\n",
      "242/242 [==============================] - 0s 747us/step - loss: 0.2792 - val_loss: 0.3106\n",
      "Epoch 50/50\n",
      "242/242 [==============================] - 0s 697us/step - loss: 0.2782 - val_loss: 0.3108\n",
      "121/121 [==============================] - 0s 364us/step - loss: 0.3158\n",
      "[CV]  learning_rate=0.0055152207481209145, n_hidden=3, n_neurons=64, total=   9.3s\n",
      "[CV] learning_rate=0.0055152207481209145, n_hidden=3, n_neurons=64 ...\n",
      "Epoch 1/50\n",
      "  1/242 [..............................] - ETA: 0s - loss: 6.4546"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 947us/step - loss: 0.9955 - val_loss: 1.2136\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 775us/step - loss: 0.5459 - val_loss: 0.4548\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.4490 - val_loss: 0.4267\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 752us/step - loss: 0.4092 - val_loss: 0.3685\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 763us/step - loss: 0.3903 - val_loss: 0.5466\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 736us/step - loss: 0.3788 - val_loss: 0.6541\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 0s 737us/step - loss: 0.3704 - val_loss: 0.9117\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.3640 - val_loss: 0.9674\n",
      "Epoch 9/50\n",
      "242/242 [==============================] - 0s 775us/step - loss: 0.3587 - val_loss: 0.8596\n",
      "Epoch 10/50\n",
      "242/242 [==============================] - 0s 739us/step - loss: 0.3535 - val_loss: 1.1059\n",
      "Epoch 11/50\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.3493 - val_loss: 1.0328\n",
      "Epoch 12/50\n",
      "242/242 [==============================] - 0s 739us/step - loss: 0.3450 - val_loss: 0.8285\n",
      "Epoch 13/50\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.3423 - val_loss: 0.8920\n",
      "Epoch 14/50\n",
      "242/242 [==============================] - 0s 724us/step - loss: 0.3384 - val_loss: 0.8312\n",
      "Epoch 15/50\n",
      "242/242 [==============================] - 0s 722us/step - loss: 0.3353 - val_loss: 0.7314\n",
      "Epoch 16/50\n",
      "242/242 [==============================] - 0s 732us/step - loss: 0.3325 - val_loss: 0.6444\n",
      "Epoch 17/50\n",
      "242/242 [==============================] - 0s 711us/step - loss: 0.3298 - val_loss: 0.7013\n",
      "Epoch 18/50\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.3291 - val_loss: 0.6111\n",
      "Epoch 19/50\n",
      "242/242 [==============================] - 0s 728us/step - loss: 0.3248 - val_loss: 0.5834\n",
      "Epoch 20/50\n",
      "242/242 [==============================] - 0s 720us/step - loss: 0.3235 - val_loss: 0.6586\n",
      "Epoch 21/50\n",
      "242/242 [==============================] - 0s 732us/step - loss: 0.3227 - val_loss: 0.8164\n",
      "Epoch 22/50\n",
      "242/242 [==============================] - 0s 756us/step - loss: 0.3199 - val_loss: 0.7848\n",
      "Epoch 23/50\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.3177 - val_loss: 0.6294\n",
      "Epoch 24/50\n",
      "242/242 [==============================] - 0s 691us/step - loss: 0.3164 - val_loss: 0.5623\n",
      "Epoch 25/50\n",
      "242/242 [==============================] - 0s 706us/step - loss: 0.3152 - val_loss: 0.6951\n",
      "Epoch 26/50\n",
      "242/242 [==============================] - 0s 817us/step - loss: 0.3122 - val_loss: 0.5221\n",
      "Epoch 27/50\n",
      "242/242 [==============================] - 0s 760us/step - loss: 0.3112 - val_loss: 0.5935\n",
      "Epoch 28/50\n",
      "242/242 [==============================] - 0s 763us/step - loss: 0.3100 - val_loss: 0.4287\n",
      "Epoch 29/50\n",
      "242/242 [==============================] - 0s 726us/step - loss: 0.3083 - val_loss: 0.5203\n",
      "Epoch 30/50\n",
      "242/242 [==============================] - 0s 745us/step - loss: 0.3058 - val_loss: 0.3605\n",
      "Epoch 31/50\n",
      "242/242 [==============================] - 0s 730us/step - loss: 0.3056 - val_loss: 0.5157\n",
      "Epoch 32/50\n",
      "242/242 [==============================] - 0s 743us/step - loss: 0.3024 - val_loss: 0.5381\n",
      "Epoch 33/50\n",
      "242/242 [==============================] - 0s 703us/step - loss: 0.3020 - val_loss: 0.5180\n",
      "Epoch 34/50\n",
      "242/242 [==============================] - 0s 745us/step - loss: 0.2996 - val_loss: 0.5296\n",
      "Epoch 35/50\n",
      "242/242 [==============================] - 0s 740us/step - loss: 0.2986 - val_loss: 0.5551\n",
      "Epoch 36/50\n",
      "242/242 [==============================] - 0s 697us/step - loss: 0.2965 - val_loss: 0.6705\n",
      "Epoch 37/50\n",
      "242/242 [==============================] - 0s 697us/step - loss: 0.2961 - val_loss: 0.4956\n",
      "Epoch 38/50\n",
      "242/242 [==============================] - 0s 710us/step - loss: 0.2929 - val_loss: 0.5662\n",
      "Epoch 39/50\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.2914 - val_loss: 0.4331\n",
      "Epoch 40/50\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.2922 - val_loss: 0.5157\n",
      "Epoch 41/50\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.2893 - val_loss: 0.5002\n",
      "Epoch 42/50\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.2884 - val_loss: 0.8583\n",
      "Epoch 43/50\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.2896 - val_loss: 0.5088\n",
      "Epoch 44/50\n",
      "242/242 [==============================] - 0s 695us/step - loss: 0.2866 - val_loss: 0.3460\n",
      "Epoch 45/50\n",
      "242/242 [==============================] - 0s 749us/step - loss: 0.2867 - val_loss: 0.5097\n",
      "Epoch 46/50\n",
      "242/242 [==============================] - 0s 714us/step - loss: 0.2846 - val_loss: 0.5684\n",
      "Epoch 47/50\n",
      "242/242 [==============================] - 0s 702us/step - loss: 0.2825 - val_loss: 0.3473\n",
      "Epoch 48/50\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.2836 - val_loss: 0.5642\n",
      "Epoch 49/50\n",
      "242/242 [==============================] - 0s 719us/step - loss: 0.2819 - val_loss: 0.5092\n",
      "Epoch 50/50\n",
      "242/242 [==============================] - 0s 761us/step - loss: 0.2811 - val_loss: 0.4819\n",
      "121/121 [==============================] - 0s 358us/step - loss: 0.3109\n",
      "[CV]  learning_rate=0.0055152207481209145, n_hidden=3, n_neurons=64, total=   9.2s\n",
      "[CV] learning_rate=0.0055152207481209145, n_hidden=3, n_neurons=64 ...\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 925us/step - loss: 0.9419 - val_loss: 0.5978\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 780us/step - loss: 0.5185 - val_loss: 0.6830\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 766us/step - loss: 0.4424 - val_loss: 0.4043\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.4066 - val_loss: 0.3735\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.3882 - val_loss: 0.5562\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 711us/step - loss: 0.3809 - val_loss: 0.3487\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 0s 719us/step - loss: 0.3694 - val_loss: 0.3849\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - 0s 733us/step - loss: 0.3616 - val_loss: 0.3620\n",
      "Epoch 9/50\n",
      "242/242 [==============================] - 0s 728us/step - loss: 0.3544 - val_loss: 0.5430\n",
      "Epoch 10/50\n",
      "242/242 [==============================] - 0s 781us/step - loss: 0.3546 - val_loss: 0.4696\n",
      "Epoch 11/50\n",
      "242/242 [==============================] - 0s 775us/step - loss: 0.3493 - val_loss: 0.3998\n",
      "Epoch 12/50\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.3436 - val_loss: 0.3267\n",
      "Epoch 13/50\n",
      "242/242 [==============================] - 0s 715us/step - loss: 0.3415 - val_loss: 0.3247\n",
      "Epoch 14/50\n",
      "242/242 [==============================] - 0s 694us/step - loss: 0.3361 - val_loss: 0.3592\n",
      "Epoch 15/50\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.3348 - val_loss: 0.3522\n",
      "Epoch 16/50\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.3327 - val_loss: 0.3333\n",
      "Epoch 17/50\n",
      "242/242 [==============================] - 0s 693us/step - loss: 0.3283 - val_loss: 0.5441\n",
      "Epoch 18/50\n",
      "242/242 [==============================] - 0s 740us/step - loss: 0.3308 - val_loss: 0.3999\n",
      "Epoch 19/50\n",
      "242/242 [==============================] - 0s 700us/step - loss: 0.3257 - val_loss: 0.5568\n",
      "Epoch 20/50\n",
      "242/242 [==============================] - 0s 743us/step - loss: 0.3275 - val_loss: 0.3606\n",
      "Epoch 21/50\n",
      "242/242 [==============================] - 0s 733us/step - loss: 0.3206 - val_loss: 0.3364\n",
      "Epoch 22/50\n",
      "242/242 [==============================] - 0s 744us/step - loss: 0.3175 - val_loss: 0.4201\n",
      "Epoch 23/50\n",
      "242/242 [==============================] - 0s 694us/step - loss: 0.3170 - val_loss: 0.3092\n",
      "Epoch 24/50\n",
      "242/242 [==============================] - 0s 726us/step - loss: 0.3134 - val_loss: 0.5337\n",
      "Epoch 25/50\n",
      "242/242 [==============================] - 0s 715us/step - loss: 0.3167 - val_loss: 0.3187\n",
      "Epoch 26/50\n",
      "242/242 [==============================] - 0s 747us/step - loss: 0.3102 - val_loss: 0.3918\n",
      "Epoch 27/50\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.3138 - val_loss: 0.3050\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 707us/step - loss: 0.3073 - val_loss: 0.3379\n",
      "Epoch 29/50\n",
      "242/242 [==============================] - 0s 719us/step - loss: 0.3074 - val_loss: 0.3515\n",
      "Epoch 30/50\n",
      "242/242 [==============================] - 0s 764us/step - loss: 0.3041 - val_loss: 0.3732\n",
      "Epoch 31/50\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.3038 - val_loss: 0.4783\n",
      "Epoch 32/50\n",
      "242/242 [==============================] - 0s 691us/step - loss: 0.3055 - val_loss: 0.3952\n",
      "Epoch 33/50\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.3029 - val_loss: 0.3015\n",
      "Epoch 34/50\n",
      "242/242 [==============================] - 0s 715us/step - loss: 0.2994 - val_loss: 0.3200\n",
      "Epoch 35/50\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.2976 - val_loss: 0.3285\n",
      "Epoch 36/50\n",
      "242/242 [==============================] - 0s 669us/step - loss: 0.3017 - val_loss: 0.3125\n",
      "Epoch 37/50\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.2959 - val_loss: 0.4055\n",
      "Epoch 38/50\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.2973 - val_loss: 0.3095\n",
      "Epoch 39/50\n",
      "242/242 [==============================] - 0s 733us/step - loss: 0.2949 - val_loss: 0.4107\n",
      "Epoch 40/50\n",
      "242/242 [==============================] - 0s 727us/step - loss: 0.2947 - val_loss: 0.4575\n",
      "Epoch 41/50\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.2940 - val_loss: 0.6227\n",
      "Epoch 42/50\n",
      "242/242 [==============================] - 0s 691us/step - loss: 0.2932 - val_loss: 0.3082\n",
      "Epoch 43/50\n",
      "242/242 [==============================] - 0s 728us/step - loss: 0.2899 - val_loss: 0.5423\n",
      "Epoch 44/50\n",
      "242/242 [==============================] - 0s 699us/step - loss: 0.2909 - val_loss: 0.3178\n",
      "Epoch 45/50\n",
      "242/242 [==============================] - 0s 722us/step - loss: 0.2869 - val_loss: 0.4987\n",
      "Epoch 46/50\n",
      "242/242 [==============================] - 0s 671us/step - loss: 0.2875 - val_loss: 0.3567\n",
      "Epoch 47/50\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.2852 - val_loss: 0.4928\n",
      "Epoch 48/50\n",
      "242/242 [==============================] - 0s 756us/step - loss: 0.2855 - val_loss: 0.2929\n",
      "Epoch 49/50\n",
      "242/242 [==============================] - 0s 665us/step - loss: 0.2853 - val_loss: 0.4301\n",
      "Epoch 50/50\n",
      "242/242 [==============================] - 0s 680us/step - loss: 0.2886 - val_loss: 0.3635\n",
      "121/121 [==============================] - 0s 349us/step - loss: 0.3102\n",
      "[CV]  learning_rate=0.0055152207481209145, n_hidden=3, n_neurons=64, total=   9.1s\n",
      "[CV] learning_rate=0.008072800877482553, n_hidden=1, n_neurons=21 ....\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 795us/step - loss: 1.2971 - val_loss: 36.7928\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.6618 - val_loss: 18.7254\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 689us/step - loss: 0.6490 - val_loss: 0.4066\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 652us/step - loss: 0.4318 - val_loss: 0.3923\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 630us/step - loss: 0.4194 - val_loss: 0.3818\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 627us/step - loss: 0.4110 - val_loss: 0.3748\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 0s 542us/step - loss: 0.4033 - val_loss: 0.3706\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - 0s 588us/step - loss: 0.3974 - val_loss: 0.3728\n",
      "Epoch 9/50\n",
      "242/242 [==============================] - 0s 652us/step - loss: 0.3925 - val_loss: 0.3633\n",
      "Epoch 10/50\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.3882 - val_loss: 0.3633\n",
      "Epoch 11/50\n",
      "242/242 [==============================] - 0s 593us/step - loss: 0.3859 - val_loss: 0.3653\n",
      "Epoch 12/50\n",
      "242/242 [==============================] - 0s 568us/step - loss: 0.3829 - val_loss: 0.3593\n",
      "Epoch 13/50\n",
      "242/242 [==============================] - 0s 622us/step - loss: 0.3807 - val_loss: 0.3582\n",
      "Epoch 14/50\n",
      "242/242 [==============================] - 0s 567us/step - loss: 0.3788 - val_loss: 0.3541\n",
      "Epoch 15/50\n",
      "242/242 [==============================] - 0s 583us/step - loss: 0.3756 - val_loss: 0.3534\n",
      "Epoch 16/50\n",
      "242/242 [==============================] - 0s 611us/step - loss: 0.3744 - val_loss: 0.3513\n",
      "Epoch 17/50\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.3726 - val_loss: 0.3561\n",
      "Epoch 18/50\n",
      "242/242 [==============================] - 0s 650us/step - loss: 0.3709 - val_loss: 0.3523\n",
      "Epoch 19/50\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.3689 - val_loss: 0.3478\n",
      "Epoch 20/50\n",
      "242/242 [==============================] - 0s 644us/step - loss: 0.3673 - val_loss: 0.3495\n",
      "Epoch 21/50\n",
      "242/242 [==============================] - 0s 636us/step - loss: 0.3662 - val_loss: 0.3481\n",
      "Epoch 22/50\n",
      "242/242 [==============================] - 0s 653us/step - loss: 0.3647 - val_loss: 0.3480\n",
      "Epoch 23/50\n",
      "242/242 [==============================] - 0s 617us/step - loss: 0.3629 - val_loss: 0.3447\n",
      "Epoch 24/50\n",
      "242/242 [==============================] - 0s 609us/step - loss: 0.3616 - val_loss: 0.3475\n",
      "Epoch 25/50\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.3615 - val_loss: 0.3457\n",
      "Epoch 26/50\n",
      "242/242 [==============================] - 0s 635us/step - loss: 0.3599 - val_loss: 0.3439\n",
      "Epoch 27/50\n",
      "242/242 [==============================] - 0s 624us/step - loss: 0.3587 - val_loss: 0.3430\n",
      "Epoch 28/50\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.3582 - val_loss: 0.3469\n",
      "Epoch 29/50\n",
      "242/242 [==============================] - 0s 632us/step - loss: 0.3565 - val_loss: 0.3416\n",
      "Epoch 30/50\n",
      "242/242 [==============================] - 0s 579us/step - loss: 0.3580 - val_loss: 0.3419\n",
      "Epoch 31/50\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.3537 - val_loss: 0.3419\n",
      "Epoch 32/50\n",
      "242/242 [==============================] - 0s 575us/step - loss: 0.3540 - val_loss: 0.3407\n",
      "Epoch 33/50\n",
      "242/242 [==============================] - 0s 608us/step - loss: 0.3513 - val_loss: 0.4976\n",
      "Epoch 34/50\n",
      "242/242 [==============================] - 0s 545us/step - loss: 0.3543 - val_loss: 0.3407\n",
      "Epoch 35/50\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.3526 - val_loss: 0.3384\n",
      "Epoch 36/50\n",
      "242/242 [==============================] - 0s 615us/step - loss: 0.3511 - val_loss: 0.3389\n",
      "Epoch 37/50\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3518 - val_loss: 0.3363\n",
      "Epoch 38/50\n",
      "242/242 [==============================] - 0s 539us/step - loss: 0.3497 - val_loss: 0.3417\n",
      "Epoch 39/50\n",
      "242/242 [==============================] - 0s 646us/step - loss: 0.3490 - val_loss: 0.3361\n",
      "Epoch 40/50\n",
      "242/242 [==============================] - 0s 587us/step - loss: 0.3493 - val_loss: 0.3509\n",
      "Epoch 41/50\n",
      "242/242 [==============================] - 0s 588us/step - loss: 0.3491 - val_loss: 0.3364\n",
      "Epoch 42/50\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.3478 - val_loss: 0.3358\n",
      "Epoch 43/50\n",
      "242/242 [==============================] - 0s 612us/step - loss: 0.3479 - val_loss: 0.4071\n",
      "Epoch 44/50\n",
      "242/242 [==============================] - 0s 626us/step - loss: 0.3497 - val_loss: 0.3345\n",
      "Epoch 45/50\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.3487 - val_loss: 0.3344\n",
      "Epoch 46/50\n",
      "242/242 [==============================] - 0s 628us/step - loss: 0.3469 - val_loss: 0.3347\n",
      "Epoch 47/50\n",
      "242/242 [==============================] - 0s 578us/step - loss: 0.3463 - val_loss: 0.4765\n",
      "Epoch 48/50\n",
      "242/242 [==============================] - 0s 566us/step - loss: 0.3477 - val_loss: 0.3365\n",
      "Epoch 49/50\n",
      "242/242 [==============================] - 0s 624us/step - loss: 0.3458 - val_loss: 0.3328\n",
      "Epoch 50/50\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.3439 - val_loss: 0.3342\n",
      "121/121 [==============================] - 0s 325us/step - loss: 0.3633\n",
      "[CV]  learning_rate=0.008072800877482553, n_hidden=1, n_neurons=21, total=   7.7s\n",
      "[CV] learning_rate=0.008072800877482553, n_hidden=1, n_neurons=21 ....\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 783us/step - loss: 1.1073 - val_loss: 0.8795\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 649us/step - loss: 0.5923 - val_loss: 2.6055\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 626us/step - loss: 0.5159 - val_loss: 4.9912\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 561us/step - loss: 0.4672 - val_loss: 4.9049\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 566us/step - loss: 0.4401 - val_loss: 4.5599\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 631us/step - loss: 0.4242 - val_loss: 4.0331\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.4153 - val_loss: 3.5372\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.4080 - val_loss: 3.0613\n",
      "Epoch 9/50\n",
      "242/242 [==============================] - 0s 687us/step - loss: 0.3997 - val_loss: 2.6364\n",
      "Epoch 10/50\n",
      "242/242 [==============================] - 0s 687us/step - loss: 0.3945 - val_loss: 2.4013\n",
      "Epoch 11/50\n",
      "242/242 [==============================] - 0s 637us/step - loss: 0.3903 - val_loss: 2.0786\n",
      "Epoch 12/50\n",
      "242/242 [==============================] - 0s 669us/step - loss: 0.3854 - val_loss: 1.8835\n",
      "Epoch 13/50\n",
      "242/242 [==============================] - 0s 636us/step - loss: 0.3820 - val_loss: 1.5367\n",
      "Epoch 14/50\n",
      "242/242 [==============================] - 0s 607us/step - loss: 0.3786 - val_loss: 1.3221\n",
      "Epoch 15/50\n",
      "242/242 [==============================] - 0s 617us/step - loss: 0.3756 - val_loss: 1.0845\n",
      "Epoch 16/50\n",
      "242/242 [==============================] - 0s 612us/step - loss: 0.3729 - val_loss: 0.8374\n",
      "Epoch 17/50\n",
      "242/242 [==============================] - 0s 629us/step - loss: 0.3714 - val_loss: 0.6500\n",
      "Epoch 18/50\n",
      "242/242 [==============================] - 0s 619us/step - loss: 0.3706 - val_loss: 0.5391\n",
      "Epoch 19/50\n",
      "242/242 [==============================] - 0s 549us/step - loss: 0.3695 - val_loss: 0.4423\n",
      "Epoch 20/50\n",
      "242/242 [==============================] - 0s 600us/step - loss: 0.3658 - val_loss: 0.3946\n",
      "Epoch 21/50\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.3646 - val_loss: 0.3575\n",
      "Epoch 22/50\n",
      "242/242 [==============================] - 0s 646us/step - loss: 0.3649 - val_loss: 0.3414\n",
      "Epoch 23/50\n",
      "242/242 [==============================] - 0s 650us/step - loss: 0.3616 - val_loss: 0.3406\n",
      "Epoch 24/50\n",
      "242/242 [==============================] - 0s 645us/step - loss: 0.3607 - val_loss: 0.3425\n",
      "Epoch 25/50\n",
      "242/242 [==============================] - 0s 626us/step - loss: 0.3609 - val_loss: 0.3632\n",
      "Epoch 26/50\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.3604 - val_loss: 0.3666\n",
      "Epoch 27/50\n",
      "242/242 [==============================] - 0s 592us/step - loss: 0.3582 - val_loss: 0.4133\n",
      "Epoch 28/50\n",
      "242/242 [==============================] - 0s 632us/step - loss: 0.3570 - val_loss: 0.4418\n",
      "Epoch 29/50\n",
      "242/242 [==============================] - 0s 601us/step - loss: 0.3558 - val_loss: 0.4315\n",
      "Epoch 30/50\n",
      "242/242 [==============================] - 0s 594us/step - loss: 0.3553 - val_loss: 0.4748\n",
      "Epoch 31/50\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.3543 - val_loss: 0.5004\n",
      "Epoch 32/50\n",
      "242/242 [==============================] - 0s 609us/step - loss: 0.3536 - val_loss: 0.4915\n",
      "Epoch 33/50\n",
      "242/242 [==============================] - 0s 596us/step - loss: 0.3519 - val_loss: 0.5371\n",
      "Epoch 34/50\n",
      "242/242 [==============================] - 0s 603us/step - loss: 0.3525 - val_loss: 0.5333\n",
      "Epoch 35/50\n",
      "242/242 [==============================] - 0s 625us/step - loss: 0.3525 - val_loss: 0.6259\n",
      "Epoch 36/50\n",
      "242/242 [==============================] - 0s 599us/step - loss: 0.3499 - val_loss: 0.5558\n",
      "Epoch 37/50\n",
      "242/242 [==============================] - 0s 629us/step - loss: 0.3500 - val_loss: 0.5912\n",
      "Epoch 38/50\n",
      "242/242 [==============================] - 0s 686us/step - loss: 0.3484 - val_loss: 0.5682\n",
      "Epoch 39/50\n",
      "242/242 [==============================] - 0s 641us/step - loss: 0.3460 - val_loss: 0.5547\n",
      "Epoch 40/50\n",
      "242/242 [==============================] - 0s 633us/step - loss: 0.3486 - val_loss: 0.5569\n",
      "Epoch 41/50\n",
      "242/242 [==============================] - 0s 663us/step - loss: 0.3452 - val_loss: 0.5911\n",
      "Epoch 42/50\n",
      "242/242 [==============================] - 0s 644us/step - loss: 0.3453 - val_loss: 0.5878\n",
      "Epoch 43/50\n",
      "242/242 [==============================] - 0s 667us/step - loss: 0.3427 - val_loss: 0.6397\n",
      "Epoch 44/50\n",
      "242/242 [==============================] - 0s 632us/step - loss: 0.3438 - val_loss: 0.6326\n",
      "Epoch 45/50\n",
      "242/242 [==============================] - 0s 607us/step - loss: 0.3450 - val_loss: 0.6419\n",
      "Epoch 46/50\n",
      "242/242 [==============================] - 0s 588us/step - loss: 0.3421 - val_loss: 0.6780\n",
      "Epoch 47/50\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.3441 - val_loss: 0.6333\n",
      "Epoch 48/50\n",
      "242/242 [==============================] - 0s 617us/step - loss: 0.3411 - val_loss: 0.6291\n",
      "Epoch 49/50\n",
      "242/242 [==============================] - 0s 574us/step - loss: 0.3395 - val_loss: 0.5687\n",
      "Epoch 50/50\n",
      "242/242 [==============================] - 0s 575us/step - loss: 0.3395 - val_loss: 0.5743\n",
      "121/121 [==============================] - 0s 324us/step - loss: 0.3498\n",
      "[CV]  learning_rate=0.008072800877482553, n_hidden=1, n_neurons=21, total=   7.9s\n",
      "[CV] learning_rate=0.008072800877482553, n_hidden=1, n_neurons=21 ....\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 830us/step - loss: 1.1834 - val_loss: 22.2337\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 567us/step - loss: 0.8332 - val_loss: 29.3001\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 609us/step - loss: 0.6396 - val_loss: 23.3232\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 621us/step - loss: 0.7419 - val_loss: 0.4311\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 586us/step - loss: 0.4549 - val_loss: 0.4067\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 646us/step - loss: 0.4396 - val_loss: 0.3975\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 0s 669us/step - loss: 0.4288 - val_loss: 0.3959\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.4188 - val_loss: 0.4004\n",
      "Epoch 9/50\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.4105 - val_loss: 0.4033\n",
      "Epoch 10/50\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.4068 - val_loss: 0.4067\n",
      "Epoch 11/50\n",
      "242/242 [==============================] - 0s 613us/step - loss: 0.4024 - val_loss: 0.4092\n",
      "Epoch 12/50\n",
      "242/242 [==============================] - 0s 621us/step - loss: 0.4011 - val_loss: 0.4122\n",
      "Epoch 13/50\n",
      "242/242 [==============================] - 0s 624us/step - loss: 0.3999 - val_loss: 0.4115\n",
      "Epoch 14/50\n",
      "242/242 [==============================] - 0s 624us/step - loss: 0.3932 - val_loss: 0.4096\n",
      "Epoch 15/50\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.3900 - val_loss: 0.4076\n",
      "Epoch 16/50\n",
      "242/242 [==============================] - 0s 597us/step - loss: 0.3871 - val_loss: 0.4038\n",
      "Epoch 17/50\n",
      "242/242 [==============================] - 0s 592us/step - loss: 0.3895 - val_loss: 0.3811\n",
      "Epoch 18/50\n",
      "242/242 [==============================] - 0s 549us/step - loss: 0.3848 - val_loss: 0.3834\n",
      "Epoch 19/50\n",
      "242/242 [==============================] - 0s 568us/step - loss: 0.3835 - val_loss: 0.3989\n",
      "Epoch 20/50\n",
      "242/242 [==============================] - 0s 579us/step - loss: 0.3820 - val_loss: 0.3672\n",
      "Epoch 21/50\n",
      "242/242 [==============================] - 0s 629us/step - loss: 0.3826 - val_loss: 0.3743\n",
      "Epoch 22/50\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.3769 - val_loss: 0.3725\n",
      "Epoch 23/50\n",
      "242/242 [==============================] - 0s 590us/step - loss: 0.3771 - val_loss: 0.4308\n",
      "Epoch 24/50\n",
      "242/242 [==============================] - 0s 579us/step - loss: 0.3784 - val_loss: 0.3602\n",
      "Epoch 25/50\n",
      "242/242 [==============================] - 0s 538us/step - loss: 0.3751 - val_loss: 0.3711\n",
      "Epoch 26/50\n",
      "242/242 [==============================] - 0s 554us/step - loss: 0.3730 - val_loss: 0.3826\n",
      "Epoch 27/50\n",
      "242/242 [==============================] - 0s 627us/step - loss: 0.3699 - val_loss: 0.3530\n",
      "Epoch 28/50\n",
      "242/242 [==============================] - 0s 565us/step - loss: 0.3723 - val_loss: 0.3547\n",
      "Epoch 29/50\n",
      "242/242 [==============================] - 0s 597us/step - loss: 0.3698 - val_loss: 0.3517\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 603us/step - loss: 0.3666 - val_loss: 0.3654\n",
      "Epoch 31/50\n",
      "242/242 [==============================] - 0s 598us/step - loss: 0.3694 - val_loss: 0.3524\n",
      "Epoch 32/50\n",
      "242/242 [==============================] - 0s 568us/step - loss: 0.3654 - val_loss: 0.4021\n",
      "Epoch 33/50\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.3657 - val_loss: 0.3430\n",
      "Epoch 34/50\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.3668 - val_loss: 0.3545\n",
      "Epoch 35/50\n",
      "242/242 [==============================] - 0s 642us/step - loss: 0.3640 - val_loss: 0.3672\n",
      "Epoch 36/50\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.3624 - val_loss: 0.3410\n",
      "Epoch 37/50\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.3624 - val_loss: 0.3426\n",
      "Epoch 38/50\n",
      "242/242 [==============================] - 0s 568us/step - loss: 0.3606 - val_loss: 0.4290\n",
      "Epoch 39/50\n",
      "242/242 [==============================] - 0s 594us/step - loss: 0.3604 - val_loss: 0.3377\n",
      "Epoch 40/50\n",
      "242/242 [==============================] - 0s 613us/step - loss: 0.3614 - val_loss: 0.3374\n",
      "Epoch 41/50\n",
      "242/242 [==============================] - 0s 567us/step - loss: 0.3577 - val_loss: 0.3468\n",
      "Epoch 42/50\n",
      "242/242 [==============================] - 0s 571us/step - loss: 0.3569 - val_loss: 0.3419\n",
      "Epoch 43/50\n",
      "242/242 [==============================] - 0s 620us/step - loss: 0.3543 - val_loss: 0.4639\n",
      "Epoch 44/50\n",
      "242/242 [==============================] - 0s 599us/step - loss: 0.3706 - val_loss: 0.3349\n",
      "Epoch 45/50\n",
      "242/242 [==============================] - 0s 609us/step - loss: 0.3557 - val_loss: 0.3425\n",
      "Epoch 46/50\n",
      "242/242 [==============================] - 0s 616us/step - loss: 0.3538 - val_loss: 0.3924\n",
      "Epoch 47/50\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.3542 - val_loss: 0.3339\n",
      "Epoch 48/50\n",
      "242/242 [==============================] - 0s 631us/step - loss: 0.3540 - val_loss: 0.3589\n",
      "Epoch 49/50\n",
      "242/242 [==============================] - 0s 625us/step - loss: 0.3682 - val_loss: 0.4113\n",
      "Epoch 50/50\n",
      "242/242 [==============================] - 0s 615us/step - loss: 0.3565 - val_loss: 0.3356\n",
      "121/121 [==============================] - 0s 302us/step - loss: 0.3535\n",
      "[CV]  learning_rate=0.008072800877482553, n_hidden=1, n_neurons=21, total=   7.6s\n",
      "[CV] learning_rate=0.018843848483309004, n_hidden=1, n_neurons=92 ....\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.7910 - val_loss: 8.5962\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 650us/step - loss: 0.4500 - val_loss: 1.2272\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.4177 - val_loss: 1.8502\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 617us/step - loss: 0.4439 - val_loss: 335.9096\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 671us/step - loss: 0.5766 - val_loss: 125.6131\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 656us/step - loss: 0.5987 - val_loss: 43.0328\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.5892 - val_loss: 86.0627\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - 0s 644us/step - loss: 0.3774 - val_loss: 0.3417\n",
      "Epoch 9/50\n",
      "242/242 [==============================] - 0s 675us/step - loss: 0.3683 - val_loss: 0.3404\n",
      "Epoch 10/50\n",
      "242/242 [==============================] - 0s 629us/step - loss: 0.3422 - val_loss: 0.3565\n",
      "Epoch 11/50\n",
      "242/242 [==============================] - 0s 649us/step - loss: 0.3378 - val_loss: 0.3584\n",
      "Epoch 12/50\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.3338 - val_loss: 0.3530\n",
      "Epoch 13/50\n",
      "242/242 [==============================] - 0s 663us/step - loss: 0.3359 - val_loss: 0.3240\n",
      "Epoch 14/50\n",
      "242/242 [==============================] - 0s 690us/step - loss: 0.3281 - val_loss: 0.3234\n",
      "Epoch 15/50\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.3235 - val_loss: 0.3380\n",
      "Epoch 16/50\n",
      "242/242 [==============================] - 0s 583us/step - loss: 0.3332 - val_loss: 0.3385\n",
      "Epoch 17/50\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.3320 - val_loss: 0.3177\n",
      "Epoch 18/50\n",
      "242/242 [==============================] - 0s 622us/step - loss: 0.3362 - val_loss: 0.3337\n",
      "Epoch 19/50\n",
      "242/242 [==============================] - 0s 638us/step - loss: 0.3241 - val_loss: 0.3186\n",
      "Epoch 20/50\n",
      "242/242 [==============================] - 0s 654us/step - loss: 0.3243 - val_loss: 5.5078\n",
      "Epoch 21/50\n",
      "242/242 [==============================] - 0s 631us/step - loss: 0.3759 - val_loss: 0.3112\n",
      "Epoch 22/50\n",
      "242/242 [==============================] - 0s 675us/step - loss: 0.3243 - val_loss: 0.3168\n",
      "Epoch 23/50\n",
      "242/242 [==============================] - 0s 641us/step - loss: 0.3231 - val_loss: 0.3285\n",
      "Epoch 24/50\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.3191 - val_loss: 0.3122\n",
      "Epoch 25/50\n",
      "242/242 [==============================] - 0s 645us/step - loss: 0.3162 - val_loss: 0.3556\n",
      "Epoch 26/50\n",
      "242/242 [==============================] - 0s 675us/step - loss: 0.3158 - val_loss: 0.3054\n",
      "Epoch 27/50\n",
      "242/242 [==============================] - 0s 673us/step - loss: 0.3197 - val_loss: 0.3149\n",
      "Epoch 28/50\n",
      "242/242 [==============================] - 0s 644us/step - loss: 0.3107 - val_loss: 0.3085\n",
      "Epoch 29/50\n",
      "242/242 [==============================] - 0s 607us/step - loss: 0.3088 - val_loss: 0.3088\n",
      "Epoch 30/50\n",
      "242/242 [==============================] - 0s 629us/step - loss: 0.3069 - val_loss: 0.3132\n",
      "Epoch 31/50\n",
      "242/242 [==============================] - 0s 628us/step - loss: 0.3072 - val_loss: 0.3075\n",
      "Epoch 32/50\n",
      "242/242 [==============================] - 0s 646us/step - loss: 0.3057 - val_loss: 0.3251\n",
      "Epoch 33/50\n",
      "242/242 [==============================] - 0s 632us/step - loss: 0.3056 - val_loss: 0.3058\n",
      "Epoch 34/50\n",
      "242/242 [==============================] - 0s 631us/step - loss: 0.3084 - val_loss: 0.2940\n",
      "Epoch 35/50\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.3046 - val_loss: 0.2998\n",
      "Epoch 36/50\n",
      "242/242 [==============================] - 0s 644us/step - loss: 0.3037 - val_loss: 0.4393\n",
      "Epoch 37/50\n",
      "242/242 [==============================] - 0s 626us/step - loss: 0.3037 - val_loss: 0.2947\n",
      "Epoch 38/50\n",
      "242/242 [==============================] - 0s 591us/step - loss: 0.3000 - val_loss: 0.3446\n",
      "Epoch 39/50\n",
      "242/242 [==============================] - 0s 570us/step - loss: 0.3053 - val_loss: 0.2951\n",
      "Epoch 40/50\n",
      "242/242 [==============================] - 0s 611us/step - loss: 0.2985 - val_loss: 0.3004\n",
      "Epoch 41/50\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.3033 - val_loss: 0.3063\n",
      "Epoch 42/50\n",
      "242/242 [==============================] - 0s 652us/step - loss: 0.3026 - val_loss: 0.3192\n",
      "Epoch 43/50\n",
      "242/242 [==============================] - 0s 652us/step - loss: 0.2988 - val_loss: 0.2929\n",
      "Epoch 44/50\n",
      "242/242 [==============================] - 0s 658us/step - loss: 0.2969 - val_loss: 0.2930\n",
      "Epoch 45/50\n",
      "242/242 [==============================] - 0s 624us/step - loss: 0.2971 - val_loss: 0.3330\n",
      "Epoch 46/50\n",
      "242/242 [==============================] - 0s 634us/step - loss: 0.2964 - val_loss: 0.2933\n",
      "Epoch 47/50\n",
      "242/242 [==============================] - 0s 621us/step - loss: 0.2979 - val_loss: 0.2914\n",
      "Epoch 48/50\n",
      "242/242 [==============================] - 0s 629us/step - loss: 0.3032 - val_loss: 0.3007\n",
      "Epoch 49/50\n",
      "242/242 [==============================] - 0s 671us/step - loss: 0.3185 - val_loss: 0.3159\n",
      "Epoch 50/50\n",
      "242/242 [==============================] - 0s 625us/step - loss: 0.3016 - val_loss: 0.3048\n",
      "121/121 [==============================] - 0s 399us/step - loss: 0.3358\n",
      "[CV]  learning_rate=0.018843848483309004, n_hidden=1, n_neurons=92, total=   8.1s\n",
      "[CV] learning_rate=0.018843848483309004, n_hidden=1, n_neurons=92 ....\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 822us/step - loss: 0.6804 - val_loss: 4.1213\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 617us/step - loss: 0.4368 - val_loss: 0.5545\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 669us/step - loss: 0.4066 - val_loss: 0.4504\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 678us/step - loss: 0.3938 - val_loss: 0.3673\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 625us/step - loss: 0.3807 - val_loss: 0.3517\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 625us/step - loss: 0.3830 - val_loss: 0.4851\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 0s 652us/step - loss: 0.3676 - val_loss: 0.3732\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - 0s 578us/step - loss: 0.3657 - val_loss: 0.4602\n",
      "Epoch 9/50\n",
      "242/242 [==============================] - 0s 693us/step - loss: 0.3608 - val_loss: 0.3750\n",
      "Epoch 10/50\n",
      "242/242 [==============================] - 0s 633us/step - loss: 0.3563 - val_loss: 0.3764\n",
      "Epoch 11/50\n",
      "242/242 [==============================] - 0s 702us/step - loss: 0.3558 - val_loss: 0.5232\n",
      "Epoch 12/50\n",
      "242/242 [==============================] - 0s 677us/step - loss: 0.3578 - val_loss: 0.3340\n",
      "Epoch 13/50\n",
      "242/242 [==============================] - 0s 683us/step - loss: 0.3514 - val_loss: 0.3872\n",
      "Epoch 14/50\n",
      "242/242 [==============================] - 0s 648us/step - loss: 0.3504 - val_loss: 0.3351\n",
      "Epoch 15/50\n",
      "242/242 [==============================] - 0s 680us/step - loss: 0.3466 - val_loss: 0.4544\n",
      "Epoch 16/50\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.3870 - val_loss: 0.3926\n",
      "Epoch 17/50\n",
      "242/242 [==============================] - 0s 645us/step - loss: 0.3472 - val_loss: 0.3776\n",
      "Epoch 18/50\n",
      "242/242 [==============================] - 0s 629us/step - loss: 0.3452 - val_loss: 0.4644\n",
      "Epoch 19/50\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.3391 - val_loss: 0.3209\n",
      "Epoch 20/50\n",
      "242/242 [==============================] - 0s 656us/step - loss: 0.3390 - val_loss: 0.4729\n",
      "Epoch 21/50\n",
      "242/242 [==============================] - 0s 621us/step - loss: 0.3369 - val_loss: 0.3376\n",
      "Epoch 22/50\n",
      "242/242 [==============================] - 0s 636us/step - loss: 0.3351 - val_loss: 0.3588\n",
      "Epoch 23/50\n",
      "242/242 [==============================] - 0s 631us/step - loss: 0.3348 - val_loss: 0.8269\n",
      "Epoch 24/50\n",
      "242/242 [==============================] - 0s 649us/step - loss: 0.3320 - val_loss: 0.3313\n",
      "Epoch 25/50\n",
      "242/242 [==============================] - 0s 637us/step - loss: 0.3333 - val_loss: 0.3336\n",
      "Epoch 26/50\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.3323 - val_loss: 0.4890\n",
      "Epoch 27/50\n",
      "242/242 [==============================] - 0s 591us/step - loss: 0.3278 - val_loss: 0.5365\n",
      "Epoch 28/50\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.3266 - val_loss: 0.3306\n",
      "Epoch 29/50\n",
      "242/242 [==============================] - 0s 619us/step - loss: 0.3253 - val_loss: 0.3595\n",
      "Epoch 30/50\n",
      "242/242 [==============================] - 0s 617us/step - loss: 0.3246 - val_loss: 0.3630\n",
      "Epoch 31/50\n",
      "242/242 [==============================] - 0s 644us/step - loss: 0.3247 - val_loss: 0.3807\n",
      "Epoch 32/50\n",
      "242/242 [==============================] - 0s 633us/step - loss: 0.3222 - val_loss: 0.5748\n",
      "Epoch 33/50\n",
      "242/242 [==============================] - 0s 653us/step - loss: 0.3194 - val_loss: 0.8258\n",
      "Epoch 34/50\n",
      "242/242 [==============================] - 0s 604us/step - loss: 0.3188 - val_loss: 0.5480\n",
      "Epoch 35/50\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.3204 - val_loss: 0.3047\n",
      "Epoch 36/50\n",
      "242/242 [==============================] - 0s 632us/step - loss: 0.3218 - val_loss: 0.4411\n",
      "Epoch 37/50\n",
      "242/242 [==============================] - 0s 645us/step - loss: 0.3148 - val_loss: 0.7112\n",
      "Epoch 38/50\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.3159 - val_loss: 0.8360\n",
      "Epoch 39/50\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.3118 - val_loss: 0.3058\n",
      "Epoch 40/50\n",
      "242/242 [==============================] - 0s 649us/step - loss: 0.3120 - val_loss: 1.0341\n",
      "Epoch 41/50\n",
      "242/242 [==============================] - 0s 631us/step - loss: 0.3123 - val_loss: 0.3388\n",
      "Epoch 42/50\n",
      "242/242 [==============================] - 0s 641us/step - loss: 0.3103 - val_loss: 0.5955\n",
      "Epoch 43/50\n",
      "242/242 [==============================] - 0s 619us/step - loss: 0.3102 - val_loss: 0.3186\n",
      "Epoch 44/50\n",
      "242/242 [==============================] - 0s 665us/step - loss: 0.3086 - val_loss: 0.9748\n",
      "Epoch 45/50\n",
      "242/242 [==============================] - 0s 603us/step - loss: 0.3087 - val_loss: 0.5137\n",
      "Epoch 46/50\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.3097 - val_loss: 0.7744\n",
      "Epoch 47/50\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.3085 - val_loss: 0.3551\n",
      "Epoch 48/50\n",
      "242/242 [==============================] - 0s 648us/step - loss: 0.3084 - val_loss: 0.6097\n",
      "Epoch 49/50\n",
      "242/242 [==============================] - 0s 617us/step - loss: 0.3072 - val_loss: 0.3282\n",
      "Epoch 50/50\n",
      "242/242 [==============================] - 0s 646us/step - loss: 0.3052 - val_loss: 1.0103\n",
      "121/121 [==============================] - 0s 312us/step - loss: 0.3288\n",
      "[CV]  learning_rate=0.018843848483309004, n_hidden=1, n_neurons=92, total=   8.1s\n",
      "[CV] learning_rate=0.018843848483309004, n_hidden=1, n_neurons=92 ....\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 820us/step - loss: 0.7205 - val_loss: 14.7975\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 654us/step - loss: 0.4978 - val_loss: 51.9590\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 627us/step - loss: 0.5383 - val_loss: 25.5133\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 638us/step - loss: 0.5106 - val_loss: 2.9716\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 615us/step - loss: 0.4956 - val_loss: 5.9443\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 627us/step - loss: 0.4568 - val_loss: 0.3808\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.3916 - val_loss: 0.3697\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - 0s 661us/step - loss: 0.3804 - val_loss: 0.4029\n",
      "Epoch 9/50\n",
      "242/242 [==============================] - 0s 660us/step - loss: 0.3741 - val_loss: 0.3590\n",
      "Epoch 10/50\n",
      "242/242 [==============================] - 0s 628us/step - loss: 0.3684 - val_loss: 0.3733\n",
      "Epoch 11/50\n",
      "242/242 [==============================] - 0s 675us/step - loss: 0.3691 - val_loss: 0.3658\n",
      "Epoch 12/50\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.3628 - val_loss: 0.3721\n",
      "Epoch 13/50\n",
      "242/242 [==============================] - 0s 685us/step - loss: 0.3575 - val_loss: 0.3571\n",
      "Epoch 14/50\n",
      "242/242 [==============================] - 0s 665us/step - loss: 0.3543 - val_loss: 0.3843\n",
      "Epoch 15/50\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.3518 - val_loss: 0.3500\n",
      "Epoch 16/50\n",
      "242/242 [==============================] - 0s 671us/step - loss: 0.3505 - val_loss: 0.3371\n",
      "Epoch 17/50\n",
      "242/242 [==============================] - 0s 679us/step - loss: 0.3486 - val_loss: 0.3430\n",
      "Epoch 18/50\n",
      "242/242 [==============================] - 0s 622us/step - loss: 0.3432 - val_loss: 0.3664\n",
      "Epoch 19/50\n",
      "242/242 [==============================] - 0s 612us/step - loss: 0.3797 - val_loss: 0.3565\n",
      "Epoch 20/50\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.3414 - val_loss: 0.3393\n",
      "Epoch 21/50\n",
      "242/242 [==============================] - 0s 629us/step - loss: 0.3388 - val_loss: 0.3279\n",
      "Epoch 22/50\n",
      "242/242 [==============================] - 0s 635us/step - loss: 0.3351 - val_loss: 0.3249\n",
      "Epoch 23/50\n",
      "242/242 [==============================] - 0s 636us/step - loss: 0.3304 - val_loss: 0.3448\n",
      "Epoch 24/50\n",
      "242/242 [==============================] - 0s 646us/step - loss: 0.3315 - val_loss: 0.3179\n",
      "Epoch 25/50\n",
      "242/242 [==============================] - 0s 652us/step - loss: 0.3287 - val_loss: 0.3584\n",
      "Epoch 26/50\n",
      "242/242 [==============================] - 0s 601us/step - loss: 0.3265 - val_loss: 0.3106\n",
      "Epoch 27/50\n",
      "242/242 [==============================] - 0s 604us/step - loss: 0.3246 - val_loss: 0.3565\n",
      "Epoch 28/50\n",
      "242/242 [==============================] - 0s 612us/step - loss: 0.3256 - val_loss: 0.3425\n",
      "Epoch 29/50\n",
      "242/242 [==============================] - 0s 648us/step - loss: 0.3248 - val_loss: 0.3102\n",
      "Epoch 30/50\n",
      "242/242 [==============================] - 0s 659us/step - loss: 0.3250 - val_loss: 0.3419\n",
      "Epoch 31/50\n",
      "242/242 [==============================] - 0s 642us/step - loss: 0.3233 - val_loss: 0.3177\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 672us/step - loss: 0.3239 - val_loss: 0.3081\n",
      "Epoch 33/50\n",
      "242/242 [==============================] - 0s 622us/step - loss: 0.3212 - val_loss: 0.3916\n",
      "Epoch 34/50\n",
      "242/242 [==============================] - 0s 609us/step - loss: 0.3257 - val_loss: 0.3246\n",
      "Epoch 35/50\n",
      "242/242 [==============================] - 0s 646us/step - loss: 0.3199 - val_loss: 0.3156\n",
      "Epoch 36/50\n",
      "242/242 [==============================] - 0s 650us/step - loss: 0.3162 - val_loss: 0.3418\n",
      "Epoch 37/50\n",
      "242/242 [==============================] - 0s 621us/step - loss: 0.3160 - val_loss: 0.3105\n",
      "Epoch 38/50\n",
      "242/242 [==============================] - 0s 612us/step - loss: 0.3145 - val_loss: 0.3255\n",
      "Epoch 39/50\n",
      "242/242 [==============================] - 0s 685us/step - loss: 0.3142 - val_loss: 0.3154\n",
      "Epoch 40/50\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.3129 - val_loss: 0.3334\n",
      "Epoch 41/50\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.3108 - val_loss: 0.2995\n",
      "Epoch 42/50\n",
      "242/242 [==============================] - 0s 630us/step - loss: 0.3079 - val_loss: 0.3233\n",
      "Epoch 43/50\n",
      "242/242 [==============================] - 0s 646us/step - loss: 0.3084 - val_loss: 0.3730\n",
      "Epoch 44/50\n",
      "242/242 [==============================] - 0s 627us/step - loss: 0.3081 - val_loss: 0.3160\n",
      "Epoch 45/50\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.3064 - val_loss: 0.3968\n",
      "Epoch 46/50\n",
      "242/242 [==============================] - 0s 640us/step - loss: 0.3201 - val_loss: 0.3031\n",
      "Epoch 47/50\n",
      "242/242 [==============================] - 0s 649us/step - loss: 0.3083 - val_loss: 0.3363\n",
      "Epoch 48/50\n",
      "242/242 [==============================] - 0s 590us/step - loss: 0.3055 - val_loss: 0.4133\n",
      "Epoch 49/50\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.3070 - val_loss: 0.2997\n",
      "Epoch 50/50\n",
      "242/242 [==============================] - 0s 602us/step - loss: 0.3056 - val_loss: 0.5694\n",
      "121/121 [==============================] - 0s 282us/step - loss: 0.3165\n",
      "[CV]  learning_rate=0.018843848483309004, n_hidden=1, n_neurons=92, total=   8.1s\n",
      "[CV] learning_rate=0.0006001182225873397, n_hidden=3, n_neurons=9 ....\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.6528 - val_loss: 3.7505\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 675us/step - loss: 1.6215 - val_loss: 6.5947\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 688us/step - loss: 1.1989 - val_loss: 5.2766\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 672us/step - loss: 1.0125 - val_loss: 2.7810\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 674us/step - loss: 0.8899 - val_loss: 1.6481\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 678us/step - loss: 0.8190 - val_loss: 1.1524\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 0s 687us/step - loss: 0.7751 - val_loss: 0.9174\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.7400 - val_loss: 0.7817\n",
      "Epoch 9/50\n",
      "242/242 [==============================] - 0s 671us/step - loss: 0.7110 - val_loss: 0.7044\n",
      "Epoch 10/50\n",
      "242/242 [==============================] - 0s 650us/step - loss: 0.6865 - val_loss: 0.6518\n",
      "Epoch 11/50\n",
      "242/242 [==============================] - 0s 670us/step - loss: 0.6651 - val_loss: 0.6259\n",
      "Epoch 12/50\n",
      "242/242 [==============================] - 0s 644us/step - loss: 0.6461 - val_loss: 0.6088\n",
      "Epoch 13/50\n",
      "242/242 [==============================] - 0s 592us/step - loss: 0.6292 - val_loss: 0.5942\n",
      "Epoch 14/50\n",
      "242/242 [==============================] - 0s 690us/step - loss: 0.6141 - val_loss: 0.5816\n",
      "Epoch 15/50\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.6001 - val_loss: 0.5707\n",
      "Epoch 16/50\n",
      "242/242 [==============================] - 0s 634us/step - loss: 0.5865 - val_loss: 0.5612\n",
      "Epoch 17/50\n",
      "242/242 [==============================] - 0s 670us/step - loss: 0.5739 - val_loss: 0.5520\n",
      "Epoch 18/50\n",
      "242/242 [==============================] - 0s 665us/step - loss: 0.5619 - val_loss: 0.5440\n",
      "Epoch 19/50\n",
      "242/242 [==============================] - 0s 715us/step - loss: 0.5508 - val_loss: 0.5362\n",
      "Epoch 20/50\n",
      "242/242 [==============================] - 0s 739us/step - loss: 0.5402 - val_loss: 0.5305\n",
      "Epoch 21/50\n",
      "242/242 [==============================] - 0s 666us/step - loss: 0.5303 - val_loss: 0.5253\n",
      "Epoch 22/50\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.5213 - val_loss: 0.5193\n",
      "Epoch 23/50\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.5128 - val_loss: 0.5130\n",
      "Epoch 24/50\n",
      "242/242 [==============================] - 0s 690us/step - loss: 0.5048 - val_loss: 0.5064\n",
      "Epoch 25/50\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.4977 - val_loss: 0.5008\n",
      "Epoch 26/50\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.4915 - val_loss: 0.4958\n",
      "Epoch 27/50\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.4855 - val_loss: 0.4912\n",
      "Epoch 28/50\n",
      "242/242 [==============================] - 0s 666us/step - loss: 0.4801 - val_loss: 0.4868\n",
      "Epoch 29/50\n",
      "242/242 [==============================] - 0s 693us/step - loss: 0.4752 - val_loss: 0.4828\n",
      "Epoch 30/50\n",
      "242/242 [==============================] - 0s 652us/step - loss: 0.4706 - val_loss: 0.4792\n",
      "Epoch 31/50\n",
      "242/242 [==============================] - 0s 689us/step - loss: 0.4667 - val_loss: 0.4763\n",
      "Epoch 32/50\n",
      "242/242 [==============================] - 0s 693us/step - loss: 0.4626 - val_loss: 0.4737\n",
      "Epoch 33/50\n",
      "242/242 [==============================] - 0s 658us/step - loss: 0.4592 - val_loss: 0.4713\n",
      "Epoch 34/50\n",
      "242/242 [==============================] - 0s 669us/step - loss: 0.4558 - val_loss: 0.4694\n",
      "Epoch 35/50\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.4532 - val_loss: 0.4673\n",
      "Epoch 36/50\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.4504 - val_loss: 0.4657\n",
      "Epoch 37/50\n",
      "242/242 [==============================] - 0s 656us/step - loss: 0.4479 - val_loss: 0.4636\n",
      "Epoch 38/50\n",
      "242/242 [==============================] - 0s 654us/step - loss: 0.4455 - val_loss: 0.4597\n",
      "Epoch 39/50\n",
      "242/242 [==============================] - 0s 689us/step - loss: 0.4435 - val_loss: 0.4586\n",
      "Epoch 40/50\n",
      "242/242 [==============================] - 0s 680us/step - loss: 0.4414 - val_loss: 0.4579\n",
      "Epoch 41/50\n",
      "242/242 [==============================] - 0s 681us/step - loss: 0.4395 - val_loss: 0.4549\n",
      "Epoch 42/50\n",
      "242/242 [==============================] - 0s 678us/step - loss: 0.4376 - val_loss: 0.4513\n",
      "Epoch 43/50\n",
      "242/242 [==============================] - 0s 686us/step - loss: 0.4361 - val_loss: 0.4513\n",
      "Epoch 44/50\n",
      "242/242 [==============================] - 0s 703us/step - loss: 0.4345 - val_loss: 0.4484\n",
      "Epoch 45/50\n",
      "242/242 [==============================] - 0s 634us/step - loss: 0.4330 - val_loss: 0.4454\n",
      "Epoch 46/50\n",
      "242/242 [==============================] - 0s 690us/step - loss: 0.4316 - val_loss: 0.4461\n",
      "Epoch 47/50\n",
      "242/242 [==============================] - 0s 594us/step - loss: 0.4302 - val_loss: 0.4440\n",
      "Epoch 48/50\n",
      "242/242 [==============================] - 0s 628us/step - loss: 0.4290 - val_loss: 0.4423\n",
      "Epoch 49/50\n",
      "242/242 [==============================] - 0s 653us/step - loss: 0.4279 - val_loss: 0.4408\n",
      "Epoch 50/50\n",
      "242/242 [==============================] - 0s 665us/step - loss: 0.4268 - val_loss: 0.4386\n",
      "121/121 [==============================] - 0s 297us/step - loss: 0.4307\n",
      "[CV]  learning_rate=0.0006001182225873397, n_hidden=3, n_neurons=9, total=   8.6s\n",
      "[CV] learning_rate=0.0006001182225873397, n_hidden=3, n_neurons=9 ....\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 914us/step - loss: 3.0481 - val_loss: 17.3740\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 698us/step - loss: 1.1530 - val_loss: 21.6225\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.8975 - val_loss: 16.7624\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 665us/step - loss: 0.8058 - val_loss: 13.8523\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 710us/step - loss: 0.7596 - val_loss: 11.5787\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 661us/step - loss: 0.7303 - val_loss: 9.7067\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 708us/step - loss: 0.7074 - val_loss: 8.2910\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - 0s 616us/step - loss: 0.6881 - val_loss: 7.0432\n",
      "Epoch 9/50\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.6710 - val_loss: 6.0447\n",
      "Epoch 10/50\n",
      "242/242 [==============================] - 0s 638us/step - loss: 0.6550 - val_loss: 5.2075\n",
      "Epoch 11/50\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.6406 - val_loss: 4.6301\n",
      "Epoch 12/50\n",
      "242/242 [==============================] - 0s 693us/step - loss: 0.6269 - val_loss: 4.0374\n",
      "Epoch 13/50\n",
      "242/242 [==============================] - 0s 631us/step - loss: 0.6139 - val_loss: 3.5581\n",
      "Epoch 14/50\n",
      "242/242 [==============================] - 0s 631us/step - loss: 0.6015 - val_loss: 3.1640\n",
      "Epoch 15/50\n",
      "242/242 [==============================] - 0s 634us/step - loss: 0.5897 - val_loss: 2.8447\n",
      "Epoch 16/50\n",
      "242/242 [==============================] - 0s 642us/step - loss: 0.5782 - val_loss: 2.6263\n",
      "Epoch 17/50\n",
      "242/242 [==============================] - 0s 657us/step - loss: 0.5671 - val_loss: 2.4476\n",
      "Epoch 18/50\n",
      "242/242 [==============================] - 0s 642us/step - loss: 0.5563 - val_loss: 2.2681\n",
      "Epoch 19/50\n",
      "242/242 [==============================] - 0s 663us/step - loss: 0.5459 - val_loss: 2.0852\n",
      "Epoch 20/50\n",
      "242/242 [==============================] - 0s 718us/step - loss: 0.5362 - val_loss: 1.9527\n",
      "Epoch 21/50\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.5268 - val_loss: 1.8305\n",
      "Epoch 22/50\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.5178 - val_loss: 1.6989\n",
      "Epoch 23/50\n",
      "242/242 [==============================] - 0s 677us/step - loss: 0.5090 - val_loss: 1.5837\n",
      "Epoch 24/50\n",
      "242/242 [==============================] - 0s 624us/step - loss: 0.5005 - val_loss: 1.5255\n",
      "Epoch 25/50\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.4933 - val_loss: 1.3954\n",
      "Epoch 26/50\n",
      "242/242 [==============================] - 0s 680us/step - loss: 0.4859 - val_loss: 1.3336\n",
      "Epoch 27/50\n",
      "242/242 [==============================] - 0s 680us/step - loss: 0.4795 - val_loss: 1.2520\n",
      "Epoch 28/50\n",
      "242/242 [==============================] - 0s 632us/step - loss: 0.4734 - val_loss: 1.1884\n",
      "Epoch 29/50\n",
      "242/242 [==============================] - 0s 652us/step - loss: 0.4679 - val_loss: 1.1307\n",
      "Epoch 30/50\n",
      "242/242 [==============================] - 0s 609us/step - loss: 0.4625 - val_loss: 1.0954\n",
      "Epoch 31/50\n",
      "242/242 [==============================] - 0s 679us/step - loss: 0.4579 - val_loss: 1.0323\n",
      "Epoch 32/50\n",
      "242/242 [==============================] - 0s 649us/step - loss: 0.4535 - val_loss: 1.0133\n",
      "Epoch 33/50\n",
      "242/242 [==============================] - 0s 683us/step - loss: 0.4498 - val_loss: 0.9682\n",
      "Epoch 34/50\n",
      "242/242 [==============================] - 0s 693us/step - loss: 0.4461 - val_loss: 0.9429\n",
      "Epoch 35/50\n",
      "242/242 [==============================] - 0s 686us/step - loss: 0.4429 - val_loss: 0.9142\n",
      "Epoch 36/50\n",
      "242/242 [==============================] - 0s 748us/step - loss: 0.4397 - val_loss: 0.8950\n",
      "Epoch 37/50\n",
      "242/242 [==============================] - 0s 733us/step - loss: 0.4370 - val_loss: 0.8765\n",
      "Epoch 38/50\n",
      "242/242 [==============================] - 0s 698us/step - loss: 0.4343 - val_loss: 0.8540\n",
      "Epoch 39/50\n",
      "242/242 [==============================] - 0s 656us/step - loss: 0.4320 - val_loss: 0.8497\n",
      "Epoch 40/50\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.4297 - val_loss: 0.8434\n",
      "Epoch 41/50\n",
      "242/242 [==============================] - 0s 697us/step - loss: 0.4275 - val_loss: 0.8208\n",
      "Epoch 42/50\n",
      "242/242 [==============================] - 0s 665us/step - loss: 0.4258 - val_loss: 0.8289\n",
      "Epoch 43/50\n",
      "242/242 [==============================] - 0s 699us/step - loss: 0.4239 - val_loss: 0.8226\n",
      "Epoch 44/50\n",
      "242/242 [==============================] - 0s 720us/step - loss: 0.4221 - val_loss: 0.8210\n",
      "Epoch 45/50\n",
      "242/242 [==============================] - 0s 642us/step - loss: 0.4201 - val_loss: 0.8309\n",
      "Epoch 46/50\n",
      "242/242 [==============================] - 0s 633us/step - loss: 0.4186 - val_loss: 0.8313\n",
      "Epoch 47/50\n",
      "242/242 [==============================] - 0s 660us/step - loss: 0.4169 - val_loss: 0.8166\n",
      "Epoch 48/50\n",
      "242/242 [==============================] - 0s 685us/step - loss: 0.4151 - val_loss: 0.8286\n",
      "Epoch 49/50\n",
      "242/242 [==============================] - 0s 648us/step - loss: 0.4136 - val_loss: 0.8276\n",
      "Epoch 50/50\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.4121 - val_loss: 0.8314\n",
      "121/121 [==============================] - 0s 274us/step - loss: 0.4259\n",
      "[CV]  learning_rate=0.0006001182225873397, n_hidden=3, n_neurons=9, total=   8.5s\n",
      "[CV] learning_rate=0.0006001182225873397, n_hidden=3, n_neurons=9 ....\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 815us/step - loss: 2.7394 - val_loss: 7.9081\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 648us/step - loss: 1.0464 - val_loss: 3.9370\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 637us/step - loss: 0.7496 - val_loss: 2.0068\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.6459 - val_loss: 1.3223\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 679us/step - loss: 0.5925 - val_loss: 0.9860\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 714us/step - loss: 0.5592 - val_loss: 0.7764\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 0s 716us/step - loss: 0.5335 - val_loss: 0.6860\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.5134 - val_loss: 0.6256\n",
      "Epoch 9/50\n",
      "242/242 [==============================] - 0s 698us/step - loss: 0.4980 - val_loss: 0.5930\n",
      "Epoch 10/50\n",
      "242/242 [==============================] - 0s 667us/step - loss: 0.4863 - val_loss: 0.5741\n",
      "Epoch 11/50\n",
      "242/242 [==============================] - 0s 726us/step - loss: 0.4777 - val_loss: 0.5610\n",
      "Epoch 12/50\n",
      "242/242 [==============================] - 0s 691us/step - loss: 0.4704 - val_loss: 0.5590\n",
      "Epoch 13/50\n",
      "242/242 [==============================] - 0s 677us/step - loss: 0.4645 - val_loss: 0.5474\n",
      "Epoch 14/50\n",
      "242/242 [==============================] - 0s 710us/step - loss: 0.4593 - val_loss: 0.5431\n",
      "Epoch 15/50\n",
      "242/242 [==============================] - 0s 679us/step - loss: 0.4549 - val_loss: 0.5336\n",
      "Epoch 16/50\n",
      "242/242 [==============================] - 0s 679us/step - loss: 0.4509 - val_loss: 0.5295\n",
      "Epoch 17/50\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.4470 - val_loss: 0.5218\n",
      "Epoch 18/50\n",
      "242/242 [==============================] - 0s 621us/step - loss: 0.4438 - val_loss: 0.5253\n",
      "Epoch 19/50\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.4409 - val_loss: 0.5148\n",
      "Epoch 20/50\n",
      "242/242 [==============================] - 0s 632us/step - loss: 0.4380 - val_loss: 0.5092\n",
      "Epoch 21/50\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.4353 - val_loss: 0.5133\n",
      "Epoch 22/50\n",
      "242/242 [==============================] - 0s 673us/step - loss: 0.4330 - val_loss: 0.5076\n",
      "Epoch 23/50\n",
      "242/242 [==============================] - 0s 700us/step - loss: 0.4308 - val_loss: 0.5093\n",
      "Epoch 24/50\n",
      "242/242 [==============================] - 0s 656us/step - loss: 0.4284 - val_loss: 0.5098\n",
      "Epoch 25/50\n",
      "242/242 [==============================] - 0s 660us/step - loss: 0.4265 - val_loss: 0.5034\n",
      "Epoch 26/50\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.4245 - val_loss: 0.5095\n",
      "Epoch 27/50\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.4227 - val_loss: 0.5062\n",
      "Epoch 28/50\n",
      "242/242 [==============================] - 0s 654us/step - loss: 0.4210 - val_loss: 0.5009\n",
      "Epoch 29/50\n",
      "242/242 [==============================] - 0s 667us/step - loss: 0.4193 - val_loss: 0.5004\n",
      "Epoch 30/50\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.4177 - val_loss: 0.5012\n",
      "Epoch 31/50\n",
      "242/242 [==============================] - 0s 662us/step - loss: 0.4163 - val_loss: 0.4975\n",
      "Epoch 32/50\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.4149 - val_loss: 0.4974\n",
      "Epoch 33/50\n",
      "242/242 [==============================] - 0s 648us/step - loss: 0.4138 - val_loss: 0.4955\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 659us/step - loss: 0.4125 - val_loss: 0.4880\n",
      "Epoch 35/50\n",
      "242/242 [==============================] - 0s 678us/step - loss: 0.4114 - val_loss: 0.4817\n",
      "Epoch 36/50\n",
      "242/242 [==============================] - 0s 650us/step - loss: 0.4103 - val_loss: 0.4851\n",
      "Epoch 37/50\n",
      "242/242 [==============================] - 0s 644us/step - loss: 0.4093 - val_loss: 0.4800\n",
      "Epoch 38/50\n",
      "242/242 [==============================] - 0s 642us/step - loss: 0.4085 - val_loss: 0.4825\n",
      "Epoch 39/50\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.4075 - val_loss: 0.4798\n",
      "Epoch 40/50\n",
      "242/242 [==============================] - 0s 615us/step - loss: 0.4068 - val_loss: 0.4813\n",
      "Epoch 41/50\n",
      "242/242 [==============================] - 0s 663us/step - loss: 0.4059 - val_loss: 0.4784\n",
      "Epoch 42/50\n",
      "242/242 [==============================] - 0s 662us/step - loss: 0.4051 - val_loss: 0.4718\n",
      "Epoch 43/50\n",
      "242/242 [==============================] - 0s 624us/step - loss: 0.4043 - val_loss: 0.4764\n",
      "Epoch 44/50\n",
      "242/242 [==============================] - 0s 678us/step - loss: 0.4037 - val_loss: 0.4760\n",
      "Epoch 45/50\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.4031 - val_loss: 0.4784\n",
      "Epoch 46/50\n",
      "242/242 [==============================] - 0s 642us/step - loss: 0.4025 - val_loss: 0.4711\n",
      "Epoch 47/50\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.4018 - val_loss: 0.4770\n",
      "Epoch 48/50\n",
      "242/242 [==============================] - 0s 616us/step - loss: 0.4010 - val_loss: 0.4765\n",
      "Epoch 49/50\n",
      "242/242 [==============================] - 0s 632us/step - loss: 0.4003 - val_loss: 0.4676\n",
      "Epoch 50/50\n",
      "242/242 [==============================] - 0s 669us/step - loss: 0.4001 - val_loss: 0.4695\n",
      "121/121 [==============================] - 0s 297us/step - loss: 0.3992\n",
      "[CV]  learning_rate=0.0006001182225873397, n_hidden=3, n_neurons=9, total=   8.4s\n",
      "[CV] learning_rate=0.0009605227473292263, n_hidden=0, n_neurons=24 ...\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 780us/step - loss: 5.9250 - val_loss: 9.5151\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 551us/step - loss: 2.3806 - val_loss: 1.9184\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 569us/step - loss: 1.3120 - val_loss: 1.0133\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 557us/step - loss: 0.9411 - val_loss: 0.8666\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 549us/step - loss: 0.7953 - val_loss: 0.8580\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 626us/step - loss: 0.7317 - val_loss: 0.8057\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.6987 - val_loss: 0.9786\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - 0s 542us/step - loss: 0.6818 - val_loss: 0.9630\n",
      "Epoch 9/50\n",
      "242/242 [==============================] - 0s 567us/step - loss: 0.6684 - val_loss: 0.9413\n",
      "Epoch 10/50\n",
      "242/242 [==============================] - 0s 582us/step - loss: 0.6572 - val_loss: 0.9953\n",
      "Epoch 11/50\n",
      "242/242 [==============================] - 0s 645us/step - loss: 0.6492 - val_loss: 0.8675\n",
      "Epoch 12/50\n",
      "242/242 [==============================] - 0s 594us/step - loss: 0.6391 - val_loss: 0.9740\n",
      "Epoch 13/50\n",
      "242/242 [==============================] - 0s 534us/step - loss: 0.6331 - val_loss: 0.8170\n",
      "Epoch 14/50\n",
      "242/242 [==============================] - 0s 603us/step - loss: 0.6243 - val_loss: 0.9140\n",
      "Epoch 15/50\n",
      "242/242 [==============================] - 0s 598us/step - loss: 0.6178 - val_loss: 0.9762\n",
      "Epoch 16/50\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.6120 - val_loss: 0.9833\n",
      "Epoch 17/50\n",
      "242/242 [==============================] - 0s 580us/step - loss: 0.6073 - val_loss: 0.8758\n",
      "Epoch 18/50\n",
      "242/242 [==============================] - 0s 611us/step - loss: 0.6002 - val_loss: 0.9575\n",
      "Epoch 19/50\n",
      "242/242 [==============================] - 0s 567us/step - loss: 0.5967 - val_loss: 0.8712\n",
      "Epoch 20/50\n",
      "242/242 [==============================] - 0s 558us/step - loss: 0.5908 - val_loss: 0.9300\n",
      "Epoch 21/50\n",
      "242/242 [==============================] - 0s 626us/step - loss: 0.5867 - val_loss: 0.9528\n",
      "Epoch 22/50\n",
      "242/242 [==============================] - 0s 542us/step - loss: 0.5836 - val_loss: 0.8610\n",
      "Epoch 23/50\n",
      "242/242 [==============================] - 0s 595us/step - loss: 0.5795 - val_loss: 0.8043\n",
      "Epoch 24/50\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.5755 - val_loss: 0.8015\n",
      "Epoch 25/50\n",
      "242/242 [==============================] - 0s 586us/step - loss: 0.5725 - val_loss: 0.7456\n",
      "Epoch 26/50\n",
      "242/242 [==============================] - 0s 584us/step - loss: 0.5685 - val_loss: 0.8001\n",
      "Epoch 27/50\n",
      "242/242 [==============================] - 0s 650us/step - loss: 0.5666 - val_loss: 0.7399\n",
      "Epoch 28/50\n",
      "242/242 [==============================] - 0s 612us/step - loss: 0.5625 - val_loss: 0.8284\n",
      "Epoch 29/50\n",
      "242/242 [==============================] - 0s 546us/step - loss: 0.5616 - val_loss: 0.7102\n",
      "Epoch 30/50\n",
      "242/242 [==============================] - 0s 627us/step - loss: 0.5585 - val_loss: 0.7342\n",
      "Epoch 31/50\n",
      "242/242 [==============================] - 0s 634us/step - loss: 0.5565 - val_loss: 0.7144\n",
      "Epoch 32/50\n",
      "242/242 [==============================] - 0s 626us/step - loss: 0.5538 - val_loss: 0.7794\n",
      "Epoch 33/50\n",
      "242/242 [==============================] - 0s 592us/step - loss: 0.5518 - val_loss: 0.8372\n",
      "Epoch 34/50\n",
      "242/242 [==============================] - 0s 693us/step - loss: 0.5508 - val_loss: 0.8219\n",
      "Epoch 35/50\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.5496 - val_loss: 0.7372\n",
      "Epoch 36/50\n",
      "242/242 [==============================] - 0s 677us/step - loss: 0.5477 - val_loss: 0.6732\n",
      "Epoch 37/50\n",
      "242/242 [==============================] - 0s 658us/step - loss: 0.5455 - val_loss: 0.7227\n",
      "Epoch 38/50\n",
      "242/242 [==============================] - 0s 659us/step - loss: 0.5444 - val_loss: 0.7559\n",
      "Epoch 39/50\n",
      "242/242 [==============================] - 0s 633us/step - loss: 0.5426 - val_loss: 0.8306\n",
      "Epoch 40/50\n",
      "242/242 [==============================] - 0s 613us/step - loss: 0.5423 - val_loss: 0.8262\n",
      "Epoch 41/50\n",
      "242/242 [==============================] - 0s 627us/step - loss: 0.5416 - val_loss: 0.7785\n",
      "Epoch 42/50\n",
      "242/242 [==============================] - 0s 584us/step - loss: 0.5399 - val_loss: 0.7973\n",
      "Epoch 43/50\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.5395 - val_loss: 0.7576\n",
      "Epoch 44/50\n",
      "242/242 [==============================] - 0s 704us/step - loss: 0.5382 - val_loss: 0.7700\n",
      "Epoch 45/50\n",
      "242/242 [==============================] - 0s 632us/step - loss: 0.5380 - val_loss: 0.6714\n",
      "Epoch 46/50\n",
      "242/242 [==============================] - 0s 559us/step - loss: 0.5366 - val_loss: 0.6253\n",
      "Epoch 47/50\n",
      "242/242 [==============================] - 0s 605us/step - loss: 0.5353 - val_loss: 0.7087\n",
      "Epoch 48/50\n",
      "242/242 [==============================] - 0s 654us/step - loss: 0.5356 - val_loss: 0.6330\n",
      "Epoch 49/50\n",
      "242/242 [==============================] - 0s 571us/step - loss: 0.5345 - val_loss: 0.6587\n",
      "Epoch 50/50\n",
      "242/242 [==============================] - 0s 522us/step - loss: 0.5335 - val_loss: 0.7260\n",
      "121/121 [==============================] - 0s 287us/step - loss: 0.5396\n",
      "[CV]  learning_rate=0.0009605227473292263, n_hidden=0, n_neurons=24, total=   7.5s\n",
      "[CV] learning_rate=0.0009605227473292263, n_hidden=0, n_neurons=24 ...\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 834us/step - loss: 4.1004 - val_loss: 16.2511\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 601us/step - loss: 2.0198 - val_loss: 9.5963\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 617us/step - loss: 1.1975 - val_loss: 5.5186\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.8644 - val_loss: 3.0085\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.7233 - val_loss: 1.5348\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 633us/step - loss: 0.6586 - val_loss: 0.7794\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 0s 621us/step - loss: 0.6251 - val_loss: 0.5615\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.6050 - val_loss: 0.7335\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 607us/step - loss: 0.5911 - val_loss: 1.1935\n",
      "Epoch 10/50\n",
      "242/242 [==============================] - 0s 604us/step - loss: 0.5803 - val_loss: 1.8591\n",
      "Epoch 11/50\n",
      "242/242 [==============================] - 0s 587us/step - loss: 0.5714 - val_loss: 2.6895\n",
      "Epoch 12/50\n",
      "242/242 [==============================] - 0s 621us/step - loss: 0.5639 - val_loss: 3.6365\n",
      "Epoch 13/50\n",
      "242/242 [==============================] - 0s 597us/step - loss: 0.5573 - val_loss: 4.6543\n",
      "Epoch 14/50\n",
      "242/242 [==============================] - 0s 566us/step - loss: 0.5516 - val_loss: 5.6770\n",
      "Epoch 15/50\n",
      "242/242 [==============================] - 0s 538us/step - loss: 0.5466 - val_loss: 6.7249\n",
      "Epoch 16/50\n",
      "242/242 [==============================] - 0s 586us/step - loss: 0.5422 - val_loss: 7.7432\n",
      "Epoch 17/50\n",
      "242/242 [==============================] - 0s 596us/step - loss: 0.5383 - val_loss: 8.7802\n",
      "Epoch 18/50\n",
      "242/242 [==============================] - 0s 624us/step - loss: 0.5349 - val_loss: 9.7664\n",
      "Epoch 19/50\n",
      "242/242 [==============================] - 0s 571us/step - loss: 0.5318 - val_loss: 10.7324\n",
      "Epoch 20/50\n",
      "242/242 [==============================] - 0s 616us/step - loss: 0.5290 - val_loss: 11.6364\n",
      "Epoch 21/50\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.5266 - val_loss: 12.4903\n",
      "Epoch 22/50\n",
      "242/242 [==============================] - 0s 579us/step - loss: 0.5244 - val_loss: 13.2858\n",
      "Epoch 23/50\n",
      "242/242 [==============================] - 0s 609us/step - loss: 0.5223 - val_loss: 14.0682\n",
      "Epoch 24/50\n",
      "242/242 [==============================] - 0s 534us/step - loss: 0.5206 - val_loss: 14.7869\n",
      "Epoch 25/50\n",
      "242/242 [==============================] - 0s 566us/step - loss: 0.5189 - val_loss: 15.4562\n",
      "Epoch 26/50\n",
      "242/242 [==============================] - 0s 533us/step - loss: 0.5174 - val_loss: 16.0754\n",
      "Epoch 27/50\n",
      "242/242 [==============================] - 0s 572us/step - loss: 0.5161 - val_loss: 16.6400\n",
      "Epoch 28/50\n",
      "242/242 [==============================] - 0s 570us/step - loss: 0.5148 - val_loss: 17.1863\n",
      "Epoch 29/50\n",
      "242/242 [==============================] - 0s 555us/step - loss: 0.5137 - val_loss: 17.6265\n",
      "Epoch 30/50\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.5127 - val_loss: 18.0270\n",
      "Epoch 31/50\n",
      "242/242 [==============================] - 0s 586us/step - loss: 0.5117 - val_loss: 18.4635\n",
      "Epoch 32/50\n",
      "242/242 [==============================] - 0s 526us/step - loss: 0.5108 - val_loss: 18.8161\n",
      "Epoch 33/50\n",
      "242/242 [==============================] - 0s 530us/step - loss: 0.5100 - val_loss: 19.1905\n",
      "Epoch 34/50\n",
      "242/242 [==============================] - 0s 580us/step - loss: 0.5093 - val_loss: 19.4255\n",
      "Epoch 35/50\n",
      "242/242 [==============================] - 0s 566us/step - loss: 0.5086 - val_loss: 19.7459\n",
      "Epoch 36/50\n",
      "242/242 [==============================] - 0s 605us/step - loss: 0.5079 - val_loss: 19.9902\n",
      "Epoch 37/50\n",
      "242/242 [==============================] - 0s 525us/step - loss: 0.5073 - val_loss: 20.2311\n",
      "Epoch 38/50\n",
      "242/242 [==============================] - 0s 592us/step - loss: 0.5067 - val_loss: 20.4693\n",
      "Epoch 39/50\n",
      "242/242 [==============================] - 0s 514us/step - loss: 0.5062 - val_loss: 20.6614\n",
      "Epoch 40/50\n",
      "242/242 [==============================] - 0s 551us/step - loss: 0.5058 - val_loss: 20.8280\n",
      "Epoch 41/50\n",
      "242/242 [==============================] - 0s 604us/step - loss: 0.5053 - val_loss: 20.9635\n",
      "Epoch 42/50\n",
      "242/242 [==============================] - 0s 574us/step - loss: 0.5049 - val_loss: 21.0968\n",
      "Epoch 43/50\n",
      "242/242 [==============================] - 0s 572us/step - loss: 0.5045 - val_loss: 21.2497\n",
      "Epoch 44/50\n",
      "242/242 [==============================] - 0s 576us/step - loss: 0.5040 - val_loss: 21.3428\n",
      "Epoch 45/50\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.5038 - val_loss: 21.4182\n",
      "Epoch 46/50\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.5034 - val_loss: 21.4941\n",
      "Epoch 47/50\n",
      "242/242 [==============================] - 0s 609us/step - loss: 0.5031 - val_loss: 21.5239\n",
      "Epoch 48/50\n",
      "242/242 [==============================] - 0s 640us/step - loss: 0.5028 - val_loss: 21.6193\n",
      "Epoch 49/50\n",
      "242/242 [==============================] - 0s 599us/step - loss: 0.5026 - val_loss: 21.6290\n",
      "Epoch 50/50\n",
      "242/242 [==============================] - 0s 609us/step - loss: 0.5023 - val_loss: 21.6926\n",
      "121/121 [==============================] - 0s 343us/step - loss: 1.0222\n",
      "[CV]  learning_rate=0.0009605227473292263, n_hidden=0, n_neurons=24, total=   7.4s\n",
      "[CV] learning_rate=0.0009605227473292263, n_hidden=0, n_neurons=24 ...\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 776us/step - loss: 4.4943 - val_loss: 4.7218\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 526us/step - loss: 2.0540 - val_loss: 2.1412\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 630us/step - loss: 1.1867 - val_loss: 1.2103\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 685us/step - loss: 0.8522 - val_loss: 0.8742\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 653us/step - loss: 0.7173 - val_loss: 0.7863\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 629us/step - loss: 0.6586 - val_loss: 0.8716\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.6330 - val_loss: 0.7751\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - 0s 534us/step - loss: 0.6173 - val_loss: 0.8392\n",
      "Epoch 9/50\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.6080 - val_loss: 0.8989\n",
      "Epoch 10/50\n",
      "242/242 [==============================] - 0s 574us/step - loss: 0.6017 - val_loss: 0.9023\n",
      "Epoch 11/50\n",
      "242/242 [==============================] - 0s 570us/step - loss: 0.5969 - val_loss: 0.7869\n",
      "Epoch 12/50\n",
      "242/242 [==============================] - 0s 608us/step - loss: 0.5913 - val_loss: 0.7940\n",
      "Epoch 13/50\n",
      "242/242 [==============================] - 0s 586us/step - loss: 0.5869 - val_loss: 0.8007\n",
      "Epoch 14/50\n",
      "242/242 [==============================] - 0s 586us/step - loss: 0.5832 - val_loss: 0.7213\n",
      "Epoch 15/50\n",
      "242/242 [==============================] - 0s 518us/step - loss: 0.5793 - val_loss: 0.6752\n",
      "Epoch 16/50\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.5745 - val_loss: 0.8098\n",
      "Epoch 17/50\n",
      "242/242 [==============================] - 0s 602us/step - loss: 0.5727 - val_loss: 0.6971\n",
      "Epoch 18/50\n",
      "242/242 [==============================] - 0s 660us/step - loss: 0.5685 - val_loss: 0.7971\n",
      "Epoch 19/50\n",
      "242/242 [==============================] - 0s 641us/step - loss: 0.5671 - val_loss: 0.6802\n",
      "Epoch 20/50\n",
      "242/242 [==============================] - 0s 637us/step - loss: 0.5635 - val_loss: 0.7521\n",
      "Epoch 21/50\n",
      "242/242 [==============================] - 0s 575us/step - loss: 0.5619 - val_loss: 0.6932\n",
      "Epoch 22/50\n",
      "242/242 [==============================] - 0s 586us/step - loss: 0.5595 - val_loss: 0.6668\n",
      "Epoch 23/50\n",
      "242/242 [==============================] - 0s 565us/step - loss: 0.5573 - val_loss: 0.6425\n",
      "Epoch 24/50\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.5554 - val_loss: 0.6204\n",
      "Epoch 25/50\n",
      "242/242 [==============================] - 0s 584us/step - loss: 0.5533 - val_loss: 0.6696\n",
      "Epoch 26/50\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.5519 - val_loss: 0.6481\n",
      "Epoch 27/50\n",
      "242/242 [==============================] - 0s 518us/step - loss: 0.5498 - val_loss: 0.7005\n",
      "Epoch 28/50\n",
      "242/242 [==============================] - 0s 563us/step - loss: 0.5484 - val_loss: 0.7481\n",
      "Epoch 29/50\n",
      "242/242 [==============================] - 0s 580us/step - loss: 0.5474 - val_loss: 0.7062\n",
      "Epoch 30/50\n",
      "242/242 [==============================] - 0s 563us/step - loss: 0.5462 - val_loss: 0.6687\n",
      "Epoch 31/50\n",
      "242/242 [==============================] - 0s 541us/step - loss: 0.5441 - val_loss: 0.7570\n",
      "Epoch 32/50\n",
      "242/242 [==============================] - 0s 575us/step - loss: 0.5434 - val_loss: 0.7723\n",
      "Epoch 33/50\n",
      "242/242 [==============================] - 0s 579us/step - loss: 0.5431 - val_loss: 0.7213\n",
      "Epoch 34/50\n",
      "242/242 [==============================] - 0s 525us/step - loss: 0.5419 - val_loss: 0.6890\n",
      "Epoch 35/50\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.5408 - val_loss: 0.6745\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 668us/step - loss: 0.5398 - val_loss: 0.6903\n",
      "Epoch 37/50\n",
      "242/242 [==============================] - 0s 634us/step - loss: 0.5387 - val_loss: 0.7381\n",
      "Epoch 38/50\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.5386 - val_loss: 0.7182\n",
      "Epoch 39/50\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.5374 - val_loss: 0.7569\n",
      "Epoch 40/50\n",
      "242/242 [==============================] - 0s 566us/step - loss: 0.5376 - val_loss: 0.6468\n",
      "Epoch 41/50\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.5358 - val_loss: 0.7141\n",
      "Epoch 42/50\n",
      "242/242 [==============================] - 0s 537us/step - loss: 0.5362 - val_loss: 0.6771\n",
      "Epoch 43/50\n",
      "242/242 [==============================] - 0s 574us/step - loss: 0.5351 - val_loss: 0.6885\n",
      "Epoch 44/50\n",
      "242/242 [==============================] - 0s 628us/step - loss: 0.5340 - val_loss: 0.7649\n",
      "Epoch 45/50\n",
      "242/242 [==============================] - 0s 574us/step - loss: 0.5348 - val_loss: 0.7085\n",
      "Epoch 46/50\n",
      "242/242 [==============================] - 0s 674us/step - loss: 0.5343 - val_loss: 0.6679\n",
      "Epoch 47/50\n",
      "242/242 [==============================] - 0s 579us/step - loss: 0.5333 - val_loss: 0.7036\n",
      "Epoch 48/50\n",
      "242/242 [==============================] - 0s 650us/step - loss: 0.5333 - val_loss: 0.6826\n",
      "Epoch 49/50\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.5325 - val_loss: 0.6825\n",
      "Epoch 50/50\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.5327 - val_loss: 0.6726\n",
      "121/121 [==============================] - 0s 346us/step - loss: 0.5335\n",
      "[CV]  learning_rate=0.0009605227473292263, n_hidden=0, n_neurons=24, total=   7.4s\n",
      "[CV] learning_rate=0.003302349014241548, n_hidden=0, n_neurons=36 ....\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 807us/step - loss: 2.4506 - val_loss: 1.4787\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 542us/step - loss: 0.6285 - val_loss: 1.8481\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 562us/step - loss: 0.5971 - val_loss: 1.8842\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 609us/step - loss: 0.5639 - val_loss: 0.5674\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.5495 - val_loss: 1.0573\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 635us/step - loss: 0.5640 - val_loss: 0.5210\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 0s 596us/step - loss: 0.5485 - val_loss: 0.5030\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.5403 - val_loss: 0.8275\n",
      "Epoch 9/50\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.5429 - val_loss: 0.8786\n",
      "Epoch 10/50\n",
      "242/242 [==============================] - 0s 539us/step - loss: 0.5530 - val_loss: 2.5691\n",
      "Epoch 11/50\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.5430 - val_loss: 1.8128\n",
      "Epoch 12/50\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.5599 - val_loss: 0.4980\n",
      "Epoch 13/50\n",
      "242/242 [==============================] - 0s 534us/step - loss: 0.5385 - val_loss: 0.5281\n",
      "Epoch 14/50\n",
      "242/242 [==============================] - 0s 554us/step - loss: 0.5347 - val_loss: 0.5261\n",
      "Epoch 15/50\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.5413 - val_loss: 2.0204\n",
      "Epoch 16/50\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.5322 - val_loss: 3.1397\n",
      "Epoch 17/50\n",
      "242/242 [==============================] - 0s 521us/step - loss: 0.5761 - val_loss: 4.6518\n",
      "Epoch 18/50\n",
      "242/242 [==============================] - 0s 522us/step - loss: 0.5527 - val_loss: 5.9073\n",
      "Epoch 19/50\n",
      "242/242 [==============================] - 0s 551us/step - loss: 0.6117 - val_loss: 5.0261\n",
      "Epoch 20/50\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.5560 - val_loss: 1.7659\n",
      "Epoch 21/50\n",
      "242/242 [==============================] - 0s 553us/step - loss: 0.5593 - val_loss: 2.1589\n",
      "Epoch 22/50\n",
      "242/242 [==============================] - 0s 537us/step - loss: 0.5336 - val_loss: 2.2386\n",
      "Epoch 23/50\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.5669 - val_loss: 1.6800\n",
      "Epoch 24/50\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.5364 - val_loss: 0.5088\n",
      "Epoch 25/50\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.5312 - val_loss: 0.6002\n",
      "Epoch 26/50\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.5381 - val_loss: 0.5804\n",
      "Epoch 27/50\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.5335 - val_loss: 0.7531\n",
      "Epoch 28/50\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.5312 - val_loss: 0.5308\n",
      "Epoch 29/50\n",
      "242/242 [==============================] - 0s 508us/step - loss: 0.5370 - val_loss: 1.6751\n",
      "Epoch 30/50\n",
      "242/242 [==============================] - 0s 537us/step - loss: 0.5296 - val_loss: 2.0923\n",
      "Epoch 31/50\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.5631 - val_loss: 2.1858\n",
      "Epoch 32/50\n",
      "242/242 [==============================] - 0s 520us/step - loss: 0.5382 - val_loss: 0.5333\n",
      "Epoch 33/50\n",
      "242/242 [==============================] - 0s 508us/step - loss: 0.5269 - val_loss: 0.9950\n",
      "Epoch 34/50\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.5458 - val_loss: 2.0586\n",
      "Epoch 35/50\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.5336 - val_loss: 1.5497\n",
      "Epoch 36/50\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.5566 - val_loss: 1.2609\n",
      "Epoch 37/50\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.5340 - val_loss: 0.5877\n",
      "Epoch 38/50\n",
      "242/242 [==============================] - 0s 543us/step - loss: 0.5205 - val_loss: 1.8406\n",
      "Epoch 39/50\n",
      "242/242 [==============================] - 0s 517us/step - loss: 0.5580 - val_loss: 0.5541\n",
      "Epoch 40/50\n",
      "242/242 [==============================] - 0s 529us/step - loss: 0.5223 - val_loss: 1.4770\n",
      "Epoch 41/50\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.5506 - val_loss: 0.5059\n",
      "Epoch 42/50\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.5334 - val_loss: 0.5780\n",
      "Epoch 43/50\n",
      "242/242 [==============================] - 0s 565us/step - loss: 0.5203 - val_loss: 1.7469\n",
      "Epoch 44/50\n",
      "242/242 [==============================] - 0s 517us/step - loss: 0.5556 - val_loss: 2.1722\n",
      "Epoch 45/50\n",
      "242/242 [==============================] - 0s 520us/step - loss: 0.5376 - val_loss: 0.7064\n",
      "Epoch 46/50\n",
      "242/242 [==============================] - 0s 546us/step - loss: 0.5412 - val_loss: 0.9969\n",
      "Epoch 47/50\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.5328 - val_loss: 0.5681\n",
      "Epoch 48/50\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.5285 - val_loss: 0.6595\n",
      "Epoch 49/50\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.5391 - val_loss: 0.5280\n",
      "Epoch 50/50\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.5227 - val_loss: 1.3347\n",
      "121/121 [==============================] - 0s 261us/step - loss: 0.5328\n",
      "[CV]  learning_rate=0.003302349014241548, n_hidden=0, n_neurons=36, total=   6.9s\n",
      "[CV] learning_rate=0.003302349014241548, n_hidden=0, n_neurons=36 ....\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 704us/step - loss: 2.4399 - val_loss: 8.8435\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 535us/step - loss: 0.6186 - val_loss: 11.4565\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 555us/step - loss: 0.5486 - val_loss: 14.2759\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 580us/step - loss: 0.5352 - val_loss: 15.9282\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 571us/step - loss: 0.5275 - val_loss: 17.2230\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 526us/step - loss: 0.5207 - val_loss: 18.7430\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 0s 504us/step - loss: 0.5162 - val_loss: 19.3293\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.5125 - val_loss: 19.9505\n",
      "Epoch 9/50\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.5097 - val_loss: 20.4543\n",
      "Epoch 10/50\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.5076 - val_loss: 20.3964\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 539us/step - loss: 0.5057 - val_loss: 20.3349\n",
      "Epoch 12/50\n",
      "242/242 [==============================] - 0s 592us/step - loss: 0.5046 - val_loss: 20.7090\n",
      "Epoch 13/50\n",
      "242/242 [==============================] - 0s 514us/step - loss: 0.5033 - val_loss: 20.3210\n",
      "Epoch 14/50\n",
      "242/242 [==============================] - 0s 551us/step - loss: 0.5026 - val_loss: 20.1934\n",
      "Epoch 15/50\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.5018 - val_loss: 20.5988\n",
      "Epoch 16/50\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.5012 - val_loss: 20.8454\n",
      "Epoch 17/50\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.5013 - val_loss: 20.8108\n",
      "Epoch 18/50\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.5005 - val_loss: 20.9689\n",
      "Epoch 19/50\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.5003 - val_loss: 21.0648\n",
      "Epoch 20/50\n",
      "242/242 [==============================] - 0s 572us/step - loss: 0.5003 - val_loss: 21.1867\n",
      "Epoch 21/50\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.5002 - val_loss: 21.0784\n",
      "Epoch 22/50\n",
      "242/242 [==============================] - 0s 550us/step - loss: 0.5001 - val_loss: 20.6552\n",
      "Epoch 23/50\n",
      "242/242 [==============================] - 0s 521us/step - loss: 0.4995 - val_loss: 20.8981\n",
      "Epoch 24/50\n",
      "242/242 [==============================] - 0s 537us/step - loss: 0.5000 - val_loss: 21.0556\n",
      "Epoch 25/50\n",
      "242/242 [==============================] - 0s 522us/step - loss: 0.4996 - val_loss: 21.1308\n",
      "Epoch 26/50\n",
      "242/242 [==============================] - 0s 541us/step - loss: 0.4993 - val_loss: 21.1515\n",
      "Epoch 27/50\n",
      "242/242 [==============================] - 0s 520us/step - loss: 0.4996 - val_loss: 21.3438\n",
      "Epoch 28/50\n",
      "242/242 [==============================] - 0s 551us/step - loss: 0.4995 - val_loss: 21.2970\n",
      "Epoch 29/50\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.4993 - val_loss: 21.3672\n",
      "Epoch 30/50\n",
      "242/242 [==============================] - 0s 568us/step - loss: 0.4995 - val_loss: 20.9634\n",
      "Epoch 31/50\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.4993 - val_loss: 20.7145\n",
      "Epoch 32/50\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.4995 - val_loss: 20.6049\n",
      "Epoch 33/50\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.4995 - val_loss: 20.3162\n",
      "Epoch 34/50\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.4994 - val_loss: 20.6145\n",
      "Epoch 35/50\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.4995 - val_loss: 20.7874\n",
      "Epoch 36/50\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.4993 - val_loss: 20.9328\n",
      "Epoch 37/50\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.4988 - val_loss: 20.9799\n",
      "Epoch 38/50\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.4992 - val_loss: 20.7559\n",
      "Epoch 39/50\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.4994 - val_loss: 20.5033\n",
      "Epoch 40/50\n",
      "242/242 [==============================] - 0s 555us/step - loss: 0.4990 - val_loss: 20.0678\n",
      "Epoch 41/50\n",
      "242/242 [==============================] - 0s 537us/step - loss: 0.4992 - val_loss: 20.1903\n",
      "Epoch 42/50\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.4990 - val_loss: 20.0317\n",
      "Epoch 43/50\n",
      "242/242 [==============================] - 0s 574us/step - loss: 0.4997 - val_loss: 20.2655\n",
      "Epoch 44/50\n",
      "242/242 [==============================] - 0s 559us/step - loss: 0.4992 - val_loss: 20.1415\n",
      "Epoch 45/50\n",
      "242/242 [==============================] - 0s 517us/step - loss: 0.4992 - val_loss: 19.9138\n",
      "Epoch 46/50\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4995 - val_loss: 19.8066\n",
      "Epoch 47/50\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.4994 - val_loss: 19.9337\n",
      "Epoch 48/50\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.4994 - val_loss: 19.7600\n",
      "Epoch 49/50\n",
      "242/242 [==============================] - 0s 567us/step - loss: 0.4994 - val_loss: 19.4643\n",
      "Epoch 50/50\n",
      "242/242 [==============================] - 0s 521us/step - loss: 0.4990 - val_loss: 19.6684\n",
      "121/121 [==============================] - 0s 271us/step - loss: 0.9679\n",
      "[CV]  learning_rate=0.003302349014241548, n_hidden=0, n_neurons=36, total=   6.7s\n",
      "[CV] learning_rate=0.003302349014241548, n_hidden=0, n_neurons=36 ....\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 658us/step - loss: 2.2832 - val_loss: 1.0787\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.6926 - val_loss: 3.2978\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 524us/step - loss: 0.6191 - val_loss: 4.1076\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 553us/step - loss: 0.6415 - val_loss: 0.9344\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 557us/step - loss: 0.5683 - val_loss: 2.6496\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 533us/step - loss: 0.5959 - val_loss: 2.9963\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 0s 553us/step - loss: 0.5695 - val_loss: 4.9344\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - 0s 546us/step - loss: 0.6156 - val_loss: 3.8711\n",
      "Epoch 9/50\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.5675 - val_loss: 1.3023\n",
      "Epoch 10/50\n",
      "242/242 [==============================] - 0s 529us/step - loss: 0.5581 - val_loss: 0.7239\n",
      "Epoch 11/50\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.5506 - val_loss: 0.8257\n",
      "Epoch 12/50\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.5351 - val_loss: 1.8310\n",
      "Epoch 13/50\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.5655 - val_loss: 0.5259\n",
      "Epoch 14/50\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.5385 - val_loss: 0.5895\n",
      "Epoch 15/50\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.5432 - val_loss: 0.4963\n",
      "Epoch 16/50\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.5398 - val_loss: 0.6399\n",
      "Epoch 17/50\n",
      "242/242 [==============================] - 0s 550us/step - loss: 0.5258 - val_loss: 1.8482\n",
      "Epoch 18/50\n",
      "242/242 [==============================] - 0s 557us/step - loss: 0.5629 - val_loss: 1.8810\n",
      "Epoch 19/50\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.5408 - val_loss: 0.7666\n",
      "Epoch 20/50\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.5349 - val_loss: 0.8300\n",
      "Epoch 21/50\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.5348 - val_loss: 0.9068\n",
      "Epoch 22/50\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.5423 - val_loss: 0.5153\n",
      "Epoch 23/50\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.5360 - val_loss: 0.5014\n",
      "Epoch 24/50\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.5347 - val_loss: 0.6996\n",
      "Epoch 25/50\n",
      "242/242 [==============================] - 0s 587us/step - loss: 0.5458 - val_loss: 0.6006\n",
      "Epoch 26/50\n",
      "242/242 [==============================] - 0s 579us/step - loss: 0.5365 - val_loss: 0.5928\n",
      "Epoch 27/50\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.5351 - val_loss: 0.5430\n",
      "Epoch 28/50\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.5350 - val_loss: 0.7069\n",
      "Epoch 29/50\n",
      "242/242 [==============================] - 0s 470us/step - loss: 0.5292 - val_loss: 1.0859\n",
      "Epoch 30/50\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.5462 - val_loss: 2.2382\n",
      "Epoch 31/50\n",
      "242/242 [==============================] - 0s 526us/step - loss: 0.5405 - val_loss: 0.5638\n",
      "Epoch 32/50\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.5422 - val_loss: 1.4514\n",
      "Epoch 33/50\n",
      "242/242 [==============================] - 0s 584us/step - loss: 0.5383 - val_loss: 0.5929\n",
      "Epoch 34/50\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.5232 - val_loss: 1.7333\n",
      "Epoch 35/50\n",
      "242/242 [==============================] - 0s 588us/step - loss: 0.5612 - val_loss: 0.6662\n",
      "Epoch 36/50\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.5243 - val_loss: 1.8024\n",
      "Epoch 37/50\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.5522 - val_loss: 0.5063\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 529us/step - loss: 0.5380 - val_loss: 1.4082\n",
      "Epoch 39/50\n",
      "242/242 [==============================] - 0s 525us/step - loss: 0.5374 - val_loss: 0.5303\n",
      "Epoch 40/50\n",
      "242/242 [==============================] - 0s 512us/step - loss: 0.5311 - val_loss: 0.6603\n",
      "Epoch 41/50\n",
      "242/242 [==============================] - 0s 513us/step - loss: 0.5416 - val_loss: 0.8767\n",
      "Epoch 42/50\n",
      "242/242 [==============================] - 0s 557us/step - loss: 0.5335 - val_loss: 0.4952\n",
      "Epoch 43/50\n",
      "242/242 [==============================] - 0s 517us/step - loss: 0.5280 - val_loss: 1.1892\n",
      "Epoch 44/50\n",
      "242/242 [==============================] - 0s 522us/step - loss: 0.5472 - val_loss: 2.3311\n",
      "Epoch 45/50\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.5352 - val_loss: 2.9939\n",
      "Epoch 46/50\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.5731 - val_loss: 1.9082\n",
      "Epoch 47/50\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.5336 - val_loss: 1.5608\n",
      "Epoch 48/50\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.5499 - val_loss: 2.6904\n",
      "Epoch 49/50\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.5372 - val_loss: 2.5576\n",
      "Epoch 50/50\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.5653 - val_loss: 0.5139\n",
      "121/121 [==============================] - 0s 245us/step - loss: 0.5391\n",
      "[CV]  learning_rate=0.003302349014241548, n_hidden=0, n_neurons=36, total=   6.6s\n",
      "[CV] learning_rate=0.006179362576313367, n_hidden=0, n_neurons=47 ....\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 667us/step - loss: 2.0793 - val_loss: 15.7150\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 496us/step - loss: 0.8875 - val_loss: 63.4364\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 503us/step - loss: 1.9942 - val_loss: 123.8664\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 572us/step - loss: 2.4561 - val_loss: 362.1297\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 577us/step - loss: 7.7695 - val_loss: 788.7568\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 527us/step - loss: 9.4122 - val_loss: 1814.0807\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 0s 543us/step - loss: 27.2417 - val_loss: 4167.2358\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - 0s 567us/step - loss: 64.2016 - val_loss: 10037.0586\n",
      "Epoch 9/50\n",
      "242/242 [==============================] - 0s 521us/step - loss: 78.6343 - val_loss: 25148.8457\n",
      "Epoch 10/50\n",
      "242/242 [==============================] - 0s 515us/step - loss: 323.0071 - val_loss: 60284.6328\n",
      "Epoch 11/50\n",
      "242/242 [==============================] - 0s 511us/step - loss: 343.1200 - val_loss: 150941.0469\n",
      "Epoch 12/50\n",
      "242/242 [==============================] - 0s 533us/step - loss: 1946.3380 - val_loss: 367174.2500\n",
      "Epoch 13/50\n",
      "242/242 [==============================] - 0s 469us/step - loss: 6923.4448 - val_loss: 881655.1250\n",
      "Epoch 14/50\n",
      "242/242 [==============================] - 0s 514us/step - loss: 14571.0713 - val_loss: 2120915.7500\n",
      "Epoch 15/50\n",
      "242/242 [==============================] - 0s 521us/step - loss: 27057.9668 - val_loss: 5113376.0000\n",
      "Epoch 16/50\n",
      "242/242 [==============================] - 0s 509us/step - loss: 95259.9688 - val_loss: 12380351.0000\n",
      "Epoch 17/50\n",
      "242/242 [==============================] - 0s 501us/step - loss: 216709.1406 - val_loss: 29678134.0000\n",
      "Epoch 18/50\n",
      "242/242 [==============================] - 0s 476us/step - loss: 337681.4375 - val_loss: 71520952.0000\n",
      "Epoch 19/50\n",
      "242/242 [==============================] - 0s 499us/step - loss: 841138.1875 - val_loss: 171911680.0000\n",
      "Epoch 20/50\n",
      "242/242 [==============================] - 0s 470us/step - loss: 1143671.1250 - val_loss: 416690208.0000\n",
      "Epoch 21/50\n",
      "242/242 [==============================] - 0s 522us/step - loss: 2801384.7500 - val_loss: 1006225152.0000\n",
      "Epoch 22/50\n",
      "242/242 [==============================] - 0s 526us/step - loss: 5538443.5000 - val_loss: 2427943424.0000\n",
      "Epoch 23/50\n",
      "242/242 [==============================] - 0s 563us/step - loss: 13526114.0000 - val_loss: 5831134720.0000\n",
      "Epoch 24/50\n",
      "242/242 [==============================] - 0s 527us/step - loss: 52739724.0000 - val_loss: 13882717184.0000\n",
      "Epoch 25/50\n",
      "242/242 [==============================] - 0s 497us/step - loss: 112835184.0000 - val_loss: 33485715456.0000\n",
      "Epoch 26/50\n",
      "242/242 [==============================] - 0s 488us/step - loss: 353715680.0000 - val_loss: 80974233600.0000\n",
      "Epoch 27/50\n",
      "242/242 [==============================] - 0s 531us/step - loss: 689739520.0000 - val_loss: 195149922304.0000\n",
      "Epoch 28/50\n",
      "242/242 [==============================] - 0s 485us/step - loss: 1440744192.0000 - val_loss: 469784657920.0000\n",
      "Epoch 29/50\n",
      "242/242 [==============================] - 0s 519us/step - loss: 7351519232.0000 - val_loss: 1133737410560.0000\n",
      "Epoch 30/50\n",
      "242/242 [==============================] - 0s 478us/step - loss: 7507119104.0000 - val_loss: 2755744497664.0000\n",
      "Epoch 31/50\n",
      "242/242 [==============================] - 0s 521us/step - loss: 43409780736.0000 - val_loss: 6672444555264.0000\n",
      "Epoch 32/50\n",
      "242/242 [==============================] - 0s 477us/step - loss: 128207224832.0000 - val_loss: 16025616646144.0000\n",
      "Epoch 33/50\n",
      "242/242 [==============================] - 0s 483us/step - loss: 271452110848.0000 - val_loss: 38519514857472.0000\n",
      "Epoch 34/50\n",
      "242/242 [==============================] - 0s 522us/step - loss: 520105689088.0000 - val_loss: 92498059853824.0000\n",
      "Epoch 35/50\n",
      "242/242 [==============================] - 0s 507us/step - loss: 570278019072.0000 - val_loss: 232722870042624.0000\n",
      "Epoch 36/50\n",
      "242/242 [==============================] - 0s 529us/step - loss: 4174290878464.0000 - val_loss: 568401072226304.0000\n",
      "Epoch 37/50\n",
      "242/242 [==============================] - 0s 521us/step - loss: 8372292157440.0000 - val_loss: 1362884256858112.0000\n",
      "Epoch 38/50\n",
      "242/242 [==============================] - 0s 444us/step - loss: 9251060711424.0000 - val_loss: 3330334821187584.0000\n",
      "Epoch 39/50\n",
      "242/242 [==============================] - 0s 524us/step - loss: 18224934551552.0000 - val_loss: 8042422898524160.0000\n",
      "Epoch 40/50\n",
      "242/242 [==============================] - 0s 483us/step - loss: 86295606984704.0000 - val_loss: 19018198938550272.0000\n",
      "Epoch 41/50\n",
      "242/242 [==============================] - 0s 486us/step - loss: 134732494929920.0000 - val_loss: 47980252189687808.0000\n",
      "Epoch 42/50\n",
      "242/242 [==============================] - 0s 485us/step - loss: 873510784204800.0000 - val_loss: 116635136912523264.0000\n",
      "Epoch 43/50\n",
      "242/242 [==============================] - 0s 501us/step - loss: 1303722692968448.0000 - val_loss: 279945332698120192.0000\n",
      "Epoch 44/50\n",
      "242/242 [==============================] - 0s 462us/step - loss: 3606920246067200.0000 - val_loss: 677476665118425088.0000\n",
      "Epoch 45/50\n",
      "242/242 [==============================] - 0s 465us/step - loss: 11554222235451392.0000 - val_loss: 1711230969203130368.0000\n",
      "Epoch 46/50\n",
      "242/242 [==============================] - 0s 483us/step - loss: 10935301341970432.0000 - val_loss: 4180841287571734528.0000\n",
      "Epoch 47/50\n",
      "242/242 [==============================] - 0s 508us/step - loss: 33601343780290560.0000 - val_loss: 10037354788548509696.0000\n",
      "Epoch 48/50\n",
      "242/242 [==============================] - 0s 514us/step - loss: 72868346424459264.0000 - val_loss: 32401277261489111040.0000\n",
      "Epoch 49/50\n",
      "242/242 [==============================] - 0s 491us/step - loss: 400434369535148032.0000 - val_loss: 77581575640246648832.0000\n",
      "Epoch 50/50\n",
      "242/242 [==============================] - 0s 487us/step - loss: 507500516880678912.0000 - val_loss: 188473797225920593920.0000\n",
      "121/121 [==============================] - 0s 242us/step - loss: 505416598748659712.0000\n",
      "[CV]  learning_rate=0.006179362576313367, n_hidden=0, n_neurons=47, total=   6.4s\n",
      "[CV] learning_rate=0.006179362576313367, n_hidden=0, n_neurons=47 ....\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 711us/step - loss: 1.7215 - val_loss: 4.5882\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.6134 - val_loss: 1.0396\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.5575 - val_loss: 5.9273\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 528us/step - loss: 0.5323 - val_loss: 10.9855\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.5205 - val_loss: 14.0099\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.5117 - val_loss: 17.5521\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.5106 - val_loss: 17.8235\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.5077 - val_loss: 19.4711\n",
      "Epoch 9/50\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.5052 - val_loss: 20.1474\n",
      "Epoch 10/50\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.5037 - val_loss: 20.7977\n",
      "Epoch 11/50\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.5021 - val_loss: 19.7214\n",
      "Epoch 12/50\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.5035 - val_loss: 18.5316\n",
      "Epoch 13/50\n",
      "242/242 [==============================] - 0s 533us/step - loss: 0.5004 - val_loss: 19.7205\n",
      "Epoch 14/50\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.5010 - val_loss: 19.0859\n",
      "Epoch 15/50\n",
      "242/242 [==============================] - 0s 542us/step - loss: 0.5017 - val_loss: 19.6362\n",
      "Epoch 16/50\n",
      "242/242 [==============================] - 0s 539us/step - loss: 0.5016 - val_loss: 19.7681\n",
      "Epoch 17/50\n",
      "242/242 [==============================] - 0s 559us/step - loss: 0.5020 - val_loss: 18.4221\n",
      "Epoch 18/50\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.5000 - val_loss: 20.3541\n",
      "Epoch 19/50\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.5014 - val_loss: 20.7492\n",
      "Epoch 20/50\n",
      "242/242 [==============================] - 0s 517us/step - loss: 0.5016 - val_loss: 21.3097\n",
      "Epoch 21/50\n",
      "242/242 [==============================] - 0s 539us/step - loss: 0.5011 - val_loss: 20.1310\n",
      "Epoch 22/50\n",
      "242/242 [==============================] - 0s 526us/step - loss: 0.5014 - val_loss: 19.8429\n",
      "Epoch 23/50\n",
      "242/242 [==============================] - 0s 550us/step - loss: 0.5016 - val_loss: 20.5262\n",
      "Epoch 24/50\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.5015 - val_loss: 19.8570\n",
      "Epoch 25/50\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.5017 - val_loss: 18.9569\n",
      "Epoch 26/50\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.5016 - val_loss: 19.6112\n",
      "Epoch 27/50\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.5004 - val_loss: 20.0307\n",
      "Epoch 28/50\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.5009 - val_loss: 18.9875\n",
      "Epoch 29/50\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.5017 - val_loss: 18.0031\n",
      "Epoch 30/50\n",
      "242/242 [==============================] - 0s 520us/step - loss: 0.5009 - val_loss: 18.1271\n",
      "Epoch 31/50\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.4995 - val_loss: 20.1207\n",
      "Epoch 32/50\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.5016 - val_loss: 18.5930\n",
      "Epoch 33/50\n",
      "242/242 [==============================] - 0s 524us/step - loss: 0.5000 - val_loss: 19.6811\n",
      "Epoch 34/50\n",
      "242/242 [==============================] - 0s 516us/step - loss: 0.5007 - val_loss: 20.9913\n",
      "Epoch 35/50\n",
      "242/242 [==============================] - 0s 567us/step - loss: 0.5015 - val_loss: 21.0530\n",
      "Epoch 36/50\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.5012 - val_loss: 21.2228\n",
      "Epoch 37/50\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.5012 - val_loss: 18.8118\n",
      "Epoch 38/50\n",
      "242/242 [==============================] - 0s 570us/step - loss: 0.5010 - val_loss: 20.1419\n",
      "Epoch 39/50\n",
      "242/242 [==============================] - 0s 516us/step - loss: 0.5008 - val_loss: 20.3923\n",
      "Epoch 40/50\n",
      "242/242 [==============================] - 0s 504us/step - loss: 0.5014 - val_loss: 21.1184\n",
      "Epoch 41/50\n",
      "242/242 [==============================] - 0s 557us/step - loss: 0.5016 - val_loss: 21.1279\n",
      "Epoch 42/50\n",
      "242/242 [==============================] - 0s 538us/step - loss: 0.5014 - val_loss: 20.6741\n",
      "Epoch 43/50\n",
      "242/242 [==============================] - 0s 529us/step - loss: 0.5008 - val_loss: 19.6268\n",
      "Epoch 44/50\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.5017 - val_loss: 17.5190\n",
      "Epoch 45/50\n",
      "242/242 [==============================] - 0s 555us/step - loss: 0.5015 - val_loss: 17.8369\n",
      "Epoch 46/50\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.5007 - val_loss: 18.9775\n",
      "Epoch 47/50\n",
      "242/242 [==============================] - 0s 542us/step - loss: 0.5009 - val_loss: 18.6786\n",
      "Epoch 48/50\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.5021 - val_loss: 19.2017\n",
      "Epoch 49/50\n",
      "242/242 [==============================] - 0s 562us/step - loss: 0.5017 - val_loss: 18.0333\n",
      "Epoch 50/50\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.5014 - val_loss: 17.8281\n",
      "121/121 [==============================] - 0s 246us/step - loss: 0.9245\n",
      "[CV]  learning_rate=0.006179362576313367, n_hidden=0, n_neurons=47, total=   6.6s\n",
      "[CV] learning_rate=0.006179362576313367, n_hidden=0, n_neurons=47 ....\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 696us/step - loss: 1.8174 - val_loss: 57.4588\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 523us/step - loss: 1.2926 - val_loss: 118.2220\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 555us/step - loss: 2.4633 - val_loss: 212.3308\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 542us/step - loss: 1.7846 - val_loss: 427.7787\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 507us/step - loss: 2.0719 - val_loss: 630.3652\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 552us/step - loss: 14.1983 - val_loss: 848.8133\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 0s 519us/step - loss: 5.2779 - val_loss: 1143.3094\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - 0s 517us/step - loss: 11.5448 - val_loss: 1682.2394\n",
      "Epoch 9/50\n",
      "242/242 [==============================] - 0s 540us/step - loss: 9.3713 - val_loss: 2303.3364\n",
      "Epoch 10/50\n",
      "242/242 [==============================] - 0s 559us/step - loss: 11.1384 - val_loss: 3862.8684\n",
      "Epoch 11/50\n",
      "242/242 [==============================] - 0s 568us/step - loss: 65.9136 - val_loss: 6241.4819\n",
      "Epoch 12/50\n",
      "242/242 [==============================] - 0s 558us/step - loss: 65.4227 - val_loss: 9336.2900\n",
      "Epoch 13/50\n",
      "242/242 [==============================] - 0s 558us/step - loss: 55.6251 - val_loss: 13291.5264\n",
      "Epoch 14/50\n",
      "242/242 [==============================] - 0s 567us/step - loss: 245.5703 - val_loss: 19616.8477\n",
      "Epoch 15/50\n",
      "242/242 [==============================] - 0s 541us/step - loss: 155.8423 - val_loss: 28382.0273\n",
      "Epoch 16/50\n",
      "242/242 [==============================] - 0s 531us/step - loss: 432.2971 - val_loss: 41815.7344\n",
      "Epoch 17/50\n",
      "242/242 [==============================] - 0s 530us/step - loss: 299.6628 - val_loss: 61360.3047\n",
      "Epoch 18/50\n",
      "242/242 [==============================] - 0s 504us/step - loss: 414.4362 - val_loss: 90718.7422\n",
      "Epoch 19/50\n",
      "242/242 [==============================] - 0s 528us/step - loss: 1748.6177 - val_loss: 135550.3594\n",
      "Epoch 20/50\n",
      "242/242 [==============================] - 0s 535us/step - loss: 952.3314 - val_loss: 200379.8594\n",
      "Epoch 21/50\n",
      "242/242 [==============================] - 0s 540us/step - loss: 1047.1942 - val_loss: 294761.9375\n",
      "Epoch 22/50\n",
      "242/242 [==============================] - 0s 494us/step - loss: 1418.5598 - val_loss: 440645.6250\n",
      "Epoch 23/50\n",
      "242/242 [==============================] - 0s 536us/step - loss: 2314.3838 - val_loss: 644486.4375\n",
      "Epoch 24/50\n",
      "242/242 [==============================] - 0s 508us/step - loss: 11826.3369 - val_loss: 950414.1250\n",
      "Epoch 25/50\n",
      "242/242 [==============================] - 0s 484us/step - loss: 6995.3257 - val_loss: 1401529.1250\n",
      "Epoch 26/50\n",
      "242/242 [==============================] - 0s 514us/step - loss: 13271.9141 - val_loss: 2074055.1250\n",
      "Epoch 27/50\n",
      "242/242 [==============================] - 0s 527us/step - loss: 30099.7012 - val_loss: 3063115.0000\n",
      "Epoch 28/50\n",
      "242/242 [==============================] - 0s 510us/step - loss: 13703.4912 - val_loss: 4579668.5000\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 506us/step - loss: 19531.3438 - val_loss: 6725307.0000\n",
      "Epoch 30/50\n",
      "242/242 [==============================] - 0s 453us/step - loss: 43076.9844 - val_loss: 9853913.0000\n",
      "Epoch 31/50\n",
      "242/242 [==============================] - 0s 510us/step - loss: 124013.9766 - val_loss: 14638027.0000\n",
      "Epoch 32/50\n",
      "242/242 [==============================] - 0s 551us/step - loss: 62310.8242 - val_loss: 22010732.0000\n",
      "Epoch 33/50\n",
      "242/242 [==============================] - 0s 470us/step - loss: 128472.1094 - val_loss: 32166202.0000\n",
      "Epoch 34/50\n",
      "242/242 [==============================] - 0s 493us/step - loss: 629701.0625 - val_loss: 47641864.0000\n",
      "Epoch 35/50\n",
      "242/242 [==============================] - 0s 498us/step - loss: 450994.8125 - val_loss: 70195512.0000\n",
      "Epoch 36/50\n",
      "242/242 [==============================] - 0s 476us/step - loss: 1299679.3750 - val_loss: 103581256.0000\n",
      "Epoch 37/50\n",
      "242/242 [==============================] - 0s 503us/step - loss: 513337.6562 - val_loss: 147728208.0000\n",
      "Epoch 38/50\n",
      "242/242 [==============================] - 0s 517us/step - loss: 605043.2500 - val_loss: 219386608.0000\n",
      "Epoch 39/50\n",
      "242/242 [==============================] - 0s 531us/step - loss: 890125.1875 - val_loss: 323736960.0000\n",
      "Epoch 40/50\n",
      "242/242 [==============================] - 0s 576us/step - loss: 1907738.5000 - val_loss: 473413632.0000\n",
      "Epoch 41/50\n",
      "242/242 [==============================] - 0s 626us/step - loss: 8521305.0000 - val_loss: 699524992.0000\n",
      "Epoch 42/50\n",
      "242/242 [==============================] - 0s 621us/step - loss: 7937783.0000 - val_loss: 1032592704.0000\n",
      "Epoch 43/50\n",
      "242/242 [==============================] - 0s 658us/step - loss: 7024181.0000 - val_loss: 1540743808.0000\n",
      "Epoch 44/50\n",
      "242/242 [==============================] - 0s 661us/step - loss: 19515184.0000 - val_loss: 2254391040.0000\n",
      "Epoch 45/50\n",
      "242/242 [==============================] - 0s 662us/step - loss: 9859568.0000 - val_loss: 3487465472.0000\n",
      "Epoch 46/50\n",
      "242/242 [==============================] - 0s 609us/step - loss: 36199868.0000 - val_loss: 5175597056.0000\n",
      "Epoch 47/50\n",
      "242/242 [==============================] - 0s 670us/step - loss: 28003678.0000 - val_loss: 7712137216.0000\n",
      "Epoch 48/50\n",
      "242/242 [==============================] - 0s 619us/step - loss: 123514736.0000 - val_loss: 11450249216.0000\n",
      "Epoch 49/50\n",
      "242/242 [==============================] - 0s 634us/step - loss: 58619400.0000 - val_loss: 16970445824.0000\n",
      "Epoch 50/50\n",
      "242/242 [==============================] - 0s 616us/step - loss: 333038048.0000 - val_loss: 25230303232.0000\n",
      "121/121 [==============================] - 0s 326us/step - loss: 26883894.0000\n",
      "[CV]  learning_rate=0.006179362576313367, n_hidden=0, n_neurons=47, total=   6.9s\n",
      "[CV] learning_rate=0.00046594725361364547, n_hidden=2, n_neurons=14 ..\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 906us/step - loss: 3.4196 - val_loss: 6.9447\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 685us/step - loss: 1.8627 - val_loss: 3.8485\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 705us/step - loss: 1.2846 - val_loss: 1.9099\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 695us/step - loss: 1.0528 - val_loss: 1.0987\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 719us/step - loss: 0.9393 - val_loss: 0.8794\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 659us/step - loss: 0.8742 - val_loss: 0.8127\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.8312 - val_loss: 0.7842\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - 0s 733us/step - loss: 0.8004 - val_loss: 0.7592\n",
      "Epoch 9/50\n",
      "242/242 [==============================] - 0s 674us/step - loss: 0.7767 - val_loss: 0.7348\n",
      "Epoch 10/50\n",
      "242/242 [==============================] - 0s 706us/step - loss: 0.7569 - val_loss: 0.7210\n",
      "Epoch 11/50\n",
      "242/242 [==============================] - 0s 704us/step - loss: 0.7401 - val_loss: 0.7055\n",
      "Epoch 12/50\n",
      "242/242 [==============================] - 0s 679us/step - loss: 0.7252 - val_loss: 0.6892\n",
      "Epoch 13/50\n",
      "242/242 [==============================] - 0s 657us/step - loss: 0.7120 - val_loss: 0.6778\n",
      "Epoch 14/50\n",
      "242/242 [==============================] - 0s 650us/step - loss: 0.6996 - val_loss: 0.6669\n",
      "Epoch 15/50\n",
      "242/242 [==============================] - 0s 674us/step - loss: 0.6882 - val_loss: 0.6534\n",
      "Epoch 16/50\n",
      "242/242 [==============================] - 0s 690us/step - loss: 0.6774 - val_loss: 0.6441\n",
      "Epoch 17/50\n",
      "242/242 [==============================] - 0s 602us/step - loss: 0.6675 - val_loss: 0.6351\n",
      "Epoch 18/50\n",
      "242/242 [==============================] - 0s 652us/step - loss: 0.6581 - val_loss: 0.6252\n",
      "Epoch 19/50\n",
      "242/242 [==============================] - 0s 671us/step - loss: 0.6492 - val_loss: 0.6193\n",
      "Epoch 20/50\n",
      "242/242 [==============================] - 0s 658us/step - loss: 0.6407 - val_loss: 0.6083\n",
      "Epoch 21/50\n",
      "242/242 [==============================] - 0s 671us/step - loss: 0.6326 - val_loss: 0.6043\n",
      "Epoch 22/50\n",
      "242/242 [==============================] - 0s 653us/step - loss: 0.6247 - val_loss: 0.5956\n",
      "Epoch 23/50\n",
      "242/242 [==============================] - 0s 656us/step - loss: 0.6170 - val_loss: 0.5861\n",
      "Epoch 24/50\n",
      "242/242 [==============================] - 0s 723us/step - loss: 0.6096 - val_loss: 0.5795\n",
      "Epoch 25/50\n",
      "242/242 [==============================] - 0s 712us/step - loss: 0.6024 - val_loss: 0.5721\n",
      "Epoch 26/50\n",
      "242/242 [==============================] - 0s 648us/step - loss: 0.5953 - val_loss: 0.5625\n",
      "Epoch 27/50\n",
      "242/242 [==============================] - 0s 666us/step - loss: 0.5885 - val_loss: 0.5541\n",
      "Epoch 28/50\n",
      "242/242 [==============================] - 0s 679us/step - loss: 0.5817 - val_loss: 0.5476\n",
      "Epoch 29/50\n",
      "242/242 [==============================] - 0s 702us/step - loss: 0.5751 - val_loss: 0.5393\n",
      "Epoch 30/50\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.5686 - val_loss: 0.5330\n",
      "Epoch 31/50\n",
      "242/242 [==============================] - 0s 679us/step - loss: 0.5623 - val_loss: 0.5271\n",
      "Epoch 32/50\n",
      "242/242 [==============================] - 0s 680us/step - loss: 0.5563 - val_loss: 0.5206\n",
      "Epoch 33/50\n",
      "242/242 [==============================] - 0s 682us/step - loss: 0.5502 - val_loss: 0.5150\n",
      "Epoch 34/50\n",
      "242/242 [==============================] - 0s 666us/step - loss: 0.5443 - val_loss: 0.5094\n",
      "Epoch 35/50\n",
      "242/242 [==============================] - 0s 656us/step - loss: 0.5386 - val_loss: 0.5040\n",
      "Epoch 36/50\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.5328 - val_loss: 0.4994\n",
      "Epoch 37/50\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.5274 - val_loss: 0.4938\n",
      "Epoch 38/50\n",
      "242/242 [==============================] - 0s 638us/step - loss: 0.5220 - val_loss: 0.4896\n",
      "Epoch 39/50\n",
      "242/242 [==============================] - 0s 670us/step - loss: 0.5169 - val_loss: 0.4842\n",
      "Epoch 40/50\n",
      "242/242 [==============================] - 0s 669us/step - loss: 0.5119 - val_loss: 0.4795\n",
      "Epoch 41/50\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.5071 - val_loss: 0.4750\n",
      "Epoch 42/50\n",
      "242/242 [==============================] - 0s 686us/step - loss: 0.5022 - val_loss: 0.4706\n",
      "Epoch 43/50\n",
      "242/242 [==============================] - 0s 634us/step - loss: 0.4977 - val_loss: 0.4668\n",
      "Epoch 44/50\n",
      "242/242 [==============================] - 0s 622us/step - loss: 0.4931 - val_loss: 0.4623\n",
      "Epoch 45/50\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.4887 - val_loss: 0.4588\n",
      "Epoch 46/50\n",
      "242/242 [==============================] - 0s 656us/step - loss: 0.4845 - val_loss: 0.4550\n",
      "Epoch 47/50\n",
      "242/242 [==============================] - 0s 685us/step - loss: 0.4803 - val_loss: 0.4508\n",
      "Epoch 48/50\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.4764 - val_loss: 0.4483\n",
      "Epoch 49/50\n",
      "242/242 [==============================] - 0s 652us/step - loss: 0.4726 - val_loss: 0.4441\n",
      "Epoch 50/50\n",
      "242/242 [==============================] - 0s 657us/step - loss: 0.4689 - val_loss: 0.4424\n",
      "121/121 [==============================] - 0s 280us/step - loss: 0.4681\n",
      "[CV]  learning_rate=0.00046594725361364547, n_hidden=2, n_neurons=14, total=   8.5s\n",
      "[CV] learning_rate=0.00046594725361364547, n_hidden=2, n_neurons=14 ..\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 868us/step - loss: 2.8275 - val_loss: 2.7195\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 645us/step - loss: 1.2711 - val_loss: 3.1046\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 669us/step - loss: 0.9576 - val_loss: 2.8682\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 653us/step - loss: 0.8233 - val_loss: 2.5182\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 670us/step - loss: 0.7434 - val_loss: 2.1426\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 680us/step - loss: 0.6919 - val_loss: 1.8445\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 0s 698us/step - loss: 0.6569 - val_loss: 1.5810\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.6308 - val_loss: 1.3552\n",
      "Epoch 9/50\n",
      "242/242 [==============================] - 0s 613us/step - loss: 0.6100 - val_loss: 1.1584\n",
      "Epoch 10/50\n",
      "242/242 [==============================] - 0s 682us/step - loss: 0.5926 - val_loss: 1.0027\n",
      "Epoch 11/50\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.5778 - val_loss: 0.8737\n",
      "Epoch 12/50\n",
      "242/242 [==============================] - 0s 663us/step - loss: 0.5647 - val_loss: 0.7908\n",
      "Epoch 13/50\n",
      "242/242 [==============================] - 0s 625us/step - loss: 0.5529 - val_loss: 0.7207\n",
      "Epoch 14/50\n",
      "242/242 [==============================] - 0s 669us/step - loss: 0.5423 - val_loss: 0.6644\n",
      "Epoch 15/50\n",
      "242/242 [==============================] - 0s 682us/step - loss: 0.5323 - val_loss: 0.6143\n",
      "Epoch 16/50\n",
      "242/242 [==============================] - 0s 653us/step - loss: 0.5231 - val_loss: 0.5730\n",
      "Epoch 17/50\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.5145 - val_loss: 0.5419\n",
      "Epoch 18/50\n",
      "242/242 [==============================] - 0s 632us/step - loss: 0.5063 - val_loss: 0.5158\n",
      "Epoch 19/50\n",
      "242/242 [==============================] - 0s 637us/step - loss: 0.4988 - val_loss: 0.4948\n",
      "Epoch 20/50\n",
      "242/242 [==============================] - 0s 661us/step - loss: 0.4916 - val_loss: 0.4789\n",
      "Epoch 21/50\n",
      "242/242 [==============================] - 0s 677us/step - loss: 0.4850 - val_loss: 0.4668\n",
      "Epoch 22/50\n",
      "242/242 [==============================] - 0s 634us/step - loss: 0.4789 - val_loss: 0.4596\n",
      "Epoch 23/50\n",
      "242/242 [==============================] - 0s 678us/step - loss: 0.4731 - val_loss: 0.4520\n",
      "Epoch 24/50\n",
      "242/242 [==============================] - 0s 628us/step - loss: 0.4677 - val_loss: 0.4469\n",
      "Epoch 25/50\n",
      "242/242 [==============================] - 0s 641us/step - loss: 0.4626 - val_loss: 0.4426\n",
      "Epoch 26/50\n",
      "242/242 [==============================] - 0s 583us/step - loss: 0.4580 - val_loss: 0.4388\n",
      "Epoch 27/50\n",
      "242/242 [==============================] - 0s 580us/step - loss: 0.4537 - val_loss: 0.4354\n",
      "Epoch 28/50\n",
      "242/242 [==============================] - 0s 645us/step - loss: 0.4497 - val_loss: 0.4325\n",
      "Epoch 29/50\n",
      "242/242 [==============================] - 0s 687us/step - loss: 0.4463 - val_loss: 0.4302\n",
      "Epoch 30/50\n",
      "242/242 [==============================] - 0s 635us/step - loss: 0.4430 - val_loss: 0.4285\n",
      "Epoch 31/50\n",
      "242/242 [==============================] - 0s 591us/step - loss: 0.4401 - val_loss: 0.4266\n",
      "Epoch 32/50\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.4374 - val_loss: 0.4249\n",
      "Epoch 33/50\n",
      "242/242 [==============================] - 0s 604us/step - loss: 0.4348 - val_loss: 0.4233\n",
      "Epoch 34/50\n",
      "242/242 [==============================] - 0s 621us/step - loss: 0.4324 - val_loss: 0.4220\n",
      "Epoch 35/50\n",
      "242/242 [==============================] - 0s 644us/step - loss: 0.4305 - val_loss: 0.4204\n",
      "Epoch 36/50\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.4284 - val_loss: 0.4191\n",
      "Epoch 37/50\n",
      "242/242 [==============================] - 0s 619us/step - loss: 0.4266 - val_loss: 0.4178\n",
      "Epoch 38/50\n",
      "242/242 [==============================] - 0s 671us/step - loss: 0.4250 - val_loss: 0.4163\n",
      "Epoch 39/50\n",
      "242/242 [==============================] - 0s 624us/step - loss: 0.4235 - val_loss: 0.4147\n",
      "Epoch 40/50\n",
      "242/242 [==============================] - 0s 600us/step - loss: 0.4222 - val_loss: 0.4128\n",
      "Epoch 41/50\n",
      "242/242 [==============================] - 0s 619us/step - loss: 0.4209 - val_loss: 0.4111\n",
      "Epoch 42/50\n",
      "242/242 [==============================] - 0s 630us/step - loss: 0.4196 - val_loss: 0.4094\n",
      "Epoch 43/50\n",
      "242/242 [==============================] - 0s 631us/step - loss: 0.4184 - val_loss: 0.4079\n",
      "Epoch 44/50\n",
      "242/242 [==============================] - 0s 600us/step - loss: 0.4173 - val_loss: 0.4062\n",
      "Epoch 45/50\n",
      "242/242 [==============================] - 0s 624us/step - loss: 0.4163 - val_loss: 0.4045\n",
      "Epoch 46/50\n",
      "242/242 [==============================] - 0s 584us/step - loss: 0.4153 - val_loss: 0.4030\n",
      "Epoch 47/50\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.4142 - val_loss: 0.4015\n",
      "Epoch 48/50\n",
      "242/242 [==============================] - 0s 615us/step - loss: 0.4135 - val_loss: 0.4000\n",
      "Epoch 49/50\n",
      "242/242 [==============================] - 0s 657us/step - loss: 0.4125 - val_loss: 0.3987\n",
      "Epoch 50/50\n",
      "242/242 [==============================] - 0s 653us/step - loss: 0.4117 - val_loss: 0.3970\n",
      "121/121 [==============================] - 0s 311us/step - loss: 0.4203\n",
      "[CV]  learning_rate=0.00046594725361364547, n_hidden=2, n_neurons=14, total=   8.1s\n",
      "[CV] learning_rate=0.00046594725361364547, n_hidden=2, n_neurons=14 ..\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 825us/step - loss: 5.7469 - val_loss: 3.4025\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 630us/step - loss: 2.3847 - val_loss: 1.6458\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 640us/step - loss: 1.3388 - val_loss: 1.4940\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 609us/step - loss: 1.0241 - val_loss: 1.4560\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 670us/step - loss: 0.8993 - val_loss: 1.3473\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 670us/step - loss: 0.8318 - val_loss: 1.2101\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 0s 703us/step - loss: 0.7906 - val_loss: 1.0986\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - 0s 619us/step - loss: 0.7638 - val_loss: 0.9883\n",
      "Epoch 9/50\n",
      "242/242 [==============================] - 0s 656us/step - loss: 0.7445 - val_loss: 0.9072\n",
      "Epoch 10/50\n",
      "242/242 [==============================] - 0s 622us/step - loss: 0.7288 - val_loss: 0.8388\n",
      "Epoch 11/50\n",
      "242/242 [==============================] - 0s 625us/step - loss: 0.7157 - val_loss: 0.7844\n",
      "Epoch 12/50\n",
      "242/242 [==============================] - 0s 685us/step - loss: 0.7039 - val_loss: 0.7372\n",
      "Epoch 13/50\n",
      "242/242 [==============================] - 0s 636us/step - loss: 0.6933 - val_loss: 0.7048\n",
      "Epoch 14/50\n",
      "242/242 [==============================] - 0s 682us/step - loss: 0.6833 - val_loss: 0.6828\n",
      "Epoch 15/50\n",
      "242/242 [==============================] - 0s 694us/step - loss: 0.6738 - val_loss: 0.6613\n",
      "Epoch 16/50\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.6646 - val_loss: 0.6454\n",
      "Epoch 17/50\n",
      "242/242 [==============================] - 0s 640us/step - loss: 0.6558 - val_loss: 0.6322\n",
      "Epoch 18/50\n",
      "242/242 [==============================] - 0s 632us/step - loss: 0.6473 - val_loss: 0.6214\n",
      "Epoch 19/50\n",
      "242/242 [==============================] - 0s 608us/step - loss: 0.6390 - val_loss: 0.6107\n",
      "Epoch 20/50\n",
      "242/242 [==============================] - 0s 592us/step - loss: 0.6310 - val_loss: 0.6027\n",
      "Epoch 21/50\n",
      "242/242 [==============================] - 0s 648us/step - loss: 0.6229 - val_loss: 0.5929\n",
      "Epoch 22/50\n",
      "242/242 [==============================] - 0s 630us/step - loss: 0.6150 - val_loss: 0.5849\n",
      "Epoch 23/50\n",
      "242/242 [==============================] - 0s 625us/step - loss: 0.6074 - val_loss: 0.5742\n",
      "Epoch 24/50\n",
      "242/242 [==============================] - 0s 661us/step - loss: 0.5997 - val_loss: 0.5669\n",
      "Epoch 25/50\n",
      "242/242 [==============================] - 0s 602us/step - loss: 0.5921 - val_loss: 0.5586\n",
      "Epoch 26/50\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.5846 - val_loss: 0.5517\n",
      "Epoch 27/50\n",
      "242/242 [==============================] - 0s 630us/step - loss: 0.5772 - val_loss: 0.5453\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 630us/step - loss: 0.5701 - val_loss: 0.5374\n",
      "Epoch 29/50\n",
      "242/242 [==============================] - 0s 612us/step - loss: 0.5630 - val_loss: 0.5313\n",
      "Epoch 30/50\n",
      "242/242 [==============================] - 0s 615us/step - loss: 0.5560 - val_loss: 0.5243\n",
      "Epoch 31/50\n",
      "242/242 [==============================] - 0s 630us/step - loss: 0.5491 - val_loss: 0.5175\n",
      "Epoch 32/50\n",
      "242/242 [==============================] - 0s 626us/step - loss: 0.5423 - val_loss: 0.5108\n",
      "Epoch 33/50\n",
      "242/242 [==============================] - 0s 683us/step - loss: 0.5359 - val_loss: 0.5049\n",
      "Epoch 34/50\n",
      "242/242 [==============================] - 0s 632us/step - loss: 0.5295 - val_loss: 0.4994\n",
      "Epoch 35/50\n",
      "242/242 [==============================] - 0s 624us/step - loss: 0.5237 - val_loss: 0.4925\n",
      "Epoch 36/50\n",
      "242/242 [==============================] - 0s 611us/step - loss: 0.5177 - val_loss: 0.4868\n",
      "Epoch 37/50\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.5121 - val_loss: 0.4829\n",
      "Epoch 38/50\n",
      "242/242 [==============================] - 0s 605us/step - loss: 0.5068 - val_loss: 0.4794\n",
      "Epoch 39/50\n",
      "242/242 [==============================] - 0s 602us/step - loss: 0.5017 - val_loss: 0.4748\n",
      "Epoch 40/50\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.4968 - val_loss: 0.4661\n",
      "Epoch 41/50\n",
      "242/242 [==============================] - 0s 613us/step - loss: 0.4923 - val_loss: 0.4629\n",
      "Epoch 42/50\n",
      "242/242 [==============================] - 0s 598us/step - loss: 0.4882 - val_loss: 0.4570\n",
      "Epoch 43/50\n",
      "242/242 [==============================] - 0s 619us/step - loss: 0.4841 - val_loss: 0.4515\n",
      "Epoch 44/50\n",
      "242/242 [==============================] - 0s 620us/step - loss: 0.4802 - val_loss: 0.4480\n",
      "Epoch 45/50\n",
      "242/242 [==============================] - 0s 571us/step - loss: 0.4766 - val_loss: 0.4448\n",
      "Epoch 46/50\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.4730 - val_loss: 0.4411\n",
      "Epoch 47/50\n",
      "242/242 [==============================] - 0s 595us/step - loss: 0.4696 - val_loss: 0.4366\n",
      "Epoch 48/50\n",
      "242/242 [==============================] - 0s 593us/step - loss: 0.4668 - val_loss: 0.4341\n",
      "Epoch 49/50\n",
      "242/242 [==============================] - 0s 599us/step - loss: 0.4636 - val_loss: 0.4318\n",
      "Epoch 50/50\n",
      "242/242 [==============================] - 0s 649us/step - loss: 0.4608 - val_loss: 0.4301\n",
      "121/121 [==============================] - 0s 303us/step - loss: 0.4617\n",
      "[CV]  learning_rate=0.00046594725361364547, n_hidden=2, n_neurons=14, total=   8.0s\n",
      "[CV] learning_rate=0.015460888941140918, n_hidden=0, n_neurons=79 ....\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 764us/step - loss: 0.9692 - val_loss: 204.6422\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 589us/step - loss: 2.5720 - val_loss: 1023.2737\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 545us/step - loss: 18.5937 - val_loss: 5323.2715\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 559us/step - loss: 19.2983 - val_loss: 21649.3086\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 539us/step - loss: 373.4985 - val_loss: 111262.8359\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 540us/step - loss: 5771.5435 - val_loss: 559329.0000\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 0s 534us/step - loss: 4965.3423 - val_loss: 2938539.2500\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - 0s 556us/step - loss: 31844.2109 - val_loss: 14032540.0000\n",
      "Epoch 9/50\n",
      "242/242 [==============================] - 0s 549us/step - loss: 113589.1172 - val_loss: 68999976.0000\n",
      "Epoch 10/50\n",
      "242/242 [==============================] - 0s 546us/step - loss: 634313.8125 - val_loss: 339888256.0000\n",
      "Epoch 11/50\n",
      "242/242 [==============================] - 0s 535us/step - loss: 7637566.0000 - val_loss: 1708626816.0000\n",
      "Epoch 12/50\n",
      "242/242 [==============================] - 0s 535us/step - loss: 10252277.0000 - val_loss: 8422994944.0000\n",
      "Epoch 13/50\n",
      "242/242 [==============================] - 0s 537us/step - loss: 54371580.0000 - val_loss: 40935919616.0000\n",
      "Epoch 14/50\n",
      "242/242 [==============================] - 0s 569us/step - loss: 1648633344.0000 - val_loss: 199621165056.0000\n",
      "Epoch 15/50\n",
      "242/242 [==============================] - 0s 575us/step - loss: 729537472.0000 - val_loss: 987468201984.0000\n",
      "Epoch 16/50\n",
      "242/242 [==============================] - 0s 580us/step - loss: 43155169280.0000 - val_loss: 4841147990016.0000\n",
      "Epoch 17/50\n",
      "242/242 [==============================] - 0s 525us/step - loss: 11698083840.0000 - val_loss: 25536275415040.0000\n",
      "Epoch 18/50\n",
      "242/242 [==============================] - 0s 573us/step - loss: 281843761152.0000 - val_loss: 122511610085376.0000\n",
      "Epoch 19/50\n",
      "242/242 [==============================] - 0s 562us/step - loss: 829550100480.0000 - val_loss: 603854282424320.0000\n",
      "Epoch 20/50\n",
      "242/242 [==============================] - 0s 559us/step - loss: 29987415523328.0000 - val_loss: 3111598042382336.0000\n",
      "Epoch 21/50\n",
      "242/242 [==============================] - 0s 582us/step - loss: 43338933731328.0000 - val_loss: 15609273732038656.0000\n",
      "Epoch 22/50\n",
      "242/242 [==============================] - 0s 557us/step - loss: 350669147996160.0000 - val_loss: 76697996963610624.0000\n",
      "Epoch 23/50\n",
      "242/242 [==============================] - 0s 592us/step - loss: 299188764016640.0000 - val_loss: 396189807975333888.0000\n",
      "Epoch 24/50\n",
      "242/242 [==============================] - 0s 573us/step - loss: 6034657757888512.0000 - val_loss: 1931811830871621632.0000\n",
      "Epoch 25/50\n",
      "242/242 [==============================] - 0s 582us/step - loss: 4707232616808448.0000 - val_loss: 9708283052983058432.0000\n",
      "Epoch 26/50\n",
      "242/242 [==============================] - 0s 578us/step - loss: 114546889453469696.0000 - val_loss: 47803119595142774784.0000\n",
      "Epoch 27/50\n",
      "242/242 [==============================] - 0s 569us/step - loss: 148383956071350272.0000 - val_loss: 244123335262082170880.0000\n",
      "Epoch 28/50\n",
      "242/242 [==============================] - 0s 541us/step - loss: 4776108636512452608.0000 - val_loss: 1181760586295690657792.0000\n",
      "Epoch 29/50\n",
      "242/242 [==============================] - 0s 569us/step - loss: 9315558390262398976.0000 - val_loss: 5822853702914924347392.0000\n",
      "Epoch 30/50\n",
      "242/242 [==============================] - 0s 572us/step - loss: 39260503585555742720.0000 - val_loss: 28704057016615673266176.0000\n",
      "Epoch 31/50\n",
      "242/242 [==============================] - 0s 573us/step - loss: 361293117331473432576.0000 - val_loss: 141556098652395880316928.0000\n",
      "Epoch 32/50\n",
      "242/242 [==============================] - 0s 573us/step - loss: 7038195661307079819264.0000 - val_loss: 692734903655657067511808.0000\n",
      "Epoch 33/50\n",
      "242/242 [==============================] - 0s 572us/step - loss: 2583909886906337329152.0000 - val_loss: 3548490629916568793907200.0000\n",
      "Epoch 34/50\n",
      "242/242 [==============================] - 0s 612us/step - loss: 32876387617995491377152.0000 - val_loss: 17334753588359256921341952.0000\n",
      "Epoch 35/50\n",
      "242/242 [==============================] - 0s 554us/step - loss: 256880620987202117042176.0000 - val_loss: 86142116636690910833278976.0000\n",
      "Epoch 36/50\n",
      "242/242 [==============================] - 0s 553us/step - loss: 2109284304197034128179200.0000 - val_loss: 421823467620947392920027136.0000\n",
      "Epoch 37/50\n",
      "242/242 [==============================] - 0s 567us/step - loss: 1202796024205010721046528.0000 - val_loss: 2102294108832800685971996672.0000\n",
      "Epoch 38/50\n",
      "242/242 [==============================] - 0s 560us/step - loss: 45945849643338554641743872.0000 - val_loss: 10149403311721478168768413696.0000\n",
      "Epoch 39/50\n",
      "242/242 [==============================] - 0s 593us/step - loss: 297758635974616791277109248.0000 - val_loss: 48996724548354689128894300160.0000\n",
      "Epoch 40/50\n",
      "242/242 [==============================] - 0s 573us/step - loss: 605433134758615414929883136.0000 - val_loss: 241361586538878359244147523584.0000\n",
      "Epoch 41/50\n",
      "242/242 [==============================] - 0s 572us/step - loss: 10232446126322740879851257856.0000 - val_loss: 1196537503393855714067021299712.0000\n",
      "Epoch 42/50\n",
      "242/242 [==============================] - 0s 575us/step - loss: 15178988068500691021486620672.0000 - val_loss: 5867198682305765593446778667008.0000\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 588us/step - loss: 16220425716067382489398640640.0000 - val_loss: 30115222264597092191970030256128.0000\n",
      "Epoch 44/50\n",
      "242/242 [==============================] - 0s 569us/step - loss: 64044389507924878904044552192.0000 - val_loss: 146624171504291465855869252534272.0000\n",
      "Epoch 45/50\n",
      "242/242 [==============================] - 0s 598us/step - loss: 291626644277202177684536295424.0000 - val_loss: 724013177909929875924379043364864.0000\n",
      "Epoch 46/50\n",
      "242/242 [==============================] - 0s 526us/step - loss: 1872167760581699195334006145024.0000 - val_loss: 3519541521910811100495528813658112.0000\n",
      "Epoch 47/50\n",
      "242/242 [==============================] - 0s 570us/step - loss: 9901582406194199948625939791872.0000 - val_loss: 17294867861863594355068521511124992.0000\n",
      "Epoch 48/50\n",
      "242/242 [==============================] - 0s 556us/step - loss: 249371318512105986768017419141120.0000 - val_loss: 83613550248152325792810799110029312.0000\n",
      "Epoch 49/50\n",
      "242/242 [==============================] - 0s 519us/step - loss: 2428477497556464411001948632776704.0000 - val_loss: inf\n",
      "Epoch 50/50\n",
      "242/242 [==============================] - 0s 547us/step - loss: 2159797931537558778915995596619776.0000 - val_loss: inf\n",
      "121/121 [==============================] - 0s 311us/step - loss: 5280326155758391377188435603226624.0000\n",
      "[CV]  learning_rate=0.015460888941140918, n_hidden=0, n_neurons=79, total=   7.1s\n",
      "[CV] learning_rate=0.015460888941140918, n_hidden=0, n_neurons=79 ....\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 752us/step - loss: 0.9229 - val_loss: 24.2922\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 571us/step - loss: 0.5142 - val_loss: 16.0770\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 597us/step - loss: 0.5086 - val_loss: 22.8315\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 563us/step - loss: 0.5069 - val_loss: 16.2431\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 557us/step - loss: 0.5051 - val_loss: 19.0271\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 537us/step - loss: 0.5039 - val_loss: 12.1992\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 0s 594us/step - loss: 0.5086 - val_loss: 19.1039\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - 0s 525us/step - loss: 0.5058 - val_loss: 15.2646\n",
      "Epoch 9/50\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.5097 - val_loss: 18.0980\n",
      "Epoch 10/50\n",
      "242/242 [==============================] - 0s 553us/step - loss: 0.5102 - val_loss: 15.5409\n",
      "Epoch 11/50\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.5101 - val_loss: 18.7806\n",
      "Epoch 12/50\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.5042 - val_loss: 12.9606\n",
      "Epoch 13/50\n",
      "242/242 [==============================] - 0s 584us/step - loss: 0.5054 - val_loss: 17.2332\n",
      "Epoch 14/50\n",
      "242/242 [==============================] - 0s 586us/step - loss: 0.5104 - val_loss: 15.7697\n",
      "Epoch 15/50\n",
      "242/242 [==============================] - 0s 576us/step - loss: 0.5062 - val_loss: 15.8331\n",
      "Epoch 16/50\n",
      "242/242 [==============================] - 0s 542us/step - loss: 0.5066 - val_loss: 17.5756\n",
      "Epoch 17/50\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.5083 - val_loss: 22.3144\n",
      "Epoch 18/50\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.5055 - val_loss: 23.5375\n",
      "Epoch 19/50\n",
      "242/242 [==============================] - 0s 565us/step - loss: 0.5054 - val_loss: 19.4081\n",
      "Epoch 20/50\n",
      "242/242 [==============================] - 0s 598us/step - loss: 0.5082 - val_loss: 17.7651\n",
      "Epoch 21/50\n",
      "242/242 [==============================] - 0s 562us/step - loss: 0.5118 - val_loss: 22.2991\n",
      "Epoch 22/50\n",
      "242/242 [==============================] - 0s 629us/step - loss: 0.5061 - val_loss: 19.9750\n",
      "Epoch 23/50\n",
      "242/242 [==============================] - 0s 597us/step - loss: 0.5057 - val_loss: 21.9504\n",
      "Epoch 24/50\n",
      "242/242 [==============================] - 0s 576us/step - loss: 0.5048 - val_loss: 21.4141\n",
      "Epoch 25/50\n",
      "242/242 [==============================] - 0s 561us/step - loss: 0.5077 - val_loss: 10.2426\n",
      "Epoch 26/50\n",
      "242/242 [==============================] - 0s 615us/step - loss: 0.5064 - val_loss: 19.9742\n",
      "Epoch 27/50\n",
      "242/242 [==============================] - 0s 553us/step - loss: 0.5075 - val_loss: 21.8821\n",
      "Epoch 28/50\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.5057 - val_loss: 23.0380\n",
      "Epoch 29/50\n",
      "242/242 [==============================] - 0s 583us/step - loss: 0.5068 - val_loss: 20.8817\n",
      "Epoch 30/50\n",
      "242/242 [==============================] - 0s 584us/step - loss: 0.5079 - val_loss: 22.9269\n",
      "Epoch 31/50\n",
      "242/242 [==============================] - 0s 600us/step - loss: 0.5077 - val_loss: 22.6025\n",
      "Epoch 32/50\n",
      "242/242 [==============================] - 0s 574us/step - loss: 0.5090 - val_loss: 22.0538\n",
      "Epoch 33/50\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.5063 - val_loss: 10.5259\n",
      "Epoch 34/50\n",
      "242/242 [==============================] - 0s 616us/step - loss: 0.5063 - val_loss: 21.1544\n",
      "Epoch 35/50\n",
      "242/242 [==============================] - 0s 524us/step - loss: 0.5045 - val_loss: 15.5376\n",
      "Epoch 36/50\n",
      "242/242 [==============================] - 0s 592us/step - loss: 0.5062 - val_loss: 23.0391\n",
      "Epoch 37/50\n",
      "242/242 [==============================] - 0s 570us/step - loss: 0.5056 - val_loss: 17.4612\n",
      "Epoch 38/50\n",
      "242/242 [==============================] - 0s 567us/step - loss: 0.5063 - val_loss: 23.2729\n",
      "Epoch 39/50\n",
      "242/242 [==============================] - 0s 576us/step - loss: 0.5131 - val_loss: 20.2195\n",
      "Epoch 40/50\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.5105 - val_loss: 19.3554\n",
      "Epoch 41/50\n",
      "242/242 [==============================] - 0s 553us/step - loss: 0.5080 - val_loss: 12.2047\n",
      "Epoch 42/50\n",
      "242/242 [==============================] - 0s 586us/step - loss: 0.5119 - val_loss: 16.1789\n",
      "Epoch 43/50\n",
      "242/242 [==============================] - 0s 575us/step - loss: 0.5073 - val_loss: 22.2510\n",
      "Epoch 44/50\n",
      "242/242 [==============================] - 0s 541us/step - loss: 0.5072 - val_loss: 14.8789\n",
      "Epoch 45/50\n",
      "242/242 [==============================] - 0s 595us/step - loss: 0.5069 - val_loss: 19.0424\n",
      "Epoch 46/50\n",
      "242/242 [==============================] - 0s 559us/step - loss: 0.5070 - val_loss: 14.0369\n",
      "Epoch 47/50\n",
      "242/242 [==============================] - 0s 578us/step - loss: 0.5061 - val_loss: 18.9769\n",
      "Epoch 48/50\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.5056 - val_loss: 21.5799\n",
      "Epoch 49/50\n",
      "242/242 [==============================] - 0s 602us/step - loss: 0.5073 - val_loss: 19.5944\n",
      "Epoch 50/50\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.5092 - val_loss: 17.1894\n",
      "121/121 [==============================] - 0s 275us/step - loss: 0.9103\n",
      "[CV]  learning_rate=0.015460888941140918, n_hidden=0, n_neurons=79, total=   7.3s\n",
      "[CV] learning_rate=0.015460888941140918, n_hidden=0, n_neurons=79 ....\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 765us/step - loss: 1.3071 - val_loss: 19.6594\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 634us/step - loss: 0.9704 - val_loss: 144.2744\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 596us/step - loss: 0.6863 - val_loss: 1.9374\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.7074 - val_loss: 8.3270\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 625us/step - loss: 0.5673 - val_loss: 2.4416\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.7458 - val_loss: 187.9735\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 0s 563us/step - loss: 2.3082 - val_loss: 258.5619\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - 0s 594us/step - loss: 6.1179 - val_loss: 339.7406\n",
      "Epoch 9/50\n",
      "242/242 [==============================] - 0s 541us/step - loss: 2.6118 - val_loss: 354.8502\n",
      "Epoch 10/50\n",
      "242/242 [==============================] - 0s 556us/step - loss: 1.6160 - val_loss: 1477.2491\n",
      "Epoch 11/50\n",
      "242/242 [==============================] - 0s 563us/step - loss: 4.5511 - val_loss: 1055.2249\n",
      "Epoch 12/50\n",
      "242/242 [==============================] - 0s 566us/step - loss: 3.5307 - val_loss: 2568.5989\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 547us/step - loss: 8.4503 - val_loss: 2659.7532\n",
      "Epoch 14/50\n",
      "242/242 [==============================] - 0s 543us/step - loss: 5.7671 - val_loss: 4101.5273\n",
      "Epoch 15/50\n",
      "242/242 [==============================] - 0s 522us/step - loss: 4.5670 - val_loss: 2639.7646\n",
      "Epoch 16/50\n",
      "242/242 [==============================] - 0s 616us/step - loss: 42.1368 - val_loss: 3631.5010\n",
      "Epoch 17/50\n",
      "242/242 [==============================] - 0s 544us/step - loss: 4.0070 - val_loss: 2101.8403\n",
      "Epoch 18/50\n",
      "242/242 [==============================] - 0s 651us/step - loss: 45.2281 - val_loss: 2541.2825\n",
      "Epoch 19/50\n",
      "242/242 [==============================] - 0s 581us/step - loss: 15.5576 - val_loss: 8807.5547\n",
      "Epoch 20/50\n",
      "242/242 [==============================] - 0s 517us/step - loss: 48.5057 - val_loss: 12353.7217\n",
      "Epoch 21/50\n",
      "242/242 [==============================] - 0s 566us/step - loss: 115.2681 - val_loss: 14802.2158\n",
      "Epoch 22/50\n",
      "242/242 [==============================] - 0s 591us/step - loss: 193.2616 - val_loss: 17991.7949\n",
      "Epoch 23/50\n",
      "242/242 [==============================] - 0s 597us/step - loss: 43.6699 - val_loss: 18854.2266\n",
      "Epoch 24/50\n",
      "242/242 [==============================] - 0s 594us/step - loss: 1062.7632 - val_loss: 22591.3066\n",
      "Epoch 25/50\n",
      "242/242 [==============================] - 0s 590us/step - loss: 73.1637 - val_loss: 26582.4707\n",
      "Epoch 26/50\n",
      "242/242 [==============================] - 0s 604us/step - loss: 166.4661 - val_loss: 32895.9844\n",
      "Epoch 27/50\n",
      "242/242 [==============================] - 0s 637us/step - loss: 44.4894 - val_loss: 35879.6836\n",
      "Epoch 28/50\n",
      "242/242 [==============================] - 0s 603us/step - loss: 1375.6860 - val_loss: 43234.5898\n",
      "Epoch 29/50\n",
      "242/242 [==============================] - 0s 575us/step - loss: 1727.4915 - val_loss: 53464.8594\n",
      "Epoch 30/50\n",
      "242/242 [==============================] - 0s 561us/step - loss: 179.9420 - val_loss: 68234.9531\n",
      "Epoch 31/50\n",
      "242/242 [==============================] - 0s 567us/step - loss: 1356.2141 - val_loss: 81680.1953\n",
      "Epoch 32/50\n",
      "242/242 [==============================] - 0s 562us/step - loss: 135.0816 - val_loss: 112182.7969\n",
      "Epoch 33/50\n",
      "242/242 [==============================] - 0s 623us/step - loss: 456.5830 - val_loss: 132234.4219\n",
      "Epoch 34/50\n",
      "242/242 [==============================] - 0s 556us/step - loss: 1164.5597 - val_loss: 166128.8594\n",
      "Epoch 35/50\n",
      "242/242 [==============================] - 0s 571us/step - loss: 160.8927 - val_loss: 191574.4062\n",
      "Epoch 36/50\n",
      "242/242 [==============================] - 0s 596us/step - loss: 7817.0830 - val_loss: 233313.5312\n",
      "Epoch 37/50\n",
      "242/242 [==============================] - 0s 646us/step - loss: 808.8621 - val_loss: 283785.7500\n",
      "Epoch 38/50\n",
      "242/242 [==============================] - 0s 619us/step - loss: 618.4316 - val_loss: 352075.0938\n",
      "Epoch 39/50\n",
      "242/242 [==============================] - 0s 588us/step - loss: 752.4177 - val_loss: 406520.9375\n",
      "Epoch 40/50\n",
      "242/242 [==============================] - 0s 584us/step - loss: 3567.0371 - val_loss: 499634.7812\n",
      "Epoch 41/50\n",
      "242/242 [==============================] - 0s 623us/step - loss: 1493.4969 - val_loss: 608313.0625\n",
      "Epoch 42/50\n",
      "242/242 [==============================] - 0s 593us/step - loss: 1326.5667 - val_loss: 758349.3125\n",
      "Epoch 43/50\n",
      "242/242 [==============================] - 0s 601us/step - loss: 2210.9167 - val_loss: 923528.9375\n",
      "Epoch 44/50\n",
      "242/242 [==============================] - 0s 572us/step - loss: 2302.4639 - val_loss: 1152229.8750\n",
      "Epoch 45/50\n",
      "242/242 [==============================] - 0s 549us/step - loss: 56544.9531 - val_loss: 1394980.6250\n",
      "Epoch 46/50\n",
      "242/242 [==============================] - 0s 596us/step - loss: 6298.0288 - val_loss: 1739896.8750\n",
      "Epoch 47/50\n",
      "242/242 [==============================] - 0s 598us/step - loss: 3961.4529 - val_loss: 2126452.7500\n",
      "Epoch 48/50\n",
      "242/242 [==============================] - 0s 582us/step - loss: 2480.3750 - val_loss: 2750203.7500\n",
      "Epoch 49/50\n",
      "242/242 [==============================] - 0s 583us/step - loss: 5952.3599 - val_loss: 3265045.2500\n",
      "Epoch 50/50\n",
      "242/242 [==============================] - 0s 582us/step - loss: 75243.3125 - val_loss: 4028843.2500\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 4343.1104\n",
      "[CV]  learning_rate=0.015460888941140918, n_hidden=0, n_neurons=79, total=   7.6s\n",
      "[CV] learning_rate=0.014428933444577281, n_hidden=1, n_neurons=95 ....\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.8015 - val_loss: 3.9973\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 667us/step - loss: 0.7783 - val_loss: 6.4221\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 657us/step - loss: 0.6869 - val_loss: 2.2955\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 683us/step - loss: 0.5685 - val_loss: 5.8517\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 702us/step - loss: 0.4501 - val_loss: 0.3534\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 646us/step - loss: 0.3748 - val_loss: 0.3721\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.3654 - val_loss: 0.3695\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.3582 - val_loss: 0.3889\n",
      "Epoch 9/50\n",
      "242/242 [==============================] - 0s 667us/step - loss: 0.3569 - val_loss: 0.3407\n",
      "Epoch 10/50\n",
      "242/242 [==============================] - 0s 621us/step - loss: 0.3497 - val_loss: 0.3577\n",
      "Epoch 11/50\n",
      "242/242 [==============================] - 0s 667us/step - loss: 0.3497 - val_loss: 0.3593\n",
      "Epoch 12/50\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.3448 - val_loss: 0.4067\n",
      "Epoch 13/50\n",
      "242/242 [==============================] - 0s 666us/step - loss: 0.3561 - val_loss: 0.3328\n",
      "Epoch 14/50\n",
      "242/242 [==============================] - 0s 698us/step - loss: 0.3435 - val_loss: 0.3657\n",
      "Epoch 15/50\n",
      "242/242 [==============================] - 0s 710us/step - loss: 0.3421 - val_loss: 0.3904\n",
      "Epoch 16/50\n",
      "242/242 [==============================] - 0s 677us/step - loss: 0.3368 - val_loss: 0.3346\n",
      "Epoch 17/50\n",
      "242/242 [==============================] - 0s 659us/step - loss: 0.3442 - val_loss: 0.3475\n",
      "Epoch 18/50\n",
      "242/242 [==============================] - 0s 669us/step - loss: 0.3348 - val_loss: 0.3333\n",
      "Epoch 19/50\n",
      "242/242 [==============================] - 0s 697us/step - loss: 0.3360 - val_loss: 0.3434\n",
      "Epoch 20/50\n",
      "242/242 [==============================] - 0s 708us/step - loss: 0.3305 - val_loss: 0.3931\n",
      "Epoch 21/50\n",
      "242/242 [==============================] - 0s 683us/step - loss: 0.3298 - val_loss: 0.3173\n",
      "Epoch 22/50\n",
      "242/242 [==============================] - 0s 632us/step - loss: 0.3374 - val_loss: 0.3251\n",
      "Epoch 23/50\n",
      "242/242 [==============================] - 0s 662us/step - loss: 0.3269 - val_loss: 0.3413\n",
      "Epoch 24/50\n",
      "242/242 [==============================] - 0s 660us/step - loss: 0.3268 - val_loss: 0.3585\n",
      "Epoch 25/50\n",
      "242/242 [==============================] - 0s 686us/step - loss: 0.3231 - val_loss: 0.3660\n",
      "Epoch 26/50\n",
      "242/242 [==============================] - 0s 646us/step - loss: 0.3271 - val_loss: 0.3498\n",
      "Epoch 27/50\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.3208 - val_loss: 0.3732\n",
      "Epoch 28/50\n",
      "242/242 [==============================] - 0s 710us/step - loss: 0.3187 - val_loss: 0.3324\n",
      "Epoch 29/50\n",
      "242/242 [==============================] - 0s 685us/step - loss: 0.3176 - val_loss: 0.3204\n",
      "Epoch 30/50\n",
      "242/242 [==============================] - 0s 723us/step - loss: 0.3169 - val_loss: 0.3354\n",
      "Epoch 31/50\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.3155 - val_loss: 0.3651\n",
      "Epoch 32/50\n",
      "242/242 [==============================] - 0s 693us/step - loss: 0.3164 - val_loss: 0.3098\n",
      "Epoch 33/50\n",
      "242/242 [==============================] - 0s 714us/step - loss: 0.3169 - val_loss: 0.3332\n",
      "Epoch 34/50\n",
      "242/242 [==============================] - 0s 694us/step - loss: 0.3125 - val_loss: 0.3324\n",
      "Epoch 35/50\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.3112 - val_loss: 0.3221\n",
      "Epoch 36/50\n",
      "242/242 [==============================] - 0s 659us/step - loss: 0.3160 - val_loss: 0.3231\n",
      "Epoch 37/50\n",
      "242/242 [==============================] - 0s 654us/step - loss: 0.3086 - val_loss: 0.3403\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 644us/step - loss: 0.3088 - val_loss: 0.3098\n",
      "Epoch 39/50\n",
      "242/242 [==============================] - 0s 679us/step - loss: 0.3071 - val_loss: 0.3566\n",
      "Epoch 40/50\n",
      "242/242 [==============================] - 0s 740us/step - loss: 0.3063 - val_loss: 0.3444\n",
      "Epoch 41/50\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.3087 - val_loss: 0.3046\n",
      "Epoch 42/50\n",
      "242/242 [==============================] - 0s 714us/step - loss: 0.3058 - val_loss: 0.3401\n",
      "Epoch 43/50\n",
      "242/242 [==============================] - 0s 726us/step - loss: 0.3086 - val_loss: 0.3539\n",
      "Epoch 44/50\n",
      "242/242 [==============================] - 0s 761us/step - loss: 0.3132 - val_loss: 0.3198\n",
      "Epoch 45/50\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.3042 - val_loss: 0.3261\n",
      "Epoch 46/50\n",
      "242/242 [==============================] - 0s 595us/step - loss: 0.3036 - val_loss: 0.3586\n",
      "Epoch 47/50\n",
      "242/242 [==============================] - 0s 637us/step - loss: 0.3349 - val_loss: 0.3172\n",
      "Epoch 48/50\n",
      "242/242 [==============================] - 0s 658us/step - loss: 0.3008 - val_loss: 0.3667\n",
      "Epoch 49/50\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.3042 - val_loss: 0.3090\n",
      "Epoch 50/50\n",
      "242/242 [==============================] - 0s 615us/step - loss: 0.2998 - val_loss: 0.3474\n",
      "121/121 [==============================] - 0s 342us/step - loss: 0.3339\n",
      "[CV]  learning_rate=0.014428933444577281, n_hidden=1, n_neurons=95, total=   8.6s\n",
      "[CV] learning_rate=0.014428933444577281, n_hidden=1, n_neurons=95 ....\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 805us/step - loss: 0.7843 - val_loss: 1.8093\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 650us/step - loss: 0.4637 - val_loss: 1.1527\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 649us/step - loss: 0.4226 - val_loss: 0.3996\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 641us/step - loss: 0.4111 - val_loss: 0.4105\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 650us/step - loss: 0.3923 - val_loss: 0.4449\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 630us/step - loss: 0.3878 - val_loss: 0.4848\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 0s 652us/step - loss: 0.3847 - val_loss: 0.4210\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - 0s 624us/step - loss: 0.3751 - val_loss: 0.3525\n",
      "Epoch 9/50\n",
      "242/242 [==============================] - 0s 627us/step - loss: 0.3668 - val_loss: 0.5772\n",
      "Epoch 10/50\n",
      "242/242 [==============================] - 0s 588us/step - loss: 0.3628 - val_loss: 0.8166\n",
      "Epoch 11/50\n",
      "242/242 [==============================] - 0s 575us/step - loss: 0.3600 - val_loss: 0.4289\n",
      "Epoch 12/50\n",
      "242/242 [==============================] - 0s 579us/step - loss: 0.3602 - val_loss: 0.5942\n",
      "Epoch 13/50\n",
      "242/242 [==============================] - 0s 554us/step - loss: 0.3597 - val_loss: 0.3579\n",
      "Epoch 14/50\n",
      "242/242 [==============================] - 0s 612us/step - loss: 0.3525 - val_loss: 0.5634\n",
      "Epoch 15/50\n",
      "242/242 [==============================] - 0s 578us/step - loss: 0.3517 - val_loss: 1.6277\n",
      "Epoch 16/50\n",
      "242/242 [==============================] - 0s 625us/step - loss: 0.3519 - val_loss: 0.4132\n",
      "Epoch 17/50\n",
      "242/242 [==============================] - 0s 682us/step - loss: 0.3473 - val_loss: 0.3616\n",
      "Epoch 18/50\n",
      "242/242 [==============================] - 0s 671us/step - loss: 0.3469 - val_loss: 0.6704\n",
      "Epoch 19/50\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.3453 - val_loss: 0.3234\n",
      "Epoch 20/50\n",
      "242/242 [==============================] - 0s 638us/step - loss: 0.3463 - val_loss: 0.3447\n",
      "Epoch 21/50\n",
      "242/242 [==============================] - 0s 645us/step - loss: 0.3405 - val_loss: 0.4876\n",
      "Epoch 22/50\n",
      "242/242 [==============================] - 0s 628us/step - loss: 0.3395 - val_loss: 0.3802\n",
      "Epoch 23/50\n",
      "242/242 [==============================] - 0s 595us/step - loss: 0.3397 - val_loss: 0.3751\n",
      "Epoch 24/50\n",
      "242/242 [==============================] - 0s 625us/step - loss: 0.3411 - val_loss: 0.5544\n",
      "Epoch 25/50\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.3362 - val_loss: 0.8066\n",
      "Epoch 26/50\n",
      "242/242 [==============================] - 0s 675us/step - loss: 0.3357 - val_loss: 0.3198\n",
      "Epoch 27/50\n",
      "242/242 [==============================] - 0s 686us/step - loss: 0.3366 - val_loss: 0.3460\n",
      "Epoch 28/50\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.3312 - val_loss: 0.5100\n",
      "Epoch 29/50\n",
      "242/242 [==============================] - 0s 667us/step - loss: 0.3301 - val_loss: 0.4084\n",
      "Epoch 30/50\n",
      "242/242 [==============================] - 0s 621us/step - loss: 0.3301 - val_loss: 0.3224\n",
      "Epoch 31/50\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.3560 - val_loss: 0.3398\n",
      "Epoch 32/50\n",
      "242/242 [==============================] - 0s 641us/step - loss: 0.3290 - val_loss: 0.3290\n",
      "Epoch 33/50\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.3272 - val_loss: 0.4042\n",
      "Epoch 34/50\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.3259 - val_loss: 0.3911\n",
      "Epoch 35/50\n",
      "242/242 [==============================] - 0s 702us/step - loss: 0.3245 - val_loss: 0.8787\n",
      "Epoch 36/50\n",
      "242/242 [==============================] - 0s 612us/step - loss: 0.3236 - val_loss: 0.6259\n",
      "Epoch 37/50\n",
      "242/242 [==============================] - 0s 675us/step - loss: 0.3218 - val_loss: 0.3844\n",
      "Epoch 38/50\n",
      "242/242 [==============================] - 0s 675us/step - loss: 0.3258 - val_loss: 1.1503\n",
      "Epoch 39/50\n",
      "242/242 [==============================] - 0s 631us/step - loss: 0.3251 - val_loss: 0.3132\n",
      "Epoch 40/50\n",
      "242/242 [==============================] - 0s 719us/step - loss: 0.3213 - val_loss: 0.3340\n",
      "Epoch 41/50\n",
      "242/242 [==============================] - 0s 693us/step - loss: 0.3188 - val_loss: 0.8169\n",
      "Epoch 42/50\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.3182 - val_loss: 0.3795\n",
      "Epoch 43/50\n",
      "242/242 [==============================] - 0s 739us/step - loss: 0.3174 - val_loss: 0.5617\n",
      "Epoch 44/50\n",
      "242/242 [==============================] - 0s 680us/step - loss: 0.3175 - val_loss: 0.5934\n",
      "Epoch 45/50\n",
      "242/242 [==============================] - 0s 657us/step - loss: 0.3202 - val_loss: 0.3098\n",
      "Epoch 46/50\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.3123 - val_loss: 0.4660\n",
      "Epoch 47/50\n",
      "242/242 [==============================] - 0s 723us/step - loss: 0.3225 - val_loss: 0.6347\n",
      "Epoch 48/50\n",
      "242/242 [==============================] - 0s 615us/step - loss: 0.3179 - val_loss: 0.4391\n",
      "Epoch 49/50\n",
      "242/242 [==============================] - 0s 638us/step - loss: 0.3177 - val_loss: 0.5349\n",
      "Epoch 50/50\n",
      "242/242 [==============================] - 0s 715us/step - loss: 0.3167 - val_loss: 3.4026\n",
      "121/121 [==============================] - 0s 339us/step - loss: 0.4099\n",
      "[CV]  learning_rate=0.014428933444577281, n_hidden=1, n_neurons=95, total=   8.2s\n",
      "[CV] learning_rate=0.014428933444577281, n_hidden=1, n_neurons=95 ....\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 823us/step - loss: 0.6750 - val_loss: 0.4667\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 638us/step - loss: 0.4746 - val_loss: 3.6860\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 587us/step - loss: 0.5468 - val_loss: 26.5272\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 631us/step - loss: 0.6398 - val_loss: 4.4857\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 649us/step - loss: 0.4754 - val_loss: 1.8307\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 641us/step - loss: 0.4264 - val_loss: 0.3652\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 0s 604us/step - loss: 0.3984 - val_loss: 0.3656\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - 0s 727us/step - loss: 0.3904 - val_loss: 0.3581\n",
      "Epoch 9/50\n",
      "242/242 [==============================] - 0s 671us/step - loss: 0.3836 - val_loss: 0.3707\n",
      "Epoch 10/50\n",
      "242/242 [==============================] - 0s 715us/step - loss: 0.3756 - val_loss: 0.3685\n",
      "Epoch 11/50\n",
      "242/242 [==============================] - 0s 677us/step - loss: 0.3726 - val_loss: 0.3868\n",
      "Epoch 12/50\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.3699 - val_loss: 0.3858\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 648us/step - loss: 0.3650 - val_loss: 0.4129\n",
      "Epoch 14/50\n",
      "242/242 [==============================] - 0s 627us/step - loss: 0.3744 - val_loss: 0.3869\n",
      "Epoch 15/50\n",
      "242/242 [==============================] - 0s 649us/step - loss: 0.3627 - val_loss: 0.3842\n",
      "Epoch 16/50\n",
      "242/242 [==============================] - 0s 683us/step - loss: 0.3675 - val_loss: 0.3818\n",
      "Epoch 17/50\n",
      "242/242 [==============================] - 0s 617us/step - loss: 0.3588 - val_loss: 0.3750\n",
      "Epoch 18/50\n",
      "242/242 [==============================] - 0s 649us/step - loss: 0.3660 - val_loss: 0.3670\n",
      "Epoch 19/50\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.3602 - val_loss: 0.3609\n",
      "Epoch 20/50\n",
      "242/242 [==============================] - 0s 622us/step - loss: 0.3541 - val_loss: 0.3633\n",
      "Epoch 21/50\n",
      "242/242 [==============================] - 0s 601us/step - loss: 0.3502 - val_loss: 0.3548\n",
      "Epoch 22/50\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.3491 - val_loss: 0.3544\n",
      "Epoch 23/50\n",
      "242/242 [==============================] - 0s 698us/step - loss: 0.3461 - val_loss: 0.3680\n",
      "Epoch 24/50\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.3437 - val_loss: 0.3519\n",
      "Epoch 25/50\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.3425 - val_loss: 0.3471\n",
      "Epoch 26/50\n",
      "242/242 [==============================] - 0s 640us/step - loss: 0.3404 - val_loss: 0.3677\n",
      "Epoch 27/50\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.3449 - val_loss: 0.3444\n",
      "Epoch 28/50\n",
      "242/242 [==============================] - 0s 598us/step - loss: 0.3385 - val_loss: 0.3347\n",
      "Epoch 29/50\n",
      "242/242 [==============================] - 0s 625us/step - loss: 0.3388 - val_loss: 0.3381\n",
      "Epoch 30/50\n",
      "242/242 [==============================] - 0s 601us/step - loss: 0.3429 - val_loss: 0.3330\n",
      "Epoch 31/50\n",
      "242/242 [==============================] - 0s 580us/step - loss: 0.3346 - val_loss: 0.3264\n",
      "Epoch 32/50\n",
      "242/242 [==============================] - 0s 624us/step - loss: 0.3499 - val_loss: 0.3293\n",
      "Epoch 33/50\n",
      "242/242 [==============================] - 0s 622us/step - loss: 0.3367 - val_loss: 0.3276\n",
      "Epoch 34/50\n",
      "242/242 [==============================] - 0s 630us/step - loss: 0.3336 - val_loss: 0.3341\n",
      "Epoch 35/50\n",
      "242/242 [==============================] - 0s 624us/step - loss: 0.3370 - val_loss: 0.3307\n",
      "Epoch 36/50\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.3287 - val_loss: 0.3199\n",
      "Epoch 37/50\n",
      "242/242 [==============================] - 0s 677us/step - loss: 0.3299 - val_loss: 0.3328\n",
      "Epoch 38/50\n",
      "242/242 [==============================] - 0s 621us/step - loss: 0.3279 - val_loss: 0.3247\n",
      "Epoch 39/50\n",
      "242/242 [==============================] - 0s 613us/step - loss: 0.3323 - val_loss: 0.3277\n",
      "Epoch 40/50\n",
      "242/242 [==============================] - 0s 616us/step - loss: 0.3381 - val_loss: 0.4556\n",
      "Epoch 41/50\n",
      "242/242 [==============================] - 0s 683us/step - loss: 0.3293 - val_loss: 0.3215\n",
      "Epoch 42/50\n",
      "242/242 [==============================] - 0s 619us/step - loss: 0.3262 - val_loss: 0.3228\n",
      "Epoch 43/50\n",
      "242/242 [==============================] - 0s 631us/step - loss: 0.3238 - val_loss: 0.4108\n",
      "Epoch 44/50\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.3227 - val_loss: 0.3067\n",
      "Epoch 45/50\n",
      "242/242 [==============================] - 0s 682us/step - loss: 0.3251 - val_loss: 0.3184\n",
      "Epoch 46/50\n",
      "242/242 [==============================] - 0s 616us/step - loss: 0.3252 - val_loss: 0.3142\n",
      "Epoch 47/50\n",
      "242/242 [==============================] - 0s 572us/step - loss: 0.3203 - val_loss: 0.3109\n",
      "Epoch 48/50\n",
      "242/242 [==============================] - 0s 670us/step - loss: 0.3204 - val_loss: 0.3397\n",
      "Epoch 49/50\n",
      "242/242 [==============================] - 0s 715us/step - loss: 0.3207 - val_loss: 0.3125\n",
      "Epoch 50/50\n",
      "242/242 [==============================] - 0s 645us/step - loss: 0.3195 - val_loss: 0.3389\n",
      "121/121 [==============================] - 0s 333us/step - loss: 0.3207\n",
      "[CV]  learning_rate=0.014428933444577281, n_hidden=1, n_neurons=95, total=   8.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  3.9min finished\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7f56c43f9ba8>, as the constructor either does not set or modifies parameter learning_rate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-145-ae54ef22c592>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mrnd_search_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distribs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m rnd_search_cv.fit(X_train, y_train, epochs=50,\n\u001b[0;32m---> 12\u001b[0;31m                   \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m                   \u001b[0;31m#callbacks=[keras.callbacks.EarlyStopping(patience=10)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                  )\n",
      "\u001b[0;32m~/ml/my_env/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/my_env/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;31m# of the params are estimators as well.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[0;32m--> 762\u001b[0;31m                 **self.best_params_))\n\u001b[0m\u001b[1;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/my_env/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/my_env/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     96\u001b[0m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[1;32m     97\u001b[0m                                \u001b[0;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                                (estimator, name))\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7f56c43f9ba8>, as the constructor either does not set or modifies parameter learning_rate"
     ]
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=50,\n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  #callbacks=[keras.callbacks.EarlyStopping(patience=10)]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.0055152207481209145, 'n_hidden': 3, 'n_neurons': 64}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.312321017185847"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_cv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnd_search_cv.best_estimator_.model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 422us/step - loss: 0.3768 - accuracy: 0.0021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3767662048339844, 0.0021317829377949238]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
